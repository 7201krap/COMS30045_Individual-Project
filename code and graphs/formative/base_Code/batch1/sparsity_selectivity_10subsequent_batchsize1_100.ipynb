{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparsity_selectivity_10subsequent_batchsize1_100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/sparsity_selectivity_10subsequent_batchsize1_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7STrWa0P3z_",
        "outputId": "ff75e328-78a1-4c82-e468-816ef0a1c227"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIyKF1HE7uQW",
        "outputId": "91f1d010-79ea-43bf-80ee-18c203a8f001"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "root_dir = './'\n",
        "torchvision.datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-18 21:30:41--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-18 21:30:42--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.2’\n",
            "\n",
            "MNIST.tar.gz.2          [            <=>     ]  33.20M  14.0MB/s    in 2.4s    \n",
            "\n",
            "2021-03-18 21:30:44 (14.0 MB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4j9WoP-UnAm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApOU7hvb95W4"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = torchvision.datasets.MNIST(root=root_dir, train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = torchvision.datasets.MNIST(root=root_dir, \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow9Sy2SyUYgn"
      },
      "source": [
        "new_mnist_trainset =  [ [[],[]] for i in range(10)]\n",
        "# new_mnist_testset  =  [ [[],[]] for i in range(10)]\n",
        "\n",
        "for i in range(60000):\n",
        "    for j in range(10):\n",
        "        # 만약에 label 이 j 이면, \n",
        "        if mnist_trainset[i][1] == j:\n",
        "            # image \n",
        "            new_mnist_trainset[j][0].append(mnist_trainset[i][0])  \n",
        "            # new_mnist_trainset[j][0] 는 j label 에 해당하는 image 가 들어있다. \n",
        "\n",
        "            # label\n",
        "            new_mnist_trainset[j][1].append(mnist_trainset[i][1])\n",
        "            # new_mnist_trainset[j][1] 는 j label 에 해당하는 label 가 들어있다. \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyIkUPYTNdLf",
        "outputId": "639bbe10-21af-43c7-f329-ea591a924bc3"
      },
      "source": [
        "print(\"0\", len(new_mnist_trainset[0][0]))    # - pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][0]))    # - pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][0]))    # - pop 8 times\n",
        "print(\"3\", len(new_mnist_trainset[3][0]))    # - pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][0]))    # - pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][0]))    # - pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][0]))    # - pop 8 times\n",
        "print(\"7\", len(new_mnist_trainset[7][0]))    # - pop 5 times\n",
        "print(\"8\", len(new_mnist_trainset[8][0]))    # - pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][0]))    # - pop 9 times"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5923\n",
            "1 6742\n",
            "2 5958\n",
            "3 6131\n",
            "4 5842\n",
            "5 5421\n",
            "6 5918\n",
            "7 6265\n",
            "8 5851\n",
            "9 5949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieTyNQeWP1Sb"
      },
      "source": [
        "# 0 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[0][0].pop()\n",
        "    new_mnist_trainset[0][1].pop()\n",
        "\n",
        "# 1 - pop 2 times\n",
        "for i in range(2):\n",
        "    new_mnist_trainset[1][0].pop()\n",
        "    new_mnist_trainset[1][1].pop()\n",
        "\n",
        "# 2 - pop 8 times\n",
        "for i in range(8):\n",
        "    new_mnist_trainset[2][0].pop()\n",
        "    new_mnist_trainset[2][1].pop()\n",
        "\n",
        "# 3 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[3][0].pop()\n",
        "    new_mnist_trainset[3][1].pop()\n",
        "\n",
        "# 4 - pop 2 time\n",
        "for i in range(2):\n",
        "    new_mnist_trainset[4][0].pop()\n",
        "    new_mnist_trainset[4][1].pop()\n",
        "\n",
        "# 5 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[5][0].pop()\n",
        "    new_mnist_trainset[5][1].pop()\n",
        "\n",
        "# 6 - pop 8 times\n",
        "for i in range(8):\n",
        "    new_mnist_trainset[6][0].pop()\n",
        "    new_mnist_trainset[6][1].pop()\n",
        "\n",
        "# 7 - pop 0 times\n",
        "for i in range(5):\n",
        "    new_mnist_trainset[7][0].pop()\n",
        "    new_mnist_trainset[7][1].pop()\n",
        "\n",
        "# 8 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[8][0].pop()\n",
        "    new_mnist_trainset[8][1].pop()\n",
        "\n",
        "# 9 - pop 9 times\n",
        "for i in range(9):\n",
        "    new_mnist_trainset[9][0].pop()\n",
        "    new_mnist_trainset[9][1].pop()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSb6f78RQYGp",
        "outputId": "26f65c81-125a-4cc5-814f-6a44bb8d3ce9"
      },
      "source": [
        "print(\"0\", len(new_mnist_trainset[0][0]))    # pop 3 times\n",
        "print(\"0\", len(new_mnist_trainset[0][1]))    # pop 3 times\n",
        "\n",
        "print(\"1\", len(new_mnist_trainset[1][0]))    # pop 2 times\n",
        "print(\"1\", len(new_mnist_trainset[1][1]))    # pop 2 times\n",
        "\n",
        "print(\"2\", len(new_mnist_trainset[2][0]))    # pop 3 times\n",
        "print(\"2\", len(new_mnist_trainset[2][1]))    # pop 3 times\n",
        "\n",
        "print(\"3\", len(new_mnist_trainset[3][0]))    # pop 1 times\n",
        "print(\"3\", len(new_mnist_trainset[3][1]))    # pop 1 times\n",
        "\n",
        "print(\"4\", len(new_mnist_trainset[4][0]))    # pop 2 time\n",
        "print(\"4\", len(new_mnist_trainset[4][1]))    # pop 2 time\n",
        "\n",
        "print(\"5\", len(new_mnist_trainset[5][0]))    # pop 1 times\n",
        "print(\"5\", len(new_mnist_trainset[5][1]))    # pop 1 times\n",
        "\n",
        "print(\"6\", len(new_mnist_trainset[6][0]))    # pop 3 times\n",
        "print(\"6\", len(new_mnist_trainset[6][1]))    # pop 3 times\n",
        "\n",
        "print(\"7\", len(new_mnist_trainset[7][0]))    # pop 0 times\n",
        "print(\"7\", len(new_mnist_trainset[7][1]))    # pop 0 times\n",
        "\n",
        "print(\"8\", len(new_mnist_trainset[8][0]))    # pop 1 times\n",
        "print(\"8\", len(new_mnist_trainset[8][1]))    # pop 1 times\n",
        "\n",
        "print(\"9\", len(new_mnist_trainset[9][0]))    # pop 4 times\n",
        "print(\"9\", len(new_mnist_trainset[9][1]))    # pop 4 times"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5920\n",
            "0 5920\n",
            "1 6740\n",
            "1 6740\n",
            "2 5950\n",
            "2 5950\n",
            "3 6130\n",
            "3 6130\n",
            "4 5840\n",
            "4 5840\n",
            "5 5420\n",
            "5 5420\n",
            "6 5910\n",
            "6 5910\n",
            "7 6260\n",
            "7 6260\n",
            "8 5850\n",
            "8 5850\n",
            "9 5940\n",
            "9 5940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMFpH3QLNAYQ"
      },
      "source": [
        "image_trainset = list()\n",
        "label_trainset = list()\n",
        "\n",
        "for i in range(10):\n",
        "    image_trainset.append(new_mnist_trainset[i][0])\n",
        "    label_trainset.append(new_mnist_trainset[i][1])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV9vZ4G_NCTB"
      },
      "source": [
        "flattened_image_train = list()\n",
        "flattened_label_train = list()\n",
        "\n",
        "# flattening image \n",
        "for sublist in image_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_image_train.append(val)\n",
        "\n",
        "# flattening label\n",
        "for sublist in label_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_label_train.append(val)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q_z0dBzSR5o",
        "outputId": "5a6b1d5e-a2cd-4241-a52f-d6ee66d51d1e"
      },
      "source": [
        "len(flattened_image_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onYs9h2CTj41",
        "outputId": "1387970f-d673-44a9-a506-09f0ee38692f"
      },
      "source": [
        "len(flattened_label_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbZTrSWrYkkG"
      },
      "source": [
        "def split(a, n):\n",
        "    k, m = divmod(len(a), n)\n",
        "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFctZ-9EYlgx"
      },
      "source": [
        "list1 = list(split(flattened_image_train, 5996))\n",
        "list2 = list(split(flattened_label_train, 5996))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlqM-hF2ZuV2"
      },
      "source": [
        "X, y = shuffle(list1, list2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTF5pJPZypH"
      },
      "source": [
        "X_final, y_final = shuffle(X, y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LM44S14PndX",
        "outputId": "926546c2-a5ed-4b4c-a9b8-f5138b3be29c"
      },
      "source": [
        "y_final[6]\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimwHtbgaEtX"
      },
      "source": [
        "flattened_X_final = [val for sublist in X_final for val in sublist] \n",
        "flattened_y_final = [val for sublist in y_final for val in sublist] "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "Xxbuxud6djJF",
        "outputId": "959081bf-7df1-4640-d668-d0823935af2d"
      },
      "source": [
        "print(flattened_y_final[0])\n",
        "plt.imshow(flattened_X_final[0].reshape(28,28))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f101bc83f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2XVNBlcPl3I"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SkccxZdNEDY"
      },
      "source": [
        "flattened_image_train = torch.stack(flattened_X_final)\n",
        "flattened_label_train = torch.Tensor(flattened_y_final)\n",
        "flattened_label_train = flattened_label_train.type(torch.LongTensor)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trsJx6P7QQsI",
        "outputId": "0d41277b-d9d3-407e-f2d8-0aa152006146"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 3, 3,  ..., 2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cANEC2zaNFPq"
      },
      "source": [
        "train_dataset = TensorDataset(flattened_image_train, flattened_label_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAD1thJ5JvD"
      },
      "source": [
        "def selectivity(hidden_layer_each_neuron):\n",
        "    __selectivity__ = list()\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(256)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 256 lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(256)]\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity\n",
        "        __selectivity__.append(selectivity)\n",
        "\n",
        "    avg_selectivity = np.average(__selectivity__)\n",
        "    std_selectivity = np.std(__selectivity__)\n",
        "                                 \n",
        "    return avg_selectivity, std_selectivity"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9kATNPUz1cA"
      },
      "source": [
        "def sparsity_calculator(final_spareness):\n",
        "    sparseness_list = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 30\n",
        "def selectivity_trainer(optimizer, model):\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "\n",
        "    final_spareness = list()\n",
        "    \n",
        "    final_selectivity_avg_list = list()\n",
        "    final_selectivity_std_list = list()\n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        _hidden_layer_each_neuron_ = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
        "        _hidden_layer_each_neuron_ = np.array(_hidden_layer_each_neuron_)\n",
        "\n",
        "        hidden_layer_activation_list = list()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, labels) in enumerate(train_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print/Append activation of the hidden layer \n",
        "            # print(model.layer_activations.shape)\n",
        "            # model.layer_activations\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            hidden_layer_activation_list.append(model.layer_activations)\n",
        "\n",
        "            \n",
        "            for activation, label in zip(model.layer_activations, labels):\n",
        "                # shape of activation and label: 256 and 1 \n",
        "                \n",
        "                # get the actual value of item. This is because label is now Tensor \n",
        "                label = label.item()\n",
        "\n",
        "                # this is not part of gradient calculcation \n",
        "                with torch.no_grad():\n",
        "                    activation = activation.numpy()\n",
        "\n",
        "                # for each image/label, append activation value of neuron \n",
        "                for i in range(256):    # number of neurons in hidden layer \n",
        "                    _hidden_layer_each_neuron_[i][label].append(activation[i])\n",
        "\n",
        "        avg_selectivity, std_selectivity = selectivity(_hidden_layer_each_neuron_)\n",
        "        \n",
        "        final_selectivity_avg_list.append(avg_selectivity)\n",
        "        final_selectivity_std_list.append(std_selectivity)\n",
        "\n",
        "        final_spareness.append(hidden_layer_activation_list)\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "    sparsity_list = sparsity_calculator(final_spareness)\n",
        "\n",
        "    average_sparsity = list()\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    print(\"average_sparsity:\", average_sparsity)\n",
        "    print(\"final_selectivity_avg_list\", final_selectivity_avg_list)\n",
        "    print(\"final_selectivity_std_list\", final_selectivity_std_list)\n",
        "\n",
        "    return test_acc, average_sparsity, final_selectivity_avg_list, final_selectivity_std_list"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# AdaDelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WytqcJRZxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedfda39-6f39-4a21-d957-064808dc08cc"
      },
      "source": [
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"10subsebatch1_sparsity_selectivity_Adadelta.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adadelta_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 10subsebatch1_sparsity_selectivity_Adadelta.txt /content/drive/MyDrive"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.28426039, Test Loss: 0.23244632, Test Accuracy: 0.94190000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.17131123, Test Loss: 0.16839482, Test Accuracy: 0.95670000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.12806039, Test Loss: 0.13817907, Test Accuracy: 0.96430000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.10571225, Test Loss: 0.12111656, Test Accuracy: 0.96930000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.09179864, Test Loss: 0.11276845, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.08217489, Test Loss: 0.10694119, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.07508733, Test Loss: 0.10394627, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.06961910, Test Loss: 0.10160633, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.06551265, Test Loss: 0.09981236, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.06226887, Test Loss: 0.09953544, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.05878337, Test Loss: 0.10178465, Test Accuracy: 0.97710000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.05556031, Test Loss: 0.10566869, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.05274535, Test Loss: 0.11042160, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.05041512, Test Loss: 0.11188503, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.04827302, Test Loss: 0.11288808, Test Accuracy: 0.97580000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.04633824, Test Loss: 0.11284524, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.04462681, Test Loss: 0.11344954, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.04311500, Test Loss: 0.11376963, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.04142759, Test Loss: 0.11512436, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.03991479, Test Loss: 0.11548002, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.03840476, Test Loss: 0.11523205, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.03702486, Test Loss: 0.11577995, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.03569909, Test Loss: 0.11847490, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.03428012, Test Loss: 0.12077647, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.03281422, Test Loss: 0.12291640, Test Accuracy: 0.97600000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.03141000, Test Loss: 0.12483676, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.03009391, Test Loss: 0.12578572, Test Accuracy: 0.97550000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.02886616, Test Loss: 0.12686206, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.02775766, Test Loss: 0.12828921, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.02690287, Test Loss: 0.12933489, Test Accuracy: 0.97530000\n",
            "average_sparsity: [0.31343594193458557, 0.3212507665157318, 0.32450833916664124, 0.3233979046344757, 0.3189409673213959, 0.31828102469444275, 0.3159765601158142, 0.31442147493362427, 0.3124822974205017, 0.3103885352611542, 0.30884143710136414, 0.30721554160118103, 0.30494412779808044, 0.30403265357017517, 0.3038032352924347, 0.3029896020889282, 0.3016151785850525, 0.3002069592475891, 0.29868942499160767, 0.29805290699005127, 0.29778340458869934, 0.29687803983688354, 0.2950858771800995, 0.2942194640636444, 0.29347553849220276, 0.29373759031295776, 0.2939203977584839, 0.294119268655777, 0.2934111952781677, 0.29270991683006287]\n",
            "final_selectivity_avg_list [0.43642532158459824, 0.4338847254735714, 0.4274986338769866, 0.4177060449551582, 0.4068288372097647, 0.40202944326886164, 0.3978399870771534, 0.3940160080227811, 0.39052833081936345, 0.38600947804050845, 0.38211247978050844, 0.3787861112814893, 0.3752285100570101, 0.37214930465538454, 0.36964335253475394, 0.36641853431448623, 0.3632562113863617, 0.3602664419481329, 0.3568050308418029, 0.3540000431433639, 0.351860585511906, 0.3496046181727208, 0.34723160916913265, 0.3457383827911944, 0.34464099874837617, 0.344516096598402, 0.3448064832296252, 0.34456595535325757, 0.3430875687755802, 0.3416405994337829]\n",
            "final_selectivity_std_list [0.24988754956854475, 0.25185824864317635, 0.2519391674321295, 0.250481626488184, 0.24486559870574642, 0.2405053812675021, 0.23890144474895625, 0.2363017654374082, 0.2347260784727593, 0.23126207563665174, 0.22859037465505155, 0.2264889683390971, 0.22475645656866503, 0.22318524979654314, 0.22138977455810513, 0.21941252873594175, 0.2180660906750347, 0.21552183381483436, 0.2121936724773144, 0.20916097830740388, 0.20653626244003867, 0.20473212948854477, 0.20392004884734097, 0.20284687712877264, 0.20232008771410573, 0.20259629440375923, 0.20363738860038924, 0.2029340410075432, 0.20130480252237384, 0.19981836424001315]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXfQe4vMDKB"
      },
      "source": [
        "# AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb-4TPM5MGuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8652c17-4497-49b8-9dd3-5ed31474b8f6"
      },
      "source": [
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"10subsebatch1_sparsity_selectivity_Adagrad.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adagrad_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 10subsebatch1_sparsity_selectivity_Adagrad.txt /content/drive/MyDrive"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.17434923, Test Loss: 0.12282737, Test Accuracy: 0.96130000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08163107, Test Loss: 0.09844793, Test Accuracy: 0.97010000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05468853, Test Loss: 0.08666628, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03998853, Test Loss: 0.08089337, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03052060, Test Loss: 0.07741157, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02393086, Test Loss: 0.07507402, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01904293, Test Loss: 0.07272258, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01543956, Test Loss: 0.07116733, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01270352, Test Loss: 0.06997721, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01058406, Test Loss: 0.06907165, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00891153, Test Loss: 0.06847569, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00760554, Test Loss: 0.06822450, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00655833, Test Loss: 0.06808132, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00570778, Test Loss: 0.06807974, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00501991, Test Loss: 0.06807706, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00446206, Test Loss: 0.06812684, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00399646, Test Loss: 0.06827659, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00360290, Test Loss: 0.06843972, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00326879, Test Loss: 0.06858666, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00298456, Test Loss: 0.06878943, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00273715, Test Loss: 0.06898616, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00251985, Test Loss: 0.06918337, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00233101, Test Loss: 0.06938422, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00216808, Test Loss: 0.06960139, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00202470, Test Loss: 0.06981462, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00189746, Test Loss: 0.07002902, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00178396, Test Loss: 0.07025272, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00168213, Test Loss: 0.07048622, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00159026, Test Loss: 0.07072124, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00150689, Test Loss: 0.07095281, Test Accuracy: 0.98050000\n",
            "average_sparsity: [0.5267013907432556, 0.5179392099380493, 0.5150507688522339, 0.5127068758010864, 0.5107030868530273, 0.5081892013549805, 0.5055432915687561, 0.5040046572685242, 0.5025213956832886, 0.5015141367912292, 0.5004098415374756, 0.49939513206481934, 0.49861079454421997, 0.4977162182331085, 0.4970185160636902, 0.49640291929244995, 0.4957616627216339, 0.4951707422733307, 0.49469491839408875, 0.4942533075809479, 0.4938506782054901, 0.4935102164745331, 0.49322012066841125, 0.492952436208725, 0.49270814657211304, 0.4924812614917755, 0.49226415157318115, 0.4920595586299896, 0.49186503887176514, 0.4916805624961853]\n",
            "final_selectivity_avg_list [0.6258652566031926, 0.6070603192358718, 0.6032288986661898, 0.6013709761822502, 0.5974811904329411, 0.5946510974020564, 0.5916541523034435, 0.5882918401818329, 0.5859635649532596, 0.5835619362451597, 0.5815203994470163, 0.5789018412762685, 0.5766499829702815, 0.5747556200774138, 0.5728481664337854, 0.5713554652160202, 0.5696402717952687, 0.5682556435993875, 0.567445901535319, 0.5670300315405743, 0.5661815839629624, 0.5654484406426019, 0.5653135973050006, 0.5651635045455256, 0.5648833777269227, 0.5645885498223225, 0.5643176438162306, 0.5640723800504592, 0.5638674751926055, 0.5636396629539071]\n",
            "final_selectivity_std_list [0.28191547037168546, 0.2773782690952823, 0.27502529633007167, 0.27256266620985997, 0.2720035487323102, 0.27005688581240345, 0.2680758121086144, 0.26618886780096873, 0.2649010764615456, 0.2636183153936943, 0.2625980102738377, 0.26172371153320767, 0.26107963398223344, 0.2603275401909751, 0.2594038302305081, 0.25855114559573167, 0.2575541732834691, 0.25686620776582225, 0.25661832320788497, 0.2564378820985824, 0.25609853850269526, 0.2558342656506052, 0.2559718063586451, 0.2560657001383516, 0.2560544828483017, 0.2560308252780112, 0.256029370801274, 0.2560262233613081, 0.25598659723760325, 0.2559390942069271]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLJ4Zr2MnoS"
      },
      "source": [
        "# SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ObsEJHuMoPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1015c631-6f6b-4832-a226-47fcdaba4e08"
      },
      "source": [
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity, SGD_avg_selectivity_list, SGD_std_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"10subsebatch1_sparsity_selectivity_SGD.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(SGD_test_acc)+'\\n'+str(sparsity)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 10subsebatch1_sparsity_selectivity_SGD.txt /content/drive/MyDrive"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.20214335, Test Loss: 0.14677740, Test Accuracy: 0.95580000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.10113966, Test Loss: 0.11615028, Test Accuracy: 0.96530000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.06741328, Test Loss: 0.12466699, Test Accuracy: 0.96460000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.05061474, Test Loss: 0.10844396, Test Accuracy: 0.96890000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03744194, Test Loss: 0.09510388, Test Accuracy: 0.97230000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02746282, Test Loss: 0.09685668, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.02216516, Test Loss: 0.09922500, Test Accuracy: 0.97340000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01665743, Test Loss: 0.09839192, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01331789, Test Loss: 0.09826538, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01018993, Test Loss: 0.09026012, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00771151, Test Loss: 0.09415542, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00483612, Test Loss: 0.08867282, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00404759, Test Loss: 0.08321564, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00199944, Test Loss: 0.08019820, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00132235, Test Loss: 0.07963760, Test Accuracy: 0.98280000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00097897, Test Loss: 0.07933712, Test Accuracy: 0.98300000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00075808, Test Loss: 0.07932781, Test Accuracy: 0.98300000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00064987, Test Loss: 0.07948190, Test Accuracy: 0.98300000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00057277, Test Loss: 0.07966110, Test Accuracy: 0.98310000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00051615, Test Loss: 0.07987528, Test Accuracy: 0.98300000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00047112, Test Loss: 0.08010838, Test Accuracy: 0.98320000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00043413, Test Loss: 0.08034970, Test Accuracy: 0.98320000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00040307, Test Loss: 0.08059281, Test Accuracy: 0.98330000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00037653, Test Loss: 0.08083381, Test Accuracy: 0.98320000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00035354, Test Loss: 0.08107046, Test Accuracy: 0.98330000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00033338, Test Loss: 0.08130166, Test Accuracy: 0.98360000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00031555, Test Loss: 0.08152670, Test Accuracy: 0.98370000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00029963, Test Loss: 0.08174544, Test Accuracy: 0.98380000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00028533, Test Loss: 0.08195786, Test Accuracy: 0.98380000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00027238, Test Loss: 0.08216404, Test Accuracy: 0.98370000\n",
            "average_sparsity: [0.6625524163246155, 0.685755729675293, 0.6817957162857056, 0.6842270493507385, 0.6836618781089783, 0.6850442290306091, 0.6854732036590576, 0.6812124848365784, 0.674326479434967, 0.6749265193939209, 0.6721328496932983, 0.6705279350280762, 0.6650121212005615, 0.6616999506950378, 0.657987117767334, 0.6556076407432556, 0.6537472605705261, 0.6523371338844299, 0.6511744260787964, 0.6501885652542114, 0.6493386626243591, 0.6485918164253235, 0.6479241847991943, 0.6473190188407898, 0.6467641592025757, 0.6462509036064148, 0.6457727551460266, 0.6453244090080261, 0.6449021697044373, 0.6445029973983765]\n",
            "final_selectivity_avg_list [0.6720214683328319, 0.6793040594642078, 0.6743560910095863, 0.6723272759787904, 0.674213462535378, 0.6739261964872232, 0.675162085928917, 0.6725123082282938, 0.6666084188099091, 0.6671318601797085, 0.6662655442469787, 0.6682126744654957, 0.6637591619709771, 0.6615154685452906, 0.6596639711978387, 0.6580829744929382, 0.6570156549390227, 0.6562360529795727, 0.6555864988260796, 0.6550340694740525, 0.654548879912183, 0.6541157922310841, 0.6537335946150546, 0.6533978750568564, 0.6530896070458352, 0.6528053169620054, 0.6525421350146996, 0.6522954048091633, 0.6520630620700378, 0.6518434042241393]\n",
            "final_selectivity_std_list [0.17373319377682633, 0.17550888709796691, 0.17450942626443885, 0.17228648954249712, 0.1765984620207311, 0.175177827534332, 0.17445755269708968, 0.17330707195008177, 0.17322471673154427, 0.17400737748064835, 0.1685127351114009, 0.16654939697795915, 0.16867326366410187, 0.1678236239108064, 0.16805863667181853, 0.16794867080449763, 0.16800273248792405, 0.16812655369524546, 0.16822189388612246, 0.16830414293800308, 0.16839064869889475, 0.1684791629284567, 0.16854810742012988, 0.16858911857978742, 0.16863044276725336, 0.16867136421164836, 0.16871155781338024, 0.16875153966482842, 0.16879126125583913, 0.1688306448546214]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQxaN_fRXLq"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkqfFoVkRXxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833ec437-24c2-40b7-957c-399b70d89244"
      },
      "source": [
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity, Adam_avg_selectivity_list, Adam_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"10subsebatch1_sparsity_selectivity_Adam.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adam_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 10subsebatch1_sparsity_selectivity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.22000796, Test Loss: 0.12123004, Test Accuracy: 0.96440000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08441207, Test Loss: 0.09946701, Test Accuracy: 0.97130000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05547416, Test Loss: 0.09768993, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03890630, Test Loss: 0.10137132, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.02981002, Test Loss: 0.11593882, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02347023, Test Loss: 0.11311009, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01906293, Test Loss: 0.12067050, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01513064, Test Loss: 0.12360103, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01387394, Test Loss: 0.12895755, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01104491, Test Loss: 0.15213060, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00962284, Test Loss: 0.16410911, Test Accuracy: 0.97200000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00757830, Test Loss: 0.14272355, Test Accuracy: 0.97690000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00745801, Test Loss: 0.14668073, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00684021, Test Loss: 0.14783177, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00606329, Test Loss: 0.14944262, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00548428, Test Loss: 0.15835553, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00517851, Test Loss: 0.15939390, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00381024, Test Loss: 0.15872186, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00389842, Test Loss: 0.16825973, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00423412, Test Loss: 0.18001065, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00337439, Test Loss: 0.16213635, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00347964, Test Loss: 0.18238164, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00282856, Test Loss: 0.17492652, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00267614, Test Loss: 0.19770540, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00267218, Test Loss: 0.19372024, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00286516, Test Loss: 0.17686204, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00259121, Test Loss: 0.20902961, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00274708, Test Loss: 0.20063182, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00220372, Test Loss: 0.18774872, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00156762, Test Loss: 0.20737481, Test Accuracy: 0.97850000\n",
            "average_sparsity: [0.5858182907104492, 0.5811434388160706, 0.5730156898498535, 0.5596439242362976, 0.5588403344154358, 0.5470924973487854, 0.5380482077598572, 0.5343039035797119, 0.5293130874633789, 0.5301787853240967, 0.5274798274040222, 0.5297929048538208, 0.5275049805641174, 0.52647864818573, 0.5270091891288757, 0.5285874009132385, 0.5301807522773743, 0.5230762958526611, 0.5180414319038391, 0.5237686038017273, 0.5232763886451721, 0.5230551958084106, 0.5251760482788086, 0.5301888585090637, 0.5288258790969849, 0.5231189727783203, 0.5247136950492859, 0.5230586528778076, 0.5236465930938721, 0.5203256607055664]\n",
            "final_selectivity_avg_list [0.7050777525422508, 0.6866506869434165, 0.6726116248889489, 0.6515095800018987, 0.6459830221283501, 0.634350280384071, 0.6217414629539617, 0.6187111257263929, 0.6105750852572916, 0.6087860754736746, 0.6072027361279915, 0.604208070379143, 0.6015483995543961, 0.597241661501471, 0.6017220206678014, 0.5962508875753185, 0.5999379995025118, 0.5944859734931158, 0.5883578753682078, 0.5917823739181203, 0.5909809403716821, 0.5872769572670202, 0.5921220964783984, 0.5963774999316431, 0.5972767437235778, 0.586881611204393, 0.5874079965603557, 0.5855299799209258, 0.5862981603730444, 0.5828742540868324]\n",
            "final_selectivity_std_list [0.17779786038010217, 0.17654586283589735, 0.1744112156163027, 0.18434119835414658, 0.17697531007801115, 0.1858832225834756, 0.18930803107346003, 0.18790476753569876, 0.19109896183903521, 0.19023570746999877, 0.18663051504810968, 0.1871509704107197, 0.18699015716957362, 0.18204746084466492, 0.18339445727808282, 0.1786086287123714, 0.18222636296012398, 0.1804620561800993, 0.17961924001636437, 0.1780030310738492, 0.17725126758208015, 0.1783460958398529, 0.17711321389115275, 0.17693097845460914, 0.17710537133079626, 0.1752749479603283, 0.17404834963175012, 0.1758550268616426, 0.17583966826578673, 0.17044297352489185]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_nabt-L_PHl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}