{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparsity_selectivity_5subsequent_batchsize1_100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/sparsity_selectivity_5subsequent_batchsize1_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7STrWa0P3z_",
        "outputId": "c7ac1921-b0b5-45e4-b251-0b1285cd8863"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIyKF1HE7uQW",
        "outputId": "2e855bf0-8b65-4742-b32e-cc540b93771f"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "root_dir = './'\n",
        "torchvision.datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-18 21:10:13--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-18 21:10:13--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.5’\n",
            "\n",
            "MNIST.tar.gz.5          [              <=>   ]  33.20M  10.1MB/s    in 4.0s    \n",
            "\n",
            "2021-03-18 21:10:17 (8.29 MB/s) - ‘MNIST.tar.gz.5’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4j9WoP-UnAm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApOU7hvb95W4"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = torchvision.datasets.MNIST(root=root_dir, train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = torchvision.datasets.MNIST(root=root_dir, \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow9Sy2SyUYgn"
      },
      "source": [
        "new_mnist_trainset =  [ [[],[]] for i in range(10)]\n",
        "# new_mnist_testset  =  [ [[],[]] for i in range(10)]\n",
        "\n",
        "for i in range(60000):\n",
        "    for j in range(10):\n",
        "        # 만약에 label 이 j 이면, \n",
        "        if mnist_trainset[i][1] == j:\n",
        "            # image \n",
        "            new_mnist_trainset[j][0].append(mnist_trainset[i][0])  \n",
        "            # new_mnist_trainset[j][0] 는 j label 에 해당하는 image 가 들어있다. \n",
        "\n",
        "            # label\n",
        "            new_mnist_trainset[j][1].append(mnist_trainset[i][1])\n",
        "            # new_mnist_trainset[j][1] 는 j label 에 해당하는 label 가 들어있다. \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyIkUPYTNdLf",
        "outputId": "6a1d92f6-1be2-40de-b012-1dc947734f1d"
      },
      "source": [
        "print(\"0\", len(new_mnist_trainset[0][0]))    # - pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][0]))    # - pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][0]))    # - pop 3 times\n",
        "print(\"3\", len(new_mnist_trainset[3][0]))    # - pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][0]))    # - pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][0]))    # - pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][0]))    # - pop 3 times\n",
        "print(\"7\", len(new_mnist_trainset[7][0]))    # - pop 0 times\n",
        "print(\"8\", len(new_mnist_trainset[8][0]))    # - pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][0]))    # - pop 4 times"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5923\n",
            "1 6742\n",
            "2 5958\n",
            "3 6131\n",
            "4 5842\n",
            "5 5421\n",
            "6 5918\n",
            "7 6265\n",
            "8 5851\n",
            "9 5949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieTyNQeWP1Sb"
      },
      "source": [
        "# 0 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[0][0].pop()\n",
        "    new_mnist_trainset[0][1].pop()\n",
        "\n",
        "# 1 - pop 2 times\n",
        "for i in range(2):\n",
        "    new_mnist_trainset[1][0].pop()\n",
        "    new_mnist_trainset[1][1].pop()\n",
        "\n",
        "# 2 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[2][0].pop()\n",
        "    new_mnist_trainset[2][1].pop()\n",
        "\n",
        "# 3 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[3][0].pop()\n",
        "    new_mnist_trainset[3][1].pop()\n",
        "\n",
        "# 4 - pop 2 time\n",
        "for i in range(2):\n",
        "    new_mnist_trainset[4][0].pop()\n",
        "    new_mnist_trainset[4][1].pop()\n",
        "\n",
        "# 5 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[5][0].pop()\n",
        "    new_mnist_trainset[5][1].pop()\n",
        "\n",
        "# 6 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[6][0].pop()\n",
        "    new_mnist_trainset[6][1].pop()\n",
        "\n",
        "# 7 - pop 0 times\n",
        "\n",
        "# 8 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[8][0].pop()\n",
        "    new_mnist_trainset[8][1].pop()\n",
        "\n",
        "# 9 - pop 4 times\n",
        "for i in range(4):\n",
        "    new_mnist_trainset[9][0].pop()\n",
        "    new_mnist_trainset[9][1].pop()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSb6f78RQYGp",
        "outputId": "19a68a73-1f90-4109-94e7-76b76b4804ae"
      },
      "source": [
        "print(\"0\", len(new_mnist_trainset[0][0]))    # pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][0]))    # pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][0]))    # pop 3 times\n",
        "print(\"3\", len(new_mnist_trainset[3][0]))    # pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][0]))    # pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][0]))    # pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][0]))    # pop 3 times\n",
        "print(\"7\", len(new_mnist_trainset[7][0]))    # pop 0 times\n",
        "print(\"8\", len(new_mnist_trainset[8][0]))    # pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][0]))    # pop 4 times\n",
        "\n",
        "print(\"0\", len(new_mnist_trainset[0][1]))    # pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][1]))    # pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][1]))    # pop 3 times\n",
        "print(\"3\", len(new_mnist_trainset[3][1]))    # pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][1]))    # pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][1]))    # pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][1]))    # pop 3 times\n",
        "print(\"7\", len(new_mnist_trainset[7][1]))    # pop 0 times\n",
        "print(\"8\", len(new_mnist_trainset[8][1]))    # pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][1]))    # pop 4 times"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5920\n",
            "1 6740\n",
            "2 5955\n",
            "3 6130\n",
            "4 5840\n",
            "5 5420\n",
            "6 5915\n",
            "7 6265\n",
            "8 5850\n",
            "9 5945\n",
            "0 5920\n",
            "1 6740\n",
            "2 5955\n",
            "3 6130\n",
            "4 5840\n",
            "5 5420\n",
            "6 5915\n",
            "7 6265\n",
            "8 5850\n",
            "9 5945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMFpH3QLNAYQ"
      },
      "source": [
        "image_trainset = list()\n",
        "label_trainset = list()\n",
        "\n",
        "for i in range(10):\n",
        "    image_trainset.append(new_mnist_trainset[i][0])\n",
        "    label_trainset.append(new_mnist_trainset[i][1])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV9vZ4G_NCTB"
      },
      "source": [
        "flattened_image_train = list()\n",
        "flattened_label_train = list()\n",
        "\n",
        "# flattening image \n",
        "for sublist in image_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_image_train.append(val)\n",
        "\n",
        "# flattening label\n",
        "for sublist in label_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_label_train.append(val)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q_z0dBzSR5o",
        "outputId": "01337fda-648f-4900-b1af-d3f9ea4d9913"
      },
      "source": [
        "len(flattened_image_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onYs9h2CTj41",
        "outputId": "126e0083-db9a-4f23-af1b-43f799032ff8"
      },
      "source": [
        "len(flattened_label_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbZTrSWrYkkG"
      },
      "source": [
        "def split(a, n):\n",
        "    k, m = divmod(len(a), n)\n",
        "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFctZ-9EYlgx"
      },
      "source": [
        "list1 = list(split(flattened_image_train, 11996))\n",
        "list2 = list(split(flattened_label_train, 11996))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlqM-hF2ZuV2"
      },
      "source": [
        "X, y = shuffle(list1, list2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTF5pJPZypH"
      },
      "source": [
        "X_final, y_final = shuffle(X, y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimwHtbgaEtX"
      },
      "source": [
        "flattened_X_final = [val for sublist in X_final for val in sublist] \n",
        "flattened_y_final = [val for sublist in y_final for val in sublist] "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Xxbuxud6djJF",
        "outputId": "43911a37-2fb9-44ac-ad6e-c2f2711cfd82"
      },
      "source": [
        "plt.imshow(flattened_X_final[0].reshape(28,28))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb51f3c6190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SkccxZdNEDY"
      },
      "source": [
        "flattened_image_train = torch.stack(flattened_X_final)\n",
        "flattened_label_train = torch.Tensor(flattened_y_final)\n",
        "flattened_label_train = flattened_label_train.type(torch.LongTensor)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cANEC2zaNFPq"
      },
      "source": [
        "train_dataset = TensorDataset(flattened_image_train, flattened_label_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAD1thJ5JvD"
      },
      "source": [
        "def selectivity(hidden_layer_each_neuron):\n",
        "    __selectivity__ = list()\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(256)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 256 lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(256)]\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity\n",
        "        __selectivity__.append(selectivity)\n",
        "\n",
        "    avg_selectivity = np.average(__selectivity__)\n",
        "    std_selectivity = np.std(__selectivity__)\n",
        "                                 \n",
        "    return avg_selectivity, std_selectivity"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9kATNPUz1cA"
      },
      "source": [
        "def sparsity_calculator(final_spareness):\n",
        "    sparseness_list = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 30\n",
        "def selectivity_trainer(optimizer, model):\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "\n",
        "    final_spareness = list()\n",
        "    \n",
        "    final_selectivity_avg_list = list()\n",
        "    final_selectivity_std_list = list()\n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        _hidden_layer_each_neuron_ = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
        "        _hidden_layer_each_neuron_ = np.array(_hidden_layer_each_neuron_)\n",
        "\n",
        "        hidden_layer_activation_list = list()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, labels) in enumerate(train_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print/Append activation of the hidden layer \n",
        "            # print(model.layer_activations.shape)\n",
        "            # model.layer_activations\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            hidden_layer_activation_list.append(model.layer_activations)\n",
        "\n",
        "            \n",
        "            for activation, label in zip(model.layer_activations, labels):\n",
        "                # shape of activation and label: 256 and 1 \n",
        "                \n",
        "                # get the actual value of item. This is because label is now Tensor \n",
        "                label = label.item()\n",
        "\n",
        "                # this is not part of gradient calculcation \n",
        "                with torch.no_grad():\n",
        "                    activation = activation.numpy()\n",
        "\n",
        "                # for each image/label, append activation value of neuron \n",
        "                for i in range(256):    # number of neurons in hidden layer \n",
        "                    _hidden_layer_each_neuron_[i][label].append(activation[i])\n",
        "\n",
        "        avg_selectivity, std_selectivity = selectivity(_hidden_layer_each_neuron_)\n",
        "        \n",
        "        final_selectivity_avg_list.append(avg_selectivity)\n",
        "        final_selectivity_std_list.append(std_selectivity)\n",
        "\n",
        "        final_spareness.append(hidden_layer_activation_list)\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "    sparsity_list = sparsity_calculator(final_spareness)\n",
        "\n",
        "    average_sparsity = list()\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    print(\"average_sparsity:\", average_sparsity)\n",
        "    print(\"final_selectivity_avg_list\", final_selectivity_avg_list)\n",
        "    print(\"final_selectivity_std_list\", final_selectivity_std_list)\n",
        "\n",
        "    return test_acc, average_sparsity, final_selectivity_avg_list, final_selectivity_std_list"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# AdaDelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WytqcJRZxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7e3c7f-f8fa-4860-c498-8df058363d9d"
      },
      "source": [
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"5subsebatch1_sparsity_selectivity_Adadelta.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adadelta_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 5subsebatch1_sparsity_selectivity_Adadelta.txt /content/drive/MyDrive"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.29825945, Test Loss: 0.20366133, Test Accuracy: 0.94710000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.17693068, Test Loss: 0.14983820, Test Accuracy: 0.96120000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.13501798, Test Loss: 0.12808828, Test Accuracy: 0.96740000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.11267106, Test Loss: 0.11536485, Test Accuracy: 0.97210000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.09741921, Test Loss: 0.10952215, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.08676421, Test Loss: 0.10683517, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.07893250, Test Loss: 0.10634585, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.07267470, Test Loss: 0.10610281, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.06751109, Test Loss: 0.10746591, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.06253652, Test Loss: 0.10802610, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.05809694, Test Loss: 0.10748790, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.05450023, Test Loss: 0.10743239, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.05133723, Test Loss: 0.10929788, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.04873744, Test Loss: 0.11155047, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.04663382, Test Loss: 0.11600097, Test Accuracy: 0.97500000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.04469767, Test Loss: 0.11925155, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.04283337, Test Loss: 0.11974808, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.04142310, Test Loss: 0.11972664, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.03984250, Test Loss: 0.11941142, Test Accuracy: 0.97360000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.03844481, Test Loss: 0.11908616, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.03722554, Test Loss: 0.11908564, Test Accuracy: 0.97310000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.03607213, Test Loss: 0.11889246, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.03490367, Test Loss: 0.11879754, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.03371598, Test Loss: 0.11859670, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.03239539, Test Loss: 0.11913324, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.03123667, Test Loss: 0.11937322, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.03015763, Test Loss: 0.12034121, Test Accuracy: 0.97510000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.02894493, Test Loss: 0.12184805, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.02784151, Test Loss: 0.12287294, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.02678378, Test Loss: 0.12484636, Test Accuracy: 0.97470000\n",
            "average_sparsity: [0.30813339352607727, 0.30991294980049133, 0.3101643919944763, 0.31461426615715027, 0.31110936403274536, 0.30858883261680603, 0.3080710172653198, 0.3086763918399811, 0.3089123070240021, 0.30705469846725464, 0.3052397072315216, 0.30399495363235474, 0.30229058861732483, 0.3006335198879242, 0.29885390400886536, 0.2983897626399994, 0.29804834723472595, 0.29693686962127686, 0.29568448662757874, 0.2953718900680542, 0.2956709861755371, 0.2963762581348419, 0.2962333858013153, 0.29553166031837463, 0.2952743172645569, 0.2944014072418213, 0.2943984866142273, 0.29397615790367126, 0.29370352625846863, 0.29351019859313965]\n",
            "final_selectivity_avg_list [0.43291894455216795, 0.416357458976758, 0.4092817126914703, 0.4080674165607936, 0.40143624044899284, 0.39601743817750534, 0.39279232434180134, 0.39053142687155584, 0.3875103225944371, 0.382906989039945, 0.3784595103211188, 0.3741551070300465, 0.3702139301974837, 0.36700535511932675, 0.36342463944430503, 0.3613489147223322, 0.35977621853232145, 0.3569624710307605, 0.3550602037615068, 0.35372409923267056, 0.35317403147164406, 0.3525889566476301, 0.35207186304926397, 0.35049866214901265, 0.3494896469585389, 0.347897642678328, 0.3470169269959079, 0.3456719243204895, 0.344405021969191, 0.3434638558232571]\n",
            "final_selectivity_std_list [0.26517549118520195, 0.2695800624244239, 0.2685405006109725, 0.267140889474043, 0.2627391522696156, 0.2590005249849907, 0.2551916990864099, 0.25221929526796505, 0.2481358902415417, 0.2441210638974542, 0.2406330400622793, 0.23750123698417247, 0.23484604909209347, 0.23340048228852425, 0.23171152058030825, 0.22974398829386766, 0.22853396480897378, 0.226832493239117, 0.2253247638766964, 0.2235719119398522, 0.22198928598150108, 0.22038932134217243, 0.21915933066903656, 0.21790537316041625, 0.21693525442768227, 0.21572213933471487, 0.21471357824053985, 0.2136577229461481, 0.21244857341160145, 0.211430900416993]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXfQe4vMDKB"
      },
      "source": [
        "# AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb-4TPM5MGuE",
        "outputId": "cc36327d-c36b-4c7d-a1cd-711cfc685147"
      },
      "source": [
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"5subsebatch1_sparsity_selectivity_Adagrad.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adagrad_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 5subsebatch1_sparsity_selectivity_Adagrad.txt /content/drive/MyDrive"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.17935940, Test Loss: 0.11117525, Test Accuracy: 0.96610000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08131651, Test Loss: 0.09391907, Test Accuracy: 0.97060000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05574391, Test Loss: 0.08705109, Test Accuracy: 0.97350000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.04164102, Test Loss: 0.08299458, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03220011, Test Loss: 0.08043555, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02542397, Test Loss: 0.07833662, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.02043892, Test Loss: 0.07650568, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01665292, Test Loss: 0.07552760, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01373095, Test Loss: 0.07486425, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01141040, Test Loss: 0.07439799, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00956150, Test Loss: 0.07423756, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00808603, Test Loss: 0.07429751, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00691536, Test Loss: 0.07449953, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00597633, Test Loss: 0.07478032, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00521530, Test Loss: 0.07505555, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00458131, Test Loss: 0.07532800, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00406835, Test Loss: 0.07558356, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00364196, Test Loss: 0.07576761, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00327950, Test Loss: 0.07599352, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00297364, Test Loss: 0.07623210, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00271746, Test Loss: 0.07642983, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00249423, Test Loss: 0.07652567, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00229858, Test Loss: 0.07663861, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00212413, Test Loss: 0.07680368, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00197018, Test Loss: 0.07700309, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00183528, Test Loss: 0.07722887, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00171593, Test Loss: 0.07750130, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00161118, Test Loss: 0.07775757, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00151789, Test Loss: 0.07799219, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00143396, Test Loss: 0.07821735, Test Accuracy: 0.98010000\n",
            "average_sparsity: [0.5568237900733948, 0.5490918159484863, 0.545552670955658, 0.5415326356887817, 0.5370479822158813, 0.5343859195709229, 0.530925989151001, 0.5291064381599426, 0.5272221565246582, 0.5247236490249634, 0.5239291191101074, 0.5229020714759827, 0.5219681859016418, 0.5210313200950623, 0.5201506614685059, 0.5193215012550354, 0.5185917615890503, 0.5179319381713867, 0.5172455310821533, 0.5167337656021118, 0.5162846446037292, 0.5158886909484863, 0.5154295563697815, 0.5149823427200317, 0.5145877599716187, 0.5142221450805664, 0.5139164924621582, 0.5136394500732422, 0.5133671164512634, 0.5130810737609863]\n",
            "final_selectivity_avg_list [0.6720584837715333, 0.6620021544248562, 0.656962540338253, 0.6494547341291247, 0.6363736210059918, 0.6309839110925615, 0.6246396464678585, 0.6186563944776109, 0.6134226417237758, 0.609673081396984, 0.6073207141605146, 0.6056941326650644, 0.6035121127934353, 0.6009979658089339, 0.5990258384142952, 0.5969973659452663, 0.5961547022071908, 0.596248740687003, 0.5954634927645885, 0.5952355495172068, 0.5943640971452318, 0.5936179015526095, 0.5927651840574593, 0.5920567868873976, 0.5918103925238162, 0.5919729248328408, 0.5921198931316937, 0.5922454911891494, 0.5921290035353598, 0.5917468526053383]\n",
            "final_selectivity_std_list [0.27888073097570515, 0.27815873740816627, 0.2765749642716453, 0.2748736613776731, 0.2675238660960232, 0.2643559784339665, 0.2601725676822604, 0.2568481763854639, 0.25419715619022587, 0.2526716384853272, 0.2514575778612212, 0.2512941414199034, 0.25134694639404126, 0.25027522526213564, 0.24886249635954308, 0.24723407455873275, 0.24702332848441308, 0.2472450939936605, 0.24703597453902992, 0.2473471772642374, 0.2471838702247272, 0.24700642140604975, 0.24689068867238984, 0.24721685463630896, 0.24753017459408938, 0.24736460425822726, 0.24697865210972758, 0.2466616232570177, 0.2462568181473258, 0.24577438846077923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLJ4Zr2MnoS"
      },
      "source": [
        "# SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ObsEJHuMoPy",
        "outputId": "c3aa957e-90d2-45ad-aba3-01bfb370b8ed"
      },
      "source": [
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity, SGD_avg_selectivity_list, SGD_std_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"5subsebatch1_sparsity_selectivity_SGD.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(SGD_test_acc)+'\\n'+str(sparsity)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 5subsebatch1_sparsity_selectivity_SGD.txt /content/drive/MyDrive"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.21627105, Test Loss: 0.10921069, Test Accuracy: 0.96850000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.09806698, Test Loss: 0.08991250, Test Accuracy: 0.97350000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.06651983, Test Loss: 0.08476396, Test Accuracy: 0.97550000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.04642687, Test Loss: 0.08464550, Test Accuracy: 0.97690000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03344684, Test Loss: 0.08271597, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02602826, Test Loss: 0.09183130, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01897387, Test Loss: 0.08585440, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01443289, Test Loss: 0.08252837, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01026473, Test Loss: 0.08752683, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00792084, Test Loss: 0.08651278, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00590201, Test Loss: 0.08262913, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00374385, Test Loss: 0.08297429, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00258570, Test Loss: 0.08280715, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00178255, Test Loss: 0.08158563, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00115150, Test Loss: 0.08415642, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00083162, Test Loss: 0.08363611, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00069022, Test Loss: 0.08365923, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00060141, Test Loss: 0.08388305, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00053629, Test Loss: 0.08415960, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00048599, Test Loss: 0.08444456, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00044569, Test Loss: 0.08472996, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00041243, Test Loss: 0.08501238, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00038436, Test Loss: 0.08528935, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00036026, Test Loss: 0.08555950, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00033927, Test Loss: 0.08582213, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00032078, Test Loss: 0.08607718, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00030435, Test Loss: 0.08632468, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00028962, Test Loss: 0.08656487, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00027633, Test Loss: 0.08679809, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00026427, Test Loss: 0.08702460, Test Accuracy: 0.98060000\n",
            "average_sparsity: [0.671735942363739, 0.6925998330116272, 0.6900004148483276, 0.6886395812034607, 0.6892728209495544, 0.6810291409492493, 0.6827375888824463, 0.6852774024009705, 0.6830529570579529, 0.6809093356132507, 0.6786246299743652, 0.6730555891990662, 0.6719457507133484, 0.6686238050460815, 0.6639658212661743, 0.6615423560142517, 0.6597266793251038, 0.6582903265953064, 0.6570835113525391, 0.6560389399528503, 0.6551191210746765, 0.6542987823486328, 0.6535587310791016, 0.6528845429420471, 0.6522653698921204, 0.6516925096511841, 0.6511591076850891, 0.6506598591804504, 0.6501903533935547, 0.6497470736503601]\n",
            "final_selectivity_avg_list [0.6794855865888431, 0.6893043010911681, 0.6842672507516829, 0.6827039399238752, 0.6848157748774475, 0.6805457450706296, 0.6777637413219986, 0.6781134759538778, 0.6745375144025506, 0.6753460822381514, 0.6719341064700777, 0.6680798669326934, 0.6676428190472183, 0.6640869160320552, 0.6624384784239629, 0.6612261176080476, 0.6603434630103063, 0.6596484251173722, 0.6590749678213559, 0.6585658086366839, 0.6581090659426586, 0.657696100135034, 0.6573244777967919, 0.6569813919350674, 0.6566632473999873, 0.6563665050485918, 0.6560876640531262, 0.6558257390332685, 0.6555805232845077, 0.6553472781538479]\n",
            "final_selectivity_std_list [0.16198609998526844, 0.1596363505065383, 0.1632981072998685, 0.16292854852614325, 0.15828599796939927, 0.16064738431125516, 0.16281267891694698, 0.16084777422618615, 0.1615885667366942, 0.16179525311443857, 0.16256765451538183, 0.1622044584921173, 0.16209604300458566, 0.16273226350871356, 0.16312082369536984, 0.1634320175799445, 0.16361120934058337, 0.16378990718556452, 0.16390970348104156, 0.1640334158674326, 0.16415406367455418, 0.16427307741372354, 0.16439067493091902, 0.16450720174241884, 0.16462189366074229, 0.16473459978550561, 0.16484583910212694, 0.164953852824057, 0.1650562749580221, 0.16515774025823013]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQxaN_fRXLq"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkqfFoVkRXxP",
        "outputId": "99a49373-f1b0-436a-b2da-38c5c593c0dd"
      },
      "source": [
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity, Adam_avg_selectivity_list, Adam_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"5subsebatch1_sparsity_selectivity_Adam.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adam_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp 5subsebatch1_sparsity_selectivity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.21171964, Test Loss: 0.10101405, Test Accuracy: 0.96830000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08311948, Test Loss: 0.09662634, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05546506, Test Loss: 0.09662401, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03982864, Test Loss: 0.10328956, Test Accuracy: 0.97230000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03012122, Test Loss: 0.10547647, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02338557, Test Loss: 0.11102806, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01835492, Test Loss: 0.11569699, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01615421, Test Loss: 0.13190317, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01369344, Test Loss: 0.12927530, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01098321, Test Loss: 0.11971552, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00952672, Test Loss: 0.12172167, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00778807, Test Loss: 0.11845985, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00661903, Test Loss: 0.14426979, Test Accuracy: 0.97710000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00683677, Test Loss: 0.15483082, Test Accuracy: 0.97710000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00625866, Test Loss: 0.16261166, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00637718, Test Loss: 0.15199126, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00504728, Test Loss: 0.14532454, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00389492, Test Loss: 0.16171117, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00441676, Test Loss: 0.16377246, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00409551, Test Loss: 0.14837301, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00365433, Test Loss: 0.14976686, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00379808, Test Loss: 0.15916669, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00236492, Test Loss: 0.18061155, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00280663, Test Loss: 0.19358152, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00264510, Test Loss: 0.18908390, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00368518, Test Loss: 0.18742611, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00286353, Test Loss: 0.17838766, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00231116, Test Loss: 0.19463670, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00237087, Test Loss: 0.17855834, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00262034, Test Loss: 0.19400295, Test Accuracy: 0.97790000\n",
            "average_sparsity: [0.540780246257782, 0.550258994102478, 0.5495402216911316, 0.5463443398475647, 0.5390356183052063, 0.5359255075454712, 0.541374683380127, 0.528893232345581, 0.5278464555740356, 0.5315057039260864, 0.5334621071815491, 0.5285508036613464, 0.5247024297714233, 0.5264758467674255, 0.5273343920707703, 0.5248911380767822, 0.5330974459648132, 0.5232453346252441, 0.5227822065353394, 0.5232707858085632, 0.5211467146873474, 0.5319715738296509, 0.5282163023948669, 0.5210890769958496, 0.5273268818855286, 0.5258442163467407, 0.5168820023536682, 0.5219870209693909, 0.5249298214912415, 0.5254029035568237]\n",
            "final_selectivity_avg_list [0.6552516072642334, 0.6471985331109038, 0.6377294487382799, 0.6300682997465055, 0.620608331721838, 0.6147314746018767, 0.6136354084745748, 0.6047717969638169, 0.5990648662498574, 0.6017542689752111, 0.5998547502757482, 0.5974049619137828, 0.592195778661555, 0.5894676030098672, 0.5907708958895281, 0.5841877369777501, 0.5946364353292835, 0.5831627634575032, 0.5822488161995458, 0.5779922062531954, 0.5797523753565882, 0.5879556064541976, 0.5839682731253377, 0.5781315215644482, 0.5783162328975555, 0.5794578082062777, 0.5742594088189532, 0.5791985520845258, 0.5809462269814447, 0.5775802733744941]\n",
            "final_selectivity_std_list [0.17802547515247058, 0.17806499215883226, 0.17231672217210278, 0.174256777410492, 0.17785293425024534, 0.17673378651471916, 0.17259583696735759, 0.17898869451228616, 0.17721474233003015, 0.17264133248004815, 0.16572428340453565, 0.17524490202581255, 0.17273061632451364, 0.17175374684551054, 0.17301072680934038, 0.16856060042973364, 0.1642825644071516, 0.16740318736201826, 0.1707507150823773, 0.1683450654196553, 0.17065219134039836, 0.170996745556474, 0.167902761003288, 0.16223092052616933, 0.1633952644108924, 0.16594953040588833, 0.1656935036039426, 0.16991584402197582, 0.16976144949715363, 0.16676437274652192]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_nabt-L_PHl"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}