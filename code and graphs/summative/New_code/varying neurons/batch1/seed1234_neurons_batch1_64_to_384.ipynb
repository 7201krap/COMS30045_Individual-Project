{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seed1234_neurons_batch1_64_to_384.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/seed1234_neurons_batch1_64_to_384.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7STrWa0P3z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae850611-327f-4f55-d77f-bd3d48ddbb49"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4j9WoP-UnAm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = torchvision.datasets.MNIST(root='./', train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = torchvision.datasets.MNIST(root='./', \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, \n",
        "                                               batch_size=1, \n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# ************* modify this section for later use *************\n",
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, neuron_size):\n",
        "        super(Model, self).__init__()\n",
        "        # modify this section for later use \n",
        "        self.linear_1 = torch.nn.Linear(784, neuron_size)\n",
        "        self.linear_2 = torch.nn.Linear(neuron_size, 10)\n",
        "        self.sigmoid12  = torch.nn.Sigmoid()\n",
        "\n",
        "        self.layer_activations = dict()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # modify this section for later use \n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid12(x)\n",
        "        pred = self.linear_2(x)\n",
        "        return pred\n",
        "# ************* modify this section for later use *************"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model, layer_name):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations[layer_name] = output\n",
        "    return hook"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCEw3Ov3Lk5X"
      },
      "source": [
        "def sparsity_calculator(final_spareness, neuron_size):\n",
        "    sparseness_list_avg = list()\n",
        "    sparseness_list_std = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, neuron_size))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "        std_sparseness_per_epoch  = torch.std(population_sparseness)\n",
        "\n",
        "        sparseness_list_avg.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list_avg"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvHGO5RSvi6I"
      },
      "source": [
        "def selectivity(hidden_layer_each_neuron, neuron_size):\n",
        "    __selectivity__ = list()\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(neuron_size)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 'neuron_size' lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(neuron_size)]\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity\n",
        "        __selectivity__.append(selectivity)\n",
        "\n",
        "    avg_selectivity = np.average(__selectivity__)\n",
        "    std_selectivity = np.std(__selectivity__)\n",
        "                                 \n",
        "    return avg_selectivity, std_selectivity"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUHSwHZqLm3Y"
      },
      "source": [
        "# ************* modify this section for later use *************\n",
        "def avg_std_calculator(_hidden_layer_each_neuron_12, neuron_size):\n",
        "\n",
        "    avg_selectivity12, std_selectivity12 = selectivity(_hidden_layer_each_neuron_12, neuron_size)\n",
        "\n",
        "    final_selectivity_avg = (avg_selectivity12) / 1\n",
        "    final_selecvitity_std = (std_selectivity12) / 1\n",
        "\n",
        "    return final_selectivity_avg, final_selecvitity_std\n",
        "# ************* modify this section for later use *************"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5PUiBNqUImf"
      },
      "source": [
        "def model_factory(optimizer_name, seed_num, neuron_size):\n",
        "    '''\n",
        "    optimizer_name : choose one of Adagrad, Adadelta, SGD, and Adam \n",
        "\n",
        "    '''\n",
        "    my_model = Model(neuron_size)\n",
        "    print(\"my_model:\", my_model)\n",
        "    my_model.to(device)\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    my_model.sigmoid12.register_forward_hook(get_activation(my_model, 's12'))\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    if optimizer_name == 'Adadelta':\n",
        "        my_optimizer = torch.optim.Adadelta(my_model.parameters(), lr=1.0)\n",
        "\n",
        "    elif optimizer_name == 'Adagrad':\n",
        "        my_optimizer = torch.optim.Adagrad(my_model.parameters(), lr=0.1)\n",
        "\n",
        "    elif optimizer_name == 'SGD':\n",
        "        my_optimizer = torch.optim.SGD(my_model.parameters(), lr=0.1)\n",
        "\n",
        "    elif optimizer_name == 'Adam':\n",
        "        my_optimizer = torch.optim.Adam(my_model.parameters(), lr=0.001)\n",
        "\n",
        "    else:\n",
        "        print(\"ERROR\")\n",
        "    \n",
        "    print(\"my_optimizer:\", my_optimizer)\n",
        "    test_acc, sparsity_avg, selectivity_list_avg, selectivity_list_std = sparsity_selectivity_trainer(optimizer=my_optimizer, model=my_model, neuron_size=neuron_size)\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    file_saver = open(f\"seed{seed_num}_batch1_neuronsize{neuron_size}_{optimizer_name}.txt\", \"w\")\n",
        "    # ************* modify this section for later use *************\n",
        "    file_saver.write(str(test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(selectivity_list_avg)+'\\n'+str(selectivity_list_std)+'\\n\\n')\n",
        "    file_saver.close()\n",
        "\n",
        "    if seed_num == 1:\n",
        "        if neuron_size == 64:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize64_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize64_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize64_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize64_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 128:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize128_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize128_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize128_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize128_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 256:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize256_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize256_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize256_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize256_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 384:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize384_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize384_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize384_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize384_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 512:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize512_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize512_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize512_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize512_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 640:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize640_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize640_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize640_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize640_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 768:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1_batch1_neuronsize768_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1_batch1_neuronsize768_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1_batch1_neuronsize768_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1_batch1_neuronsize768_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "    elif seed_num == 100:\n",
        "        if neuron_size == 64:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize64_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize64_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize64_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize64_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 128:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize128_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize128_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize128_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize128_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 256:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize256_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize256_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize256_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize256_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 384:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize384_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize384_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize384_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize384_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 512:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize512_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize512_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize512_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize512_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 640:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize640_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize640_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize640_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize640_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 768:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed100_batch1_neuronsize768_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed100_batch1_neuronsize768_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed100_batch1_neuronsize768_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed100_batch1_neuronsize768_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "    # seed 1234\n",
        "    elif seed_num == 1234:\n",
        "        if neuron_size == 64:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize64_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize64_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize64_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize64_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 128:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize128_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize128_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize128_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize128_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 256:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize256_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize256_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize256_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize256_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 384:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize384_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize384_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize384_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize384_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 512:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize512_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize512_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize512_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize512_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 640:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize640_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize640_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize640_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize640_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************\n",
        "\n",
        "        elif neuron_size == 768:\n",
        "            # ************* modify this section for later use *************\n",
        "            if optimizer_name == 'Adadelta':\n",
        "                !cp seed1234_batch1_neuronsize768_Adadelta.txt /content/drive/MyDrive\n",
        "            \n",
        "            elif optimizer_name == 'Adagrad':\n",
        "                !cp seed1234_batch1_neuronsize768_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'SGD':\n",
        "                !cp seed1234_batch1_neuronsize768_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "            elif optimizer_name == 'Adam':\n",
        "                !cp seed1234_batch1_neuronsize768_Adam.txt /content/drive/MyDrive\n",
        "            # ************* modify this section for later use *************"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 30\n",
        "def sparsity_selectivity_trainer(optimizer, model, neuron_size):\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    test_acc   = list()\n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    selectivity_avg_list = list()\n",
        "    selectivity_std_list = list()\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    final_spareness_12 = list()\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        # ************* modify this section for later use *************\n",
        "        hidden_layer_each_neuron_12 = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(neuron_size)]\n",
        "        hidden_layer_each_neuron_12 = np.array(hidden_layer_each_neuron_12)\n",
        "        # ************* modify this section for later use *************\n",
        "\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # ************* modify this section for later use *************\n",
        "        hidden_layer_activation_list_12 = list()\n",
        "        # ************* modify this section for later use *************\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, labels) in enumerate(train_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            # ***************** sparsity calculation ***************** #\n",
        "            hidden_layer_activation_list_12.append(model.layer_activations['s12'])\n",
        "\n",
        "            # ************* modify this section for later use *************\n",
        "            for activation, label in zip(model.layer_activations['s12'], labels):\n",
        "                label = label.item()\n",
        "                with torch.no_grad():\n",
        "                    activation = activation.numpy()\n",
        "                for i in range(neuron_size):    \n",
        "                    hidden_layer_each_neuron_12[i][label].append(activation[i])\n",
        "    \n",
        "        selectivity_avg, selecvitity_std = avg_std_calculator(hidden_layer_each_neuron_12, neuron_size)\n",
        "        # ************* modify this section for later use *************\n",
        "        \n",
        "        selectivity_avg_list.append(selectivity_avg)\n",
        "        selectivity_std_list.append(selecvitity_std)\n",
        "\n",
        "        # this conains activations for all epochs \n",
        "        final_spareness_12.append(hidden_layer_activation_list_12)\n",
        "        # ***************** sparsity calculation ***************** #\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "    sparsity_list12_avg = sparsity_calculator(final_spareness_12, neuron_size)\n",
        "\n",
        "    average_sparsity = list()\n",
        "\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list12_avg[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    return test_acc, average_sparsity, selectivity_avg_list, selectivity_std_list"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mij96WW5XU2J"
      },
      "source": [
        "# Seed 1234 \n",
        "\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnE6Osc4o-yt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1857c0dd-0e39-493d-a516-4cf2636c29ea"
      },
      "source": [
        "\n",
        "\n",
        "# 64 neurons \n",
        "model_factory('Adadelta', 1234, 64)\n",
        "model_factory('Adagrad', 1234, 64)\n",
        "model_factory('SGD', 1234, 64)\n",
        "model_factory('Adam', 1234, 64)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (linear_2): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-06\n",
            "    lr: 1.0\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 19509.33179794, Test Loss: 46.73631245, Test Accuracy: 0.94070000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 13253.01882433, Test Loss: 38.45893130, Test Accuracy: 0.95030000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 10946.36862841, Test Loss: 33.72769400, Test Accuracy: 0.95840000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 9660.02711802, Test Loss: 31.75145441, Test Accuracy: 0.95940000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 8882.56415675, Test Loss: 29.74532770, Test Accuracy: 0.96430000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 8274.65386416, Test Loss: 30.00654842, Test Accuracy: 0.96260000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 7782.90821147, Test Loss: 30.88553090, Test Accuracy: 0.96440000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 7509.84837562, Test Loss: 29.33320836, Test Accuracy: 0.96790000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 7303.12065051, Test Loss: 29.01794415, Test Accuracy: 0.96680000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 7048.51672346, Test Loss: 28.52176449, Test Accuracy: 0.96870000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 6852.07338510, Test Loss: 28.75664040, Test Accuracy: 0.96860000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 6655.10967412, Test Loss: 27.93059589, Test Accuracy: 0.96920000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 6549.16947275, Test Loss: 29.19672797, Test Accuracy: 0.96990000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 6352.76402792, Test Loss: 30.38503792, Test Accuracy: 0.96970000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 6191.92213324, Test Loss: 29.69487741, Test Accuracy: 0.96960000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 6033.27733499, Test Loss: 29.76039615, Test Accuracy: 0.97050000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 6144.17980607, Test Loss: 29.48976706, Test Accuracy: 0.97010000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 5963.63657717, Test Loss: 32.19821284, Test Accuracy: 0.96820000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 5822.11625308, Test Loss: 31.10981035, Test Accuracy: 0.97000000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 5710.84954082, Test Loss: 30.59920394, Test Accuracy: 0.97050000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 5695.00808052, Test Loss: 29.34622342, Test Accuracy: 0.97060000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 5598.52559085, Test Loss: 32.20440359, Test Accuracy: 0.96990000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 5593.03194772, Test Loss: 30.83790184, Test Accuracy: 0.96970000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 5433.82338969, Test Loss: 31.52822698, Test Accuracy: 0.96800000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 5387.63341962, Test Loss: 30.62299040, Test Accuracy: 0.96970000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 5424.26445613, Test Loss: 30.86797015, Test Accuracy: 0.97000000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 5355.15903608, Test Loss: 32.57414367, Test Accuracy: 0.97060000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 5268.67419929, Test Loss: 30.26880513, Test Accuracy: 0.97140000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 5240.21776393, Test Loss: 32.35356953, Test Accuracy: 0.97170000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 5212.23884514, Test Loss: 31.37966419, Test Accuracy: 0.97030000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (linear_2): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.1\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 13432.30760808, Test Loss: 31.98123122, Test Accuracy: 0.95230000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 7466.76239354, Test Loss: 25.60412030, Test Accuracy: 0.96250000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 5890.75034924, Test Loss: 23.17594327, Test Accuracy: 0.96530000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 4939.54710183, Test Loss: 21.89377758, Test Accuracy: 0.96750000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 4297.75490578, Test Loss: 21.12469610, Test Accuracy: 0.96790000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 3786.94418659, Test Loss: 20.18585078, Test Accuracy: 0.96990000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 3419.82070564, Test Loss: 19.68170511, Test Accuracy: 0.96920000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 3109.39462665, Test Loss: 19.80933674, Test Accuracy: 0.96890000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 2844.36255720, Test Loss: 19.28833344, Test Accuracy: 0.97050000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 2629.46750290, Test Loss: 18.93622775, Test Accuracy: 0.97080000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 2447.53905671, Test Loss: 19.02309390, Test Accuracy: 0.97030000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 2280.57429800, Test Loss: 18.61800126, Test Accuracy: 0.97140000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 2129.69276993, Test Loss: 18.42935939, Test Accuracy: 0.97120000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 2004.26547432, Test Loss: 18.59309632, Test Accuracy: 0.97180000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 1883.38317234, Test Loss: 18.57802753, Test Accuracy: 0.97190000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 1784.61889655, Test Loss: 18.26283262, Test Accuracy: 0.97160000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 1680.83059717, Test Loss: 18.85312394, Test Accuracy: 0.97150000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 1604.20283332, Test Loss: 18.26246101, Test Accuracy: 0.97140000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 1517.32451180, Test Loss: 18.80231087, Test Accuracy: 0.97160000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 1447.81217050, Test Loss: 18.54987415, Test Accuracy: 0.97120000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 1380.97397468, Test Loss: 18.55547353, Test Accuracy: 0.97210000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 1318.23756821, Test Loss: 18.78076176, Test Accuracy: 0.97090000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 1257.24451978, Test Loss: 18.45689293, Test Accuracy: 0.97190000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 1210.34476049, Test Loss: 18.42741779, Test Accuracy: 0.97190000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 1162.52283539, Test Loss: 18.77111044, Test Accuracy: 0.97230000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 1111.84811917, Test Loss: 18.65639577, Test Accuracy: 0.97140000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 1070.18099943, Test Loss: 18.76051610, Test Accuracy: 0.97150000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 1027.47582567, Test Loss: 18.68118884, Test Accuracy: 0.97220000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 991.40243141, Test Loss: 18.91982215, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 954.55413026, Test Loss: 19.04872737, Test Accuracy: 0.97220000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (linear_2): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 14418.97287399, Test Loss: 32.23191028, Test Accuracy: 0.94700000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 7662.98205447, Test Loss: 25.32661396, Test Accuracy: 0.96220000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 6090.82839111, Test Loss: 23.38285252, Test Accuracy: 0.96630000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 5190.77827004, Test Loss: 24.53569968, Test Accuracy: 0.96290000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 4317.95653953, Test Loss: 23.26177072, Test Accuracy: 0.96940000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 3965.19420974, Test Loss: 22.39756523, Test Accuracy: 0.96700000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 3540.44040975, Test Loss: 23.44124464, Test Accuracy: 0.96620000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 3284.43240953, Test Loss: 21.49066718, Test Accuracy: 0.96970000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 2864.04187396, Test Loss: 22.18843069, Test Accuracy: 0.97070000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 2447.52825878, Test Loss: 23.19244664, Test Accuracy: 0.96960000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 2203.41867218, Test Loss: 20.88906960, Test Accuracy: 0.97250000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 2113.68684421, Test Loss: 22.10770068, Test Accuracy: 0.97080000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 1782.70333076, Test Loss: 22.97358575, Test Accuracy: 0.97010000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 1712.21025323, Test Loss: 24.56560664, Test Accuracy: 0.96970000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 1599.88106813, Test Loss: 22.11418051, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 1306.54818819, Test Loss: 23.34126227, Test Accuracy: 0.97280000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 1209.84344058, Test Loss: 25.42883710, Test Accuracy: 0.96880000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 1189.40732717, Test Loss: 23.47578563, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 912.67792581, Test Loss: 26.03783210, Test Accuracy: 0.97170000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 825.00099654, Test Loss: 25.01707974, Test Accuracy: 0.97250000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 712.14763355, Test Loss: 24.65171661, Test Accuracy: 0.97180000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 728.06319873, Test Loss: 24.56003184, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 615.77459691, Test Loss: 24.28990511, Test Accuracy: 0.97510000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 435.38237722, Test Loss: 24.49811173, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 566.83196368, Test Loss: 26.07806232, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 295.17407499, Test Loss: 24.64284500, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 219.32063112, Test Loss: 24.28418971, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 137.36621450, Test Loss: 24.60083699, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 108.62624347, Test Loss: 25.14493224, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 98.65907021, Test Loss: 24.61705231, Test Accuracy: 0.97660000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (linear_2): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 15296.67666795, Test Loss: 28.23818035, Test Accuracy: 0.95680000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 7779.47255605, Test Loss: 24.11616171, Test Accuracy: 0.96230000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 6061.84518612, Test Loss: 23.46621168, Test Accuracy: 0.96420000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 5033.73259594, Test Loss: 22.32526430, Test Accuracy: 0.96580000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 4316.97719420, Test Loss: 23.69084435, Test Accuracy: 0.96600000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 3796.06016096, Test Loss: 24.17813766, Test Accuracy: 0.96710000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 3441.64072833, Test Loss: 25.36313935, Test Accuracy: 0.96520000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 3066.36069203, Test Loss: 23.37890844, Test Accuracy: 0.96990000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 2733.71021711, Test Loss: 25.06062914, Test Accuracy: 0.96880000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 2541.33262140, Test Loss: 25.05187175, Test Accuracy: 0.96810000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 2263.75680783, Test Loss: 26.39282470, Test Accuracy: 0.96690000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 2052.66172921, Test Loss: 24.57841296, Test Accuracy: 0.96920000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 1801.23375902, Test Loss: 25.79862192, Test Accuracy: 0.96900000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 1732.56403354, Test Loss: 25.66812496, Test Accuracy: 0.97020000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 1522.39411498, Test Loss: 27.17776917, Test Accuracy: 0.96890000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 1407.40485287, Test Loss: 27.31953757, Test Accuracy: 0.96900000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 1393.39774456, Test Loss: 30.10841579, Test Accuracy: 0.96750000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 1255.84741354, Test Loss: 29.12459858, Test Accuracy: 0.96840000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 1213.38507823, Test Loss: 31.48245875, Test Accuracy: 0.96810000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 1109.30194431, Test Loss: 31.59926692, Test Accuracy: 0.96690000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 984.42753583, Test Loss: 32.68486729, Test Accuracy: 0.96770000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 965.81480863, Test Loss: 30.88947838, Test Accuracy: 0.96900000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 883.62325857, Test Loss: 33.58765743, Test Accuracy: 0.96710000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 734.20749375, Test Loss: 34.58310235, Test Accuracy: 0.96870000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 749.15915338, Test Loss: 35.52289077, Test Accuracy: 0.96810000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 725.57536015, Test Loss: 34.39108886, Test Accuracy: 0.96770000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 664.97313810, Test Loss: 38.48241974, Test Accuracy: 0.96680000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 654.87195840, Test Loss: 36.56274210, Test Accuracy: 0.96830000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 604.49850586, Test Loss: 39.32717363, Test Accuracy: 0.96770000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 579.78300979, Test Loss: 39.09466333, Test Accuracy: 0.96770000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoHupVpCPeXa",
        "outputId": "af9dd55c-cbc8-4c9e-9cf6-50f34f56a375"
      },
      "source": [
        "# 128 neurons \n",
        "model_factory('Adadelta', 1234, 128)\n",
        "model_factory('Adagrad', 1234, 128)\n",
        "model_factory('SGD', 1234, 128)\n",
        "model_factory('Adam', 1234, 128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear_2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-06\n",
            "    lr: 1.0\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 18444.42383475, Test Loss: 41.77293881, Test Accuracy: 0.94690000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 11527.90064449, Test Loss: 31.18162055, Test Accuracy: 0.95930000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 9385.49577610, Test Loss: 28.46026822, Test Accuracy: 0.96500000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 8025.72175532, Test Loss: 25.62459275, Test Accuracy: 0.96690000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 7110.99498187, Test Loss: 27.11246686, Test Accuracy: 0.96720000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 6587.54901018, Test Loss: 24.32751544, Test Accuracy: 0.97120000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 5977.88481313, Test Loss: 24.99082384, Test Accuracy: 0.97050000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 5568.07979717, Test Loss: 22.36310472, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 5240.69007225, Test Loss: 21.94868145, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 5033.73558098, Test Loss: 22.29356013, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 4699.73940839, Test Loss: 21.97761553, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 4494.66342964, Test Loss: 21.63448970, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 4320.41792678, Test Loss: 21.77328940, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 4097.45238351, Test Loss: 23.40822058, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 4012.44101913, Test Loss: 22.26860806, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 3884.64332433, Test Loss: 23.78919538, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 3638.89330260, Test Loss: 21.44726203, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 3601.35668650, Test Loss: 21.53055020, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 3481.46342174, Test Loss: 22.66000447, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 3318.24870070, Test Loss: 24.09916157, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 3327.60854370, Test Loss: 23.70151740, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 3149.95365067, Test Loss: 24.06327815, Test Accuracy: 0.97600000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 3040.72396043, Test Loss: 22.52968955, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 2939.69336728, Test Loss: 25.37377384, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 2948.25573374, Test Loss: 25.76353983, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 2727.99039212, Test Loss: 25.83147541, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 2732.76333837, Test Loss: 24.20384198, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 2709.66456225, Test Loss: 23.77129337, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 2663.16722385, Test Loss: 25.10709120, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 2510.21245569, Test Loss: 27.49641304, Test Accuracy: 0.97340000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear_2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.1\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 11669.15866978, Test Loss: 24.23010261, Test Accuracy: 0.96370000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 5624.35458292, Test Loss: 20.93234814, Test Accuracy: 0.96860000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 4063.99269807, Test Loss: 17.60342983, Test Accuracy: 0.97160000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 3154.03699906, Test Loss: 16.80105728, Test Accuracy: 0.97310000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2512.49928228, Test Loss: 16.56164161, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 2096.67711630, Test Loss: 15.75884569, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1755.57239290, Test Loss: 15.31617353, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1508.90625080, Test Loss: 14.78102166, Test Accuracy: 0.97550000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 1302.19275180, Test Loss: 14.85113963, Test Accuracy: 0.97580000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 1148.64045010, Test Loss: 14.82363013, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 1005.42609320, Test Loss: 14.48965863, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 897.39986031, Test Loss: 14.41800180, Test Accuracy: 0.97690000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 802.58461628, Test Loss: 14.76208731, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 719.90744201, Test Loss: 14.64290115, Test Accuracy: 0.97710000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 652.71079338, Test Loss: 14.70373502, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 593.66540317, Test Loss: 14.68477946, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 546.11980021, Test Loss: 14.68270552, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 502.02465185, Test Loss: 14.70663374, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 464.15848778, Test Loss: 14.55733378, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 432.86555413, Test Loss: 14.70184042, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 401.41217037, Test Loss: 14.74730262, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 376.61642482, Test Loss: 14.78402928, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 352.85941331, Test Loss: 14.79307797, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 331.93600979, Test Loss: 14.99082525, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 312.81706550, Test Loss: 14.87361826, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 295.94202002, Test Loss: 14.92695451, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 279.98522084, Test Loss: 15.04349530, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 264.72733230, Test Loss: 15.09800240, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 253.42291455, Test Loss: 15.09649098, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 241.09160174, Test Loss: 15.07992566, Test Accuracy: 0.97840000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear_2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 13582.54396883, Test Loss: 26.79325758, Test Accuracy: 0.95840000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 6419.68982134, Test Loss: 23.16648860, Test Accuracy: 0.96580000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 4632.64898099, Test Loss: 19.67341886, Test Accuracy: 0.97040000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 3793.23918567, Test Loss: 17.50417163, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2877.24078254, Test Loss: 16.51440831, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 2334.76426234, Test Loss: 21.76399316, Test Accuracy: 0.96970000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1928.52181351, Test Loss: 19.14349480, Test Accuracy: 0.97340000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1566.65272960, Test Loss: 18.53234688, Test Accuracy: 0.97500000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 1478.18264644, Test Loss: 18.46520057, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 1053.88788640, Test Loss: 17.79601894, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 690.99723341, Test Loss: 16.55824922, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 575.30210348, Test Loss: 17.11278006, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 372.36564207, Test Loss: 17.61745191, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 286.88042337, Test Loss: 16.71442335, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 129.11647465, Test Loss: 17.12240269, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 81.72843330, Test Loss: 16.72500254, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 62.32642090, Test Loss: 16.60470684, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 53.23208731, Test Loss: 16.89449110, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 47.27981681, Test Loss: 16.88992006, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 42.85168324, Test Loss: 16.93801960, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 37.74983991, Test Loss: 17.17106255, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 33.79838645, Test Loss: 17.26446730, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 31.52128473, Test Loss: 17.22886165, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 29.15430270, Test Loss: 17.38958561, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 27.35431356, Test Loss: 17.39159754, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 25.89184254, Test Loss: 17.47300043, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 24.44384636, Test Loss: 17.55292632, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 23.21992956, Test Loss: 17.60858293, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 22.16126953, Test Loss: 17.72065210, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 21.12637658, Test Loss: 17.74360124, Test Accuracy: 0.98060000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear_2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 13527.43625255, Test Loss: 25.86095995, Test Accuracy: 0.95990000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 6110.13963641, Test Loss: 19.18700404, Test Accuracy: 0.97160000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 4390.93512409, Test Loss: 18.29648873, Test Accuracy: 0.97240000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 3432.41793591, Test Loss: 16.99999601, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2820.39075275, Test Loss: 20.31888711, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 2248.57616589, Test Loss: 19.90049723, Test Accuracy: 0.97260000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1938.53897794, Test Loss: 19.05843433, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1695.19236207, Test Loss: 21.05776012, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 1351.25306863, Test Loss: 18.41784621, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 1082.11421546, Test Loss: 20.27087857, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 996.90854490, Test Loss: 23.91620852, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 899.30985292, Test Loss: 26.91743072, Test Accuracy: 0.97300000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 732.26711416, Test Loss: 24.90165683, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 685.47302920, Test Loss: 25.13605261, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 641.12848754, Test Loss: 26.73410091, Test Accuracy: 0.97500000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 520.60489406, Test Loss: 27.45078484, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 447.15126301, Test Loss: 26.18119534, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 412.46436708, Test Loss: 28.79980658, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 357.95446481, Test Loss: 30.63853990, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 340.14776828, Test Loss: 28.72306195, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 337.30119398, Test Loss: 32.52110206, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 274.56193077, Test Loss: 30.40304600, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 240.55524743, Test Loss: 31.67854817, Test Accuracy: 0.97550000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 203.39943809, Test Loss: 33.18591745, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 204.75706615, Test Loss: 36.12943413, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 208.48010246, Test Loss: 31.65701688, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 274.70624061, Test Loss: 34.85396643, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 230.00024341, Test Loss: 35.44317771, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 199.74640279, Test Loss: 34.04871588, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 195.36012772, Test Loss: 35.65070408, Test Accuracy: 0.97660000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-D785NrPfKE",
        "outputId": "093c480d-f1b1-423e-9056-4bcb6ee95af0"
      },
      "source": [
        "# 256 neurons \n",
        "model_factory('Adadelta', 1234, 256)\n",
        "model_factory('Adagrad', 1234, 256)\n",
        "model_factory('SGD', 1234, 256)\n",
        "model_factory('Adam', 1234, 256)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-06\n",
            "    lr: 1.0\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 18841.70052454, Test Loss: 40.31632494, Test Accuracy: 0.94740000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 11026.84288938, Test Loss: 30.45795690, Test Accuracy: 0.96080000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 8372.96893607, Test Loss: 28.84013438, Test Accuracy: 0.96620000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 6888.41192414, Test Loss: 25.89124378, Test Accuracy: 0.96820000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 6034.47159533, Test Loss: 20.37249598, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 5262.56894235, Test Loss: 20.02413215, Test Accuracy: 0.97310000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 4603.04771062, Test Loss: 20.19460536, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 4312.22388952, Test Loss: 19.15625626, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 3905.55775198, Test Loss: 18.48497080, Test Accuracy: 0.97700000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 3597.13409697, Test Loss: 17.70736420, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 3377.25723872, Test Loss: 17.36304015, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 3025.45607890, Test Loss: 17.71072910, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 2907.75845401, Test Loss: 17.84830438, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 2677.03452157, Test Loss: 16.44163451, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 2586.16868556, Test Loss: 18.20053480, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 2421.63021642, Test Loss: 17.30451656, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 2299.10098140, Test Loss: 17.02503711, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 2148.79226271, Test Loss: 18.66659938, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 2059.36532905, Test Loss: 17.13916594, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 1833.17481986, Test Loss: 17.34893674, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 1842.50579780, Test Loss: 17.11130534, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 1689.77429623, Test Loss: 18.73353697, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 1646.50017632, Test Loss: 16.58467658, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 1560.28388016, Test Loss: 18.04514970, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 1469.79373883, Test Loss: 18.65471406, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 1400.44017580, Test Loss: 17.31166385, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 1272.52028619, Test Loss: 18.42002385, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 1205.19812488, Test Loss: 17.71661851, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 1210.77512698, Test Loss: 18.82921512, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 1120.56588585, Test Loss: 18.75384398, Test Accuracy: 0.98040000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.1\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 11727.33432392, Test Loss: 24.75640525, Test Accuracy: 0.96390000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 5365.89714357, Test Loss: 19.33140564, Test Accuracy: 0.97220000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 3693.11449625, Test Loss: 17.27633725, Test Accuracy: 0.97360000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 2740.92996232, Test Loss: 16.41380458, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2078.22921684, Test Loss: 15.42160148, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 1639.08221916, Test Loss: 15.06210755, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1301.81809465, Test Loss: 14.46133731, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1066.65559294, Test Loss: 14.37357118, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 866.97609328, Test Loss: 14.40014905, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 725.30521666, Test Loss: 14.03167662, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 612.79474169, Test Loss: 13.95768060, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 524.70475576, Test Loss: 13.83983829, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 454.55655387, Test Loss: 13.92719872, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 394.83144200, Test Loss: 13.99957137, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 345.74046691, Test Loss: 14.03653552, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 306.70155060, Test Loss: 13.89621409, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 275.10878147, Test Loss: 14.09378089, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 246.45766664, Test Loss: 14.06713218, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 221.58909779, Test Loss: 14.15417653, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 200.20069951, Test Loss: 14.18984418, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 182.38978101, Test Loss: 14.35598107, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 167.78782555, Test Loss: 14.38377721, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 153.38387615, Test Loss: 14.38554782, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 141.71571558, Test Loss: 14.53804512, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 130.19262288, Test Loss: 14.57029691, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 121.35609258, Test Loss: 14.63149680, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 113.50884328, Test Loss: 14.67033688, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 105.43514218, Test Loss: 14.82680173, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 99.54831233, Test Loss: 14.73469118, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 93.34922049, Test Loss: 14.89268448, Test Accuracy: 0.98100000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 13981.32331504, Test Loss: 27.33463610, Test Accuracy: 0.95500000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 6133.85578882, Test Loss: 18.40010148, Test Accuracy: 0.97090000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 4443.32290344, Test Loss: 16.41519641, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 3283.32778684, Test Loss: 14.70570641, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2573.90712301, Test Loss: 17.76703229, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 1904.71437736, Test Loss: 15.53747455, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1433.24188146, Test Loss: 17.79663069, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1013.25916366, Test Loss: 15.26718380, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 747.39646219, Test Loss: 14.11947236, Test Accuracy: 0.98190000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 444.82030791, Test Loss: 13.77475874, Test Accuracy: 0.98230000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 269.61749723, Test Loss: 15.35029815, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 174.13504453, Test Loss: 14.42947983, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 113.28499015, Test Loss: 14.27632673, Test Accuracy: 0.98260000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 73.46034355, Test Loss: 14.16615856, Test Accuracy: 0.98330000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 58.14964819, Test Loss: 14.23005705, Test Accuracy: 0.98320000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 47.47314839, Test Loss: 14.40112985, Test Accuracy: 0.98320000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 41.87601535, Test Loss: 14.41224864, Test Accuracy: 0.98360000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 35.86151312, Test Loss: 14.51985021, Test Accuracy: 0.98310000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 31.73090816, Test Loss: 14.71795351, Test Accuracy: 0.98330000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 29.28689677, Test Loss: 14.81182320, Test Accuracy: 0.98310000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 26.85831380, Test Loss: 14.94290926, Test Accuracy: 0.98330000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 25.06385150, Test Loss: 14.96078463, Test Accuracy: 0.98290000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 23.58545480, Test Loss: 14.96067041, Test Accuracy: 0.98330000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 22.15637958, Test Loss: 15.02338206, Test Accuracy: 0.98370000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 20.99110993, Test Loss: 15.06558025, Test Accuracy: 0.98340000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 19.90965911, Test Loss: 15.16067054, Test Accuracy: 0.98340000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 18.90298026, Test Loss: 15.17864821, Test Accuracy: 0.98340000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 18.06416076, Test Loss: 15.27389425, Test Accuracy: 0.98320000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 17.22338508, Test Loss: 15.32198572, Test Accuracy: 0.98340000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 16.59074355, Test Loss: 15.30374889, Test Accuracy: 0.98330000\n",
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 12261.66888993, Test Loss: 27.22909606, Test Accuracy: 0.95990000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 5198.92752876, Test Loss: 18.53066098, Test Accuracy: 0.97360000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 3774.83934307, Test Loss: 19.03489320, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 2834.25397761, Test Loss: 23.84774453, Test Accuracy: 0.96830000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2279.14448093, Test Loss: 17.73204620, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 1800.78615787, Test Loss: 18.35554779, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1435.52029823, Test Loss: 18.79061374, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1196.66305727, Test Loss: 19.69944620, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 1008.99678403, Test Loss: 24.46899670, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 870.49904773, Test Loss: 23.21157338, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 700.04006220, Test Loss: 24.21876831, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 748.92344623, Test Loss: 25.43409178, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 517.35287572, Test Loss: 23.51406520, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 488.56050951, Test Loss: 26.21794126, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 469.14158297, Test Loss: 25.92603059, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 378.93602286, Test Loss: 29.89534479, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 364.56438528, Test Loss: 28.98774384, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 279.50023693, Test Loss: 30.31770133, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 277.46569694, Test Loss: 27.36459605, Test Accuracy: 0.98200000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 268.37861886, Test Loss: 34.51546158, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 250.50622249, Test Loss: 30.66962495, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 198.56492715, Test Loss: 30.04056589, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 201.26317127, Test Loss: 29.45810845, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 180.67432270, Test Loss: 37.03628607, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 184.44581966, Test Loss: 34.00285929, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 151.82471834, Test Loss: 37.22795462, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 142.34300112, Test Loss: 36.27090331, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 189.50233013, Test Loss: 37.21650231, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 122.55497480, Test Loss: 37.14560843, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 150.76874119, Test Loss: 41.83956205, Test Accuracy: 0.97790000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbmdG4ZNPf7Y",
        "outputId": "0c43cd6a-d743-451d-b94c-b38bd807c129"
      },
      "source": [
        "# 384 neurons \n",
        "model_factory('Adadelta', 1234, 384)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=384, bias=True)\n",
            "  (linear_2): Linear(in_features=384, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-06\n",
            "    lr: 1.0\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 19563.48843208, Test Loss: 40.67091092, Test Accuracy: 0.95190000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 10731.72155710, Test Loss: 27.22717592, Test Accuracy: 0.96440000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 8000.16694686, Test Loss: 29.50317174, Test Accuracy: 0.96340000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 6661.12701197, Test Loss: 24.32296038, Test Accuracy: 0.96950000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 5622.16367523, Test Loss: 20.70760627, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 4938.79764466, Test Loss: 20.93197935, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 4377.69068638, Test Loss: 19.86728702, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 3933.82595406, Test Loss: 20.29470902, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 3444.50356094, Test Loss: 17.79443890, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 3192.49584869, Test Loss: 20.30773085, Test Accuracy: 0.97510000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 2867.89699483, Test Loss: 18.02899581, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 2633.65456249, Test Loss: 18.93204091, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 2387.79856256, Test Loss: 17.26103641, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 2207.15842419, Test Loss: 17.55937762, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 2000.68951408, Test Loss: 18.83533731, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 1814.97782110, Test Loss: 20.03757784, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 1652.46105552, Test Loss: 17.52564821, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 1609.97500515, Test Loss: 18.18728959, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 1460.28707121, Test Loss: 19.66377388, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 1341.24729730, Test Loss: 20.60781521, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 1195.98320304, Test Loss: 18.56937752, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 1129.19844135, Test Loss: 19.96176111, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 1002.35823219, Test Loss: 21.04444323, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 905.77843566, Test Loss: 20.57595307, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 859.52977502, Test Loss: 20.59094212, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 779.15021811, Test Loss: 22.53455135, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 720.69469242, Test Loss: 23.12532104, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 635.17442012, Test Loss: 21.79825483, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 593.95050514, Test Loss: 21.25751075, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 565.66688365, Test Loss: 21.97965356, Test Accuracy: 0.97870000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jn7tbIIXYZx",
        "outputId": "757dec1e-7e3e-4687-d6a0-fbb1e8ee6553"
      },
      "source": [
        "model_factory('Adagrad', 1234, 384)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=384, bias=True)\n",
            "  (linear_2): Linear(in_features=384, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.1\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 11358.17686582, Test Loss: 22.12879748, Test Accuracy: 0.96730000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 4885.44120730, Test Loss: 18.26265254, Test Accuracy: 0.97190000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 3264.47297707, Test Loss: 15.91543117, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 2325.83017820, Test Loss: 14.65049615, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 1680.08979093, Test Loss: 14.20706485, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 1270.55998929, Test Loss: 13.58271275, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 969.78730022, Test Loss: 13.44216104, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 757.62102183, Test Loss: 13.15121318, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 588.14709978, Test Loss: 13.52126746, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 471.35017572, Test Loss: 13.42724885, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 382.14411691, Test Loss: 13.58262677, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 315.07236045, Test Loss: 13.59858399, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 262.08176137, Test Loss: 13.39546317, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 223.33679407, Test Loss: 13.37278327, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 192.53039244, Test Loss: 13.43861726, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 168.99801656, Test Loss: 13.52031100, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 149.17889389, Test Loss: 13.63731260, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 132.65221743, Test Loss: 13.65772431, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 119.30983210, Test Loss: 13.54903360, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 107.03052001, Test Loss: 13.77830287, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 97.68361574, Test Loss: 13.74731080, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 89.43738663, Test Loss: 13.79672251, Test Accuracy: 0.98220000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 82.03363780, Test Loss: 13.90639540, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 75.59290119, Test Loss: 13.84942013, Test Accuracy: 0.98200000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 69.73568903, Test Loss: 13.91681494, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 65.12173515, Test Loss: 14.04829558, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 60.63131470, Test Loss: 14.05480635, Test Accuracy: 0.98240000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 56.72761004, Test Loss: 14.12056620, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 53.20936345, Test Loss: 14.16804004, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 50.03167376, Test Loss: 14.14171565, Test Accuracy: 0.98220000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn5Vde1OXZqC",
        "outputId": "25673d5d-32ee-47c7-c168-76ca01dca0c1"
      },
      "source": [
        "model_factory('SGD', 1234, 384)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=384, bias=True)\n",
            "  (linear_2): Linear(in_features=384, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 14204.40901976, Test Loss: 26.43992034, Test Accuracy: 0.95910000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 6141.79409067, Test Loss: 20.95471618, Test Accuracy: 0.96820000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 4159.93660309, Test Loss: 16.39044069, Test Accuracy: 0.97500000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 3251.51370835, Test Loss: 15.57894610, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2520.75266061, Test Loss: 17.18050077, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 1954.75323372, Test Loss: 17.40113000, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1393.36917434, Test Loss: 16.17355087, Test Accuracy: 0.97600000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 994.73826959, Test Loss: 14.62207035, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 640.37170058, Test Loss: 15.63438561, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 363.79429259, Test Loss: 15.66350345, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 236.94831641, Test Loss: 14.85620794, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 136.33703394, Test Loss: 14.38843101, Test Accuracy: 0.98230000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 90.32402226, Test Loss: 14.48260510, Test Accuracy: 0.98280000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 65.35332604, Test Loss: 14.80788693, Test Accuracy: 0.98220000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 52.26217808, Test Loss: 14.80547126, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 44.19759411, Test Loss: 15.05298088, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 39.56293545, Test Loss: 15.20104627, Test Accuracy: 0.98220000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 35.24041125, Test Loss: 15.33702349, Test Accuracy: 0.98230000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 32.05147865, Test Loss: 15.33265141, Test Accuracy: 0.98240000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 29.52942974, Test Loss: 15.49758155, Test Accuracy: 0.98260000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 27.34616143, Test Loss: 15.51666533, Test Accuracy: 0.98230000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 25.64733381, Test Loss: 15.62426925, Test Accuracy: 0.98240000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 23.94635717, Test Loss: 15.74882344, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 22.58230288, Test Loss: 15.68500173, Test Accuracy: 0.98260000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 21.31604784, Test Loss: 15.76756963, Test Accuracy: 0.98240000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 20.31521816, Test Loss: 15.77265301, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 19.29520331, Test Loss: 15.86776285, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 18.37056699, Test Loss: 15.97537635, Test Accuracy: 0.98240000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 17.51849198, Test Loss: 16.05232063, Test Accuracy: 0.98220000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 16.79404632, Test Loss: 16.05196409, Test Accuracy: 0.98240000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6tWOQuWXaiC",
        "outputId": "1e340816-8f27-4c23-f8b4-20b15563aee8"
      },
      "source": [
        "model_factory('Adam', 1234, 384)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=384, bias=True)\n",
            "  (linear_2): Linear(in_features=384, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 12010.91230602, Test Loss: 22.63865483, Test Accuracy: 0.96610000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 5124.75464130, Test Loss: 17.09695307, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 3678.85543276, Test Loss: 15.29960955, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 2674.09666812, Test Loss: 20.37837027, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 2042.05032691, Test Loss: 16.69328676, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 1646.98364376, Test Loss: 18.93368876, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 1419.22543489, Test Loss: 19.35989850, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 1092.59300848, Test Loss: 21.85180606, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 984.17232445, Test Loss: 21.40926009, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 857.06810439, Test Loss: 22.60454174, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 663.01314028, Test Loss: 25.09451771, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 724.19423808, Test Loss: 27.95990041, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 486.43749814, Test Loss: 27.86885008, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 527.31106234, Test Loss: 28.07931470, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 453.76452630, Test Loss: 29.27937323, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 386.84767954, Test Loss: 27.85606406, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 377.29088436, Test Loss: 33.20893395, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 367.22723667, Test Loss: 30.21948489, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 307.83281320, Test Loss: 31.15189516, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 265.17074136, Test Loss: 33.09183175, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 265.00142400, Test Loss: 33.39145012, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 215.76946594, Test Loss: 33.46914832, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 181.62647456, Test Loss: 34.86229506, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 227.81732640, Test Loss: 38.41461601, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 190.59096355, Test Loss: 35.25266006, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 184.54843582, Test Loss: 38.34424012, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 158.71654924, Test Loss: 38.83616468, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 117.97007348, Test Loss: 37.98244985, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 137.78243172, Test Loss: 41.07126857, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 154.20019973, Test Loss: 40.91392503, Test Accuracy: 0.98030000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSPMTdYdXbNA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}