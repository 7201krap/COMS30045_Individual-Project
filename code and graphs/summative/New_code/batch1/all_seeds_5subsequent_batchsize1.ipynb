{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_seeds_5subsequent_batchsize1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/all_seeds_5subsequent_batchsize1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7STrWa0P3z_",
        "outputId": "f8c0d68a-d178-4874-a513-cd8196d259da"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIyKF1HE7uQW",
        "outputId": "29b3cc5d-4a81-4c9c-8226-603c3b3c9cdd"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "root_dir = './'\n",
        "torchvision.datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-08 17:30:01--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-04-08 17:30:01--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.2’\n",
            "\n",
            "MNIST.tar.gz.2          [       <=>          ]  33.20M  5.97MB/s    in 15s     \n",
            "\n",
            "2021-04-08 17:30:17 (2.16 MB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4j9WoP-UnAm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = torchvision.datasets.MNIST(root=root_dir, train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = torchvision.datasets.MNIST(root=root_dir, \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow9Sy2SyUYgn"
      },
      "source": [
        "new_mnist_trainset =  [ [[],[]] for i in range(10)]\n",
        "# new_mnist_testset  =  [ [[],[]] for i in range(10)]\n",
        "\n",
        "for i in range(60000):\n",
        "    for j in range(10):\n",
        "        # 만약에 label 이 j 이면, \n",
        "        if mnist_trainset[i][1] == j:\n",
        "            # image \n",
        "            new_mnist_trainset[j][0].append(mnist_trainset[i][0])  \n",
        "            # new_mnist_trainset[j][0] 는 j label 에 해당하는 image 가 들어있다. \n",
        "\n",
        "            # label\n",
        "            new_mnist_trainset[j][1].append(mnist_trainset[i][1])\n",
        "            # new_mnist_trainset[j][1] 는 j label 에 해당하는 label 가 들어있다. \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyIkUPYTNdLf",
        "outputId": "7c883e01-7d3a-419d-b82c-265e7a13fa48"
      },
      "source": [
        "print(\"0\", len(new_mnist_trainset[0][0]))    # - pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][0]))    # - pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][0]))    # - pop 3 times\n",
        "print(\"3\", len(new_mnist_trainset[3][0]))    # - pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][0]))    # - pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][0]))    # - pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][0]))    # - pop 3 times\n",
        "print(\"7\", len(new_mnist_trainset[7][0]))    # - pop 0 times\n",
        "print(\"8\", len(new_mnist_trainset[8][0]))    # - pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][0]))    # - pop 4 times"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5923\n",
            "1 6742\n",
            "2 5958\n",
            "3 6131\n",
            "4 5842\n",
            "5 5421\n",
            "6 5918\n",
            "7 6265\n",
            "8 5851\n",
            "9 5949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieTyNQeWP1Sb"
      },
      "source": [
        "# 0 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[0][0].pop()\n",
        "    new_mnist_trainset[0][1].pop()\n",
        "\n",
        "# 1 - pop 2 times\n",
        "for i in range(2):\n",
        "    new_mnist_trainset[1][0].pop()\n",
        "    new_mnist_trainset[1][1].pop()\n",
        "\n",
        "# 2 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[2][0].pop()\n",
        "    new_mnist_trainset[2][1].pop()\n",
        "\n",
        "# 3 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[3][0].pop()\n",
        "    new_mnist_trainset[3][1].pop()\n",
        "\n",
        "# 4 - pop 2 time\n",
        "for i in range(2):\n",
        "    new_mnist_trainset[4][0].pop()\n",
        "    new_mnist_trainset[4][1].pop()\n",
        "\n",
        "# 5 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[5][0].pop()\n",
        "    new_mnist_trainset[5][1].pop()\n",
        "\n",
        "# 6 - pop 3 times\n",
        "for i in range(3):\n",
        "    new_mnist_trainset[6][0].pop()\n",
        "    new_mnist_trainset[6][1].pop()\n",
        "\n",
        "# 7 - pop 0 times\n",
        "\n",
        "# 8 - pop 1 times\n",
        "for i in range(1):\n",
        "    new_mnist_trainset[8][0].pop()\n",
        "    new_mnist_trainset[8][1].pop()\n",
        "\n",
        "# 9 - pop 4 times\n",
        "for i in range(4):\n",
        "    new_mnist_trainset[9][0].pop()\n",
        "    new_mnist_trainset[9][1].pop()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSb6f78RQYGp",
        "outputId": "bd92022e-2854-47b6-d6ff-1161ded919d9"
      },
      "source": [
        "print(\"0\", len(new_mnist_trainset[0][0]))    # pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][0]))    # pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][0]))    # pop 3 times\n",
        "print(\"3\", len(new_mnist_trainset[3][0]))    # pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][0]))    # pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][0]))    # pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][0]))    # pop 3 times\n",
        "print(\"7\", len(new_mnist_trainset[7][0]))    # pop 0 times\n",
        "print(\"8\", len(new_mnist_trainset[8][0]))    # pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][0]))    # pop 4 times\n",
        "\n",
        "print(\"0\", len(new_mnist_trainset[0][1]))    # pop 3 times\n",
        "print(\"1\", len(new_mnist_trainset[1][1]))    # pop 2 times\n",
        "print(\"2\", len(new_mnist_trainset[2][1]))    # pop 3 times\n",
        "print(\"3\", len(new_mnist_trainset[3][1]))    # pop 1 times\n",
        "print(\"4\", len(new_mnist_trainset[4][1]))    # pop 2 time\n",
        "print(\"5\", len(new_mnist_trainset[5][1]))    # pop 1 times\n",
        "print(\"6\", len(new_mnist_trainset[6][1]))    # pop 3 times\n",
        "print(\"7\", len(new_mnist_trainset[7][1]))    # pop 0 times\n",
        "print(\"8\", len(new_mnist_trainset[8][1]))    # pop 1 times\n",
        "print(\"9\", len(new_mnist_trainset[9][1]))    # pop 4 times"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5920\n",
            "1 6740\n",
            "2 5955\n",
            "3 6130\n",
            "4 5840\n",
            "5 5420\n",
            "6 5915\n",
            "7 6265\n",
            "8 5850\n",
            "9 5945\n",
            "0 5920\n",
            "1 6740\n",
            "2 5955\n",
            "3 6130\n",
            "4 5840\n",
            "5 5420\n",
            "6 5915\n",
            "7 6265\n",
            "8 5850\n",
            "9 5945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMFpH3QLNAYQ"
      },
      "source": [
        "image_trainset = list()\n",
        "label_trainset = list()\n",
        "\n",
        "for i in range(10):\n",
        "    image_trainset.append(new_mnist_trainset[i][0])\n",
        "    label_trainset.append(new_mnist_trainset[i][1])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV9vZ4G_NCTB"
      },
      "source": [
        "flattened_image_train = list()\n",
        "flattened_label_train = list()\n",
        "\n",
        "# flattening image \n",
        "for sublist in image_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_image_train.append(val)\n",
        "\n",
        "# flattening label\n",
        "for sublist in label_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_label_train.append(val)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q_z0dBzSR5o",
        "outputId": "a738353c-cf61-4d95-a61a-d9c171932f14"
      },
      "source": [
        "len(flattened_image_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onYs9h2CTj41",
        "outputId": "47482ae7-4f97-45b4-9f96-25db01c5036f"
      },
      "source": [
        "len(flattened_label_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbZTrSWrYkkG"
      },
      "source": [
        "def split(a, n):\n",
        "    k, m = divmod(len(a), n)\n",
        "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFctZ-9EYlgx"
      },
      "source": [
        "list1 = list(split(flattened_image_train, 11996))\n",
        "list2 = list(split(flattened_label_train, 11996))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlqM-hF2ZuV2"
      },
      "source": [
        "X, y = shuffle(list1, list2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTF5pJPZypH"
      },
      "source": [
        "X_final, y_final = shuffle(X, y)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimwHtbgaEtX"
      },
      "source": [
        "flattened_X_final = [val for sublist in X_final for val in sublist] \n",
        "flattened_y_final = [val for sublist in y_final for val in sublist] "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Xxbuxud6djJF",
        "outputId": "ee63da7d-6e85-4a69-9bc1-2c2a2a6f3683"
      },
      "source": [
        "plt.imshow(flattened_X_final[0].reshape(28,28))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbd6be53cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SkccxZdNEDY"
      },
      "source": [
        "flattened_image_train = torch.stack(flattened_X_final)\n",
        "flattened_label_train = torch.Tensor(flattened_y_final)\n",
        "flattened_label_train = flattened_label_train.type(torch.LongTensor)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cANEC2zaNFPq"
      },
      "source": [
        "train_dataset = TensorDataset(flattened_image_train, flattened_label_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAD1thJ5JvD"
      },
      "source": [
        "def selectivity(hidden_layer_each_neuron):\n",
        "    __selectivity__ = list()\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(256)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 256 lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(256)]\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity\n",
        "        __selectivity__.append(selectivity)\n",
        "\n",
        "    avg_selectivity = np.average(__selectivity__)\n",
        "    std_selectivity = np.std(__selectivity__)\n",
        "                                 \n",
        "    return avg_selectivity, std_selectivity"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9kATNPUz1cA"
      },
      "source": [
        "def sparsity_calculator(final_spareness):\n",
        "    sparseness_list_avg = list()\n",
        "    sparseness_list_std = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "        std_sparseness_per_epoch  = torch.std(population_sparseness)\n",
        "\n",
        "        sparseness_list_avg.append(mean_sparseness_per_epoch)\n",
        "        sparseness_list_std.append(std_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list_avg, sparseness_list_std"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 30\n",
        "def sparsity_selectivity_trainer(optimizer, model):\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "\n",
        "    final_spareness = list()\n",
        "    \n",
        "    final_selectivity_avg_list = list()\n",
        "    final_selectivity_std_list = list()\n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        _hidden_layer_each_neuron_ = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
        "        _hidden_layer_each_neuron_ = np.array(_hidden_layer_each_neuron_)\n",
        "\n",
        "        hidden_layer_activation_list = list()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, labels) in enumerate(train_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print/Append activation of the hidden layer \n",
        "            # print(model.layer_activations.shape)\n",
        "            # model.layer_activations\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            hidden_layer_activation_list.append(model.layer_activations)\n",
        "\n",
        "            \n",
        "            for activation, label in zip(model.layer_activations, labels):\n",
        "                # shape of activation and label: 256 and 1 \n",
        "                \n",
        "                # get the actual value of item. This is because label is now Tensor \n",
        "                label = label.item()\n",
        "\n",
        "                # this is not part of gradient calculcation \n",
        "                with torch.no_grad():\n",
        "                    activation = activation.numpy()\n",
        "\n",
        "                # for each image/label, append activation value of neuron \n",
        "                for i in range(256):    # number of neurons in hidden layer \n",
        "                    _hidden_layer_each_neuron_[i][label].append(activation[i])\n",
        "\n",
        "        avg_selectivity, std_selectivity = selectivity(_hidden_layer_each_neuron_)\n",
        "        \n",
        "        final_selectivity_avg_list.append(avg_selectivity)\n",
        "        final_selectivity_std_list.append(std_selectivity)\n",
        "\n",
        "        final_spareness.append(hidden_layer_activation_list)\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "    sparsity_list_avg, sparsity_list_std = sparsity_calculator(final_spareness)\n",
        "\n",
        "    average_sparsity = list()\n",
        "    std_sparsity = list()\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list_avg[i].item()) / 1 )\n",
        "        std_sparsity.append( (sparsity_list_std[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    return test_acc, average_sparsity, std_sparsity, final_selectivity_avg_list, final_selectivity_std_list"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# seed 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WytqcJRZxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9417d45d-a927-4ccc-e4b1-ebc4ed0de13f"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Adadelta\n",
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity_avg, sparsity_std, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"seed1_5subsebatch1_sparsity_selectivity_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_5subsebatch1_sparsity_selectivity_Adadelta.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adagrad \n",
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity_avg, sparsity_std, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"seed1_5subsebatch1_sparsity_selectivity_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_5subsebatch1_sparsity_selectivity_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# SGD \n",
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity_avg, sparsity_std, SGD_avg_selectivity_list, SGD_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"seed1_5subsebatch1_sparsity_selectivity_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_5subsebatch1_sparsity_selectivity_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "# Adam \n",
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity_avg, sparsity_std, Adam_avg_selectivity_list, Adam_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"seed1_5subsebatch1_sparsity_selectivity_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_5subsebatch1_sparsity_selectivity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.29675315, Test Loss: 0.23662858, Test Accuracy: 0.94080000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.17481815, Test Loss: 0.16323194, Test Accuracy: 0.95970000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.13543872, Test Loss: 0.13489283, Test Accuracy: 0.96650000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.11328968, Test Loss: 0.12409668, Test Accuracy: 0.96820000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.09812412, Test Loss: 0.11763804, Test Accuracy: 0.97020000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.08689349, Test Loss: 0.11702171, Test Accuracy: 0.97080000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.07805683, Test Loss: 0.11526075, Test Accuracy: 0.97150000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.07167725, Test Loss: 0.11303176, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.06647352, Test Loss: 0.11030720, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.06233971, Test Loss: 0.10811033, Test Accuracy: 0.97340000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.05861863, Test Loss: 0.10907042, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.05543238, Test Loss: 0.10939594, Test Accuracy: 0.97350000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.05239713, Test Loss: 0.11112353, Test Accuracy: 0.97300000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.05001867, Test Loss: 0.11099534, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.04780725, Test Loss: 0.11102645, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.04575889, Test Loss: 0.11422154, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.04345776, Test Loss: 0.11836670, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.04135023, Test Loss: 0.12238478, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.03953943, Test Loss: 0.12632653, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.03791528, Test Loss: 0.12886103, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.03618644, Test Loss: 0.13269057, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.03490001, Test Loss: 0.13714813, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.03386071, Test Loss: 0.13844535, Test Accuracy: 0.97360000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.03254189, Test Loss: 0.14020071, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.03135448, Test Loss: 0.14046190, Test Accuracy: 0.97340000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.03027002, Test Loss: 0.14038085, Test Accuracy: 0.97350000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.02913515, Test Loss: 0.14261401, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.02800840, Test Loss: 0.14442162, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.02708058, Test Loss: 0.14684123, Test Accuracy: 0.97210000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.02621880, Test Loss: 0.15045623, Test Accuracy: 0.97140000\n",
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.18222252, Test Loss: 0.12007754, Test Accuracy: 0.96360000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08067416, Test Loss: 0.09757774, Test Accuracy: 0.97060000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05404833, Test Loss: 0.08669830, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03911514, Test Loss: 0.08242379, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.02950289, Test Loss: 0.07941565, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02276917, Test Loss: 0.07728658, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01790162, Test Loss: 0.07543578, Test Accuracy: 0.97690000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01433964, Test Loss: 0.07384119, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01162161, Test Loss: 0.07238307, Test Accuracy: 0.97750000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00957125, Test Loss: 0.07194111, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00795707, Test Loss: 0.07098289, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00670721, Test Loss: 0.07053187, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00573416, Test Loss: 0.07046180, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00494544, Test Loss: 0.07028552, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00432123, Test Loss: 0.07019938, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00382315, Test Loss: 0.07015600, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00341610, Test Loss: 0.07040593, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00307588, Test Loss: 0.07062805, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00278680, Test Loss: 0.07084451, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00254176, Test Loss: 0.07107388, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00233355, Test Loss: 0.07132939, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00215511, Test Loss: 0.07159332, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00199989, Test Loss: 0.07186261, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00186370, Test Loss: 0.07213135, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00174310, Test Loss: 0.07238104, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00163488, Test Loss: 0.07263582, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00153734, Test Loss: 0.07294476, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00144885, Test Loss: 0.07325885, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00136883, Test Loss: 0.07354322, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00129598, Test Loss: 0.07378627, Test Accuracy: 0.98070000\n",
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.21649093, Test Loss: 0.13834260, Test Accuracy: 0.95670000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.10020090, Test Loss: 0.11223443, Test Accuracy: 0.96490000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.06532162, Test Loss: 0.11018580, Test Accuracy: 0.96570000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.04860840, Test Loss: 0.10382822, Test Accuracy: 0.96750000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03518020, Test Loss: 0.11875166, Test Accuracy: 0.96480000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02544705, Test Loss: 0.10716665, Test Accuracy: 0.96940000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01878005, Test Loss: 0.09199493, Test Accuracy: 0.97280000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01416534, Test Loss: 0.09395796, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01186488, Test Loss: 0.08204919, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00950183, Test Loss: 0.08837579, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00599666, Test Loss: 0.08951380, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00506758, Test Loss: 0.08637361, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00292130, Test Loss: 0.08480626, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00205806, Test Loss: 0.08577984, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00116676, Test Loss: 0.08524540, Test Accuracy: 0.98160000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00086257, Test Loss: 0.08523583, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00070634, Test Loss: 0.08540077, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00061292, Test Loss: 0.08539824, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00054616, Test Loss: 0.08539531, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00049441, Test Loss: 0.08542199, Test Accuracy: 0.98160000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00045275, Test Loss: 0.08548262, Test Accuracy: 0.98160000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00041836, Test Loss: 0.08556846, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00038937, Test Loss: 0.08567110, Test Accuracy: 0.98190000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00036448, Test Loss: 0.08578502, Test Accuracy: 0.98190000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00034282, Test Loss: 0.08590660, Test Accuracy: 0.98210000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00032376, Test Loss: 0.08603345, Test Accuracy: 0.98230000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00030682, Test Loss: 0.08616379, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00029164, Test Loss: 0.08629634, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00027797, Test Loss: 0.08643002, Test Accuracy: 0.98250000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00026557, Test Loss: 0.08656393, Test Accuracy: 0.98240000\n",
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.20938186, Test Loss: 0.11703211, Test Accuracy: 0.96480000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08395440, Test Loss: 0.11241318, Test Accuracy: 0.96800000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05590488, Test Loss: 0.11041457, Test Accuracy: 0.97000000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03933443, Test Loss: 0.11409970, Test Accuracy: 0.97050000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03138920, Test Loss: 0.10292866, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02308300, Test Loss: 0.10954789, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01888512, Test Loss: 0.11683686, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01500245, Test Loss: 0.12091569, Test Accuracy: 0.97690000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01264942, Test Loss: 0.12194267, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01117567, Test Loss: 0.12024219, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00933946, Test Loss: 0.12338364, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00944955, Test Loss: 0.12042330, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00829113, Test Loss: 0.12416140, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00793827, Test Loss: 0.14385392, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00665671, Test Loss: 0.16361448, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00511095, Test Loss: 0.15650522, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00491642, Test Loss: 0.14512535, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00548375, Test Loss: 0.15871758, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00452817, Test Loss: 0.15534585, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00375720, Test Loss: 0.15348661, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00338705, Test Loss: 0.15752427, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00371793, Test Loss: 0.16294457, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00297492, Test Loss: 0.16607953, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00228997, Test Loss: 0.15936846, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00256536, Test Loss: 0.15753037, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00242267, Test Loss: 0.15943528, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00188278, Test Loss: 0.17328722, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00265545, Test Loss: 0.16812738, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00294246, Test Loss: 0.17739207, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00190657, Test Loss: 0.18045364, Test Accuracy: 0.98010000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMBxYrmxdy98",
        "outputId": "d84650fb-c6f8-4a5e-ed31-9f48ff1b8308"
      },
      "source": [
        "torch.manual_seed(100)\n",
        "np.random.seed(100)\n",
        "\n",
        "# Adadelta\n",
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity_avg, sparsity_std, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"seed100_5subsebatch1_sparsity_selectivity_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_5subsebatch1_sparsity_selectivity_Adadelta.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adagrad \n",
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity_avg, sparsity_std, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"seed100_5subsebatch1_sparsity_selectivity_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_5subsebatch1_sparsity_selectivity_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# SGD \n",
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity_avg, sparsity_std, SGD_avg_selectivity_list, SGD_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"seed100_5subsebatch1_sparsity_selectivity_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_5subsebatch1_sparsity_selectivity_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "# Adam \n",
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity_avg, sparsity_std, Adam_avg_selectivity_list, Adam_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"seed100_5subsebatch1_sparsity_selectivity_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_5subsebatch1_sparsity_selectivity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.29328095, Test Loss: 0.22601874, Test Accuracy: 0.94380000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.17653258, Test Loss: 0.17209419, Test Accuracy: 0.95790000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.13797354, Test Loss: 0.14892647, Test Accuracy: 0.96530000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.11654460, Test Loss: 0.13907567, Test Accuracy: 0.96730000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.10242531, Test Loss: 0.13446771, Test Accuracy: 0.96830000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.09121820, Test Loss: 0.12896524, Test Accuracy: 0.96880000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.08324886, Test Loss: 0.12304683, Test Accuracy: 0.97120000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.07679751, Test Loss: 0.11883026, Test Accuracy: 0.97190000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.07125347, Test Loss: 0.11557792, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.06667797, Test Loss: 0.11289365, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.06279663, Test Loss: 0.11435389, Test Accuracy: 0.97420000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.05923013, Test Loss: 0.11661209, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.05631588, Test Loss: 0.11905612, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.05344486, Test Loss: 0.12018159, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.05079576, Test Loss: 0.12207807, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.04835246, Test Loss: 0.12450982, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.04618198, Test Loss: 0.12773956, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.04417337, Test Loss: 0.12694491, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.04202942, Test Loss: 0.12844222, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.04015269, Test Loss: 0.12949401, Test Accuracy: 0.97350000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.03851224, Test Loss: 0.12960340, Test Accuracy: 0.97300000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.03705193, Test Loss: 0.12795679, Test Accuracy: 0.97250000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.03546503, Test Loss: 0.12521904, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.03407291, Test Loss: 0.12562355, Test Accuracy: 0.97360000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.03259026, Test Loss: 0.12502102, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.03109877, Test Loss: 0.12511702, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.02953194, Test Loss: 0.12563608, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.02816521, Test Loss: 0.12645926, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.02707506, Test Loss: 0.12725190, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.02596476, Test Loss: 0.12653030, Test Accuracy: 0.97420000\n",
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.18225019, Test Loss: 0.12515629, Test Accuracy: 0.96310000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.07991053, Test Loss: 0.09854918, Test Accuracy: 0.97030000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05283680, Test Loss: 0.08691553, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03780579, Test Loss: 0.08062086, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.02833598, Test Loss: 0.07701330, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02171241, Test Loss: 0.07438356, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01700481, Test Loss: 0.07292095, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01359378, Test Loss: 0.07191111, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01104281, Test Loss: 0.07124521, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00912692, Test Loss: 0.07123402, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00765834, Test Loss: 0.07090549, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00650148, Test Loss: 0.07073638, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00557563, Test Loss: 0.07083629, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00484609, Test Loss: 0.07108004, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00425981, Test Loss: 0.07138326, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00378957, Test Loss: 0.07164433, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00337556, Test Loss: 0.07199773, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00303955, Test Loss: 0.07232241, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00275285, Test Loss: 0.07260722, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00250888, Test Loss: 0.07279712, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00230256, Test Loss: 0.07297822, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00212210, Test Loss: 0.07312276, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00196562, Test Loss: 0.07326810, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00182921, Test Loss: 0.07341494, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00170870, Test Loss: 0.07355981, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00160068, Test Loss: 0.07368884, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00150404, Test Loss: 0.07380317, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00141785, Test Loss: 0.07391599, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00134030, Test Loss: 0.07402473, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00127013, Test Loss: 0.07413223, Test Accuracy: 0.97980000\n",
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.21673248, Test Loss: 0.13347536, Test Accuracy: 0.95860000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.10004218, Test Loss: 0.10923160, Test Accuracy: 0.96620000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.06665815, Test Loss: 0.10634569, Test Accuracy: 0.96710000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.04784525, Test Loss: 0.11114334, Test Accuracy: 0.96660000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03610760, Test Loss: 0.11782154, Test Accuracy: 0.96590000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02757099, Test Loss: 0.10830532, Test Accuracy: 0.97030000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01986105, Test Loss: 0.10246942, Test Accuracy: 0.97210000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01629357, Test Loss: 0.10659957, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01138441, Test Loss: 0.10133951, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00983790, Test Loss: 0.10012310, Test Accuracy: 0.97500000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00628569, Test Loss: 0.09441609, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00338620, Test Loss: 0.08930707, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00213690, Test Loss: 0.08787302, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00138239, Test Loss: 0.08832311, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00099071, Test Loss: 0.09002784, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00079478, Test Loss: 0.09066571, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00067438, Test Loss: 0.09124838, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00059275, Test Loss: 0.09183571, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00053111, Test Loss: 0.09236276, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00048262, Test Loss: 0.09283127, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00044321, Test Loss: 0.09325377, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00041041, Test Loss: 0.09364044, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00038258, Test Loss: 0.09399794, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00035862, Test Loss: 0.09433102, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00033773, Test Loss: 0.09464320, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00031931, Test Loss: 0.09493731, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00030293, Test Loss: 0.09521563, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00028825, Test Loss: 0.09547985, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00027501, Test Loss: 0.09573147, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00026298, Test Loss: 0.09597183, Test Accuracy: 0.98080000\n",
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.20809795, Test Loss: 0.11030398, Test Accuracy: 0.96610000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08369731, Test Loss: 0.10491784, Test Accuracy: 0.97010000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05486216, Test Loss: 0.10304877, Test Accuracy: 0.97010000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03961749, Test Loss: 0.09594804, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.02816726, Test Loss: 0.09704994, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02230963, Test Loss: 0.10855475, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01794436, Test Loss: 0.11188987, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01453934, Test Loss: 0.11398527, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01315811, Test Loss: 0.11985361, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01068882, Test Loss: 0.13532382, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00974177, Test Loss: 0.14949278, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00893715, Test Loss: 0.15009542, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00729876, Test Loss: 0.14951752, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00667245, Test Loss: 0.13928409, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00682627, Test Loss: 0.14381648, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00589462, Test Loss: 0.15343296, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00542982, Test Loss: 0.15011951, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00542449, Test Loss: 0.16028726, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00427278, Test Loss: 0.16723565, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00428136, Test Loss: 0.18333773, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00494243, Test Loss: 0.19098705, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00368358, Test Loss: 0.17125605, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00319709, Test Loss: 0.18292769, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00363101, Test Loss: 0.19691058, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00313639, Test Loss: 0.21913369, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00222630, Test Loss: 0.20049769, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00230239, Test Loss: 0.20812364, Test Accuracy: 0.97700000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00210674, Test Loss: 0.21613832, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00188782, Test Loss: 0.23152671, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00171195, Test Loss: 0.20334981, Test Accuracy: 0.97900000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2aPi5pqdzCV",
        "outputId": "dc394ec8-5f5b-4838-94a8-2f2a53089351"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Adadelta\n",
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity_avg, sparsity_std, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"seed1234_5subsebatch1_sparsity_selectivity_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_5subsebatch1_sparsity_selectivity_Adadelta.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adagrad \n",
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity_avg, sparsity_std, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"seed1234_5subsebatch1_sparsity_selectivity_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_5subsebatch1_sparsity_selectivity_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# SGD \n",
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity_avg, sparsity_std, SGD_avg_selectivity_list, SGD_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"seed1234_5subsebatch1_sparsity_selectivity_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_5subsebatch1_sparsity_selectivity_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "# Adam \n",
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity_avg, sparsity_std, Adam_avg_selectivity_list, Adam_std_selectivity_list = sparsity_selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"seed1234_5subsebatch1_sparsity_selectivity_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(sparsity_avg)+'\\n'+str(sparsity_std)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_5subsebatch1_sparsity_selectivity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.29468351, Test Loss: 0.21551923, Test Accuracy: 0.94580000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.16993477, Test Loss: 0.15897061, Test Accuracy: 0.95990000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.12974884, Test Loss: 0.13750301, Test Accuracy: 0.96600000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.10831529, Test Loss: 0.12773440, Test Accuracy: 0.96770000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.09493432, Test Loss: 0.12442521, Test Accuracy: 0.96940000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.08570489, Test Loss: 0.11829418, Test Accuracy: 0.97050000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.07826657, Test Loss: 0.11216141, Test Accuracy: 0.97130000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.07263243, Test Loss: 0.11143315, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.06786906, Test Loss: 0.11216831, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.06337444, Test Loss: 0.11233818, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.05925049, Test Loss: 0.11358280, Test Accuracy: 0.97330000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.05555891, Test Loss: 0.11492784, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.05238701, Test Loss: 0.11701597, Test Accuracy: 0.97340000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.04965999, Test Loss: 0.11809224, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.04719142, Test Loss: 0.11658261, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.04483978, Test Loss: 0.11618621, Test Accuracy: 0.97320000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.04274523, Test Loss: 0.11769252, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.04092169, Test Loss: 0.11835453, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.03933993, Test Loss: 0.11891748, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.03783383, Test Loss: 0.11838981, Test Accuracy: 0.97480000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.03672404, Test Loss: 0.11946066, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.03563097, Test Loss: 0.12084959, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.03451139, Test Loss: 0.12282771, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.03335736, Test Loss: 0.12398644, Test Accuracy: 0.97400000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.03217696, Test Loss: 0.12474883, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.03098764, Test Loss: 0.12475500, Test Accuracy: 0.97350000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.02982751, Test Loss: 0.12482069, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.02877874, Test Loss: 0.12622040, Test Accuracy: 0.97390000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.02779303, Test Loss: 0.12716511, Test Accuracy: 0.97370000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.02678769, Test Loss: 0.12777678, Test Accuracy: 0.97310000\n",
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.18205275, Test Loss: 0.11799909, Test Accuracy: 0.96530000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08182485, Test Loss: 0.09539088, Test Accuracy: 0.97090000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05458401, Test Loss: 0.08506123, Test Accuracy: 0.97340000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03933084, Test Loss: 0.07967884, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.02942115, Test Loss: 0.07628478, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02248237, Test Loss: 0.07406699, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01749772, Test Loss: 0.07275408, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01394842, Test Loss: 0.07198125, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01134261, Test Loss: 0.07161008, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00939205, Test Loss: 0.07151451, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00786811, Test Loss: 0.07154289, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00668409, Test Loss: 0.07159993, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00573072, Test Loss: 0.07150503, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00495681, Test Loss: 0.07137363, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00434179, Test Loss: 0.07145523, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00382407, Test Loss: 0.07151807, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00340549, Test Loss: 0.07171713, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00306070, Test Loss: 0.07198259, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00276902, Test Loss: 0.07224705, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00252507, Test Loss: 0.07250469, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00230700, Test Loss: 0.07275084, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00212293, Test Loss: 0.07297740, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00196164, Test Loss: 0.07323854, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00181960, Test Loss: 0.07350879, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00169422, Test Loss: 0.07375790, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00158280, Test Loss: 0.07397971, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00148279, Test Loss: 0.07417158, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00139171, Test Loss: 0.07434022, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00130924, Test Loss: 0.07450923, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00123696, Test Loss: 0.07466630, Test Accuracy: 0.98050000\n",
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.21642799, Test Loss: 0.13698695, Test Accuracy: 0.95650000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.09939511, Test Loss: 0.11285068, Test Accuracy: 0.96550000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.06610891, Test Loss: 0.11770102, Test Accuracy: 0.96400000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.04517997, Test Loss: 0.10375733, Test Accuracy: 0.96820000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.03486865, Test Loss: 0.10120756, Test Accuracy: 0.97270000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02672732, Test Loss: 0.09237981, Test Accuracy: 0.97590000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.02043507, Test Loss: 0.10346184, Test Accuracy: 0.97200000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01606111, Test Loss: 0.09450436, Test Accuracy: 0.97520000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01280120, Test Loss: 0.09592539, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.00902019, Test Loss: 0.09608682, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.00572852, Test Loss: 0.09192586, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00422937, Test Loss: 0.09229441, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00355319, Test Loss: 0.09204437, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00182968, Test Loss: 0.09046921, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00118722, Test Loss: 0.08958554, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00085929, Test Loss: 0.08973614, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00071283, Test Loss: 0.09001525, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00062132, Test Loss: 0.09021002, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00055538, Test Loss: 0.09038247, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00050400, Test Loss: 0.09054299, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00046225, Test Loss: 0.09069495, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00042742, Test Loss: 0.09083992, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00039780, Test Loss: 0.09097907, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00037226, Test Loss: 0.09111349, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00034996, Test Loss: 0.09124397, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00033032, Test Loss: 0.09137126, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00031288, Test Loss: 0.09149609, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00029726, Test Loss: 0.09161887, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00028319, Test Loss: 0.09174002, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00027045, Test Loss: 0.09185979, Test Accuracy: 0.98120000\n",
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/30, Train Loss: 0.21027736, Test Loss: 0.11396879, Test Accuracy: 0.96560000\n",
            "\n",
            "Epoch: 2/30, Train Loss: 0.08443139, Test Loss: 0.12573462, Test Accuracy: 0.96490000\n",
            "\n",
            "Epoch: 3/30, Train Loss: 0.05443311, Test Loss: 0.10013102, Test Accuracy: 0.97250000\n",
            "\n",
            "Epoch: 4/30, Train Loss: 0.03809932, Test Loss: 0.10226496, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 5/30, Train Loss: 0.02791901, Test Loss: 0.10333818, Test Accuracy: 0.97610000\n",
            "\n",
            "Epoch: 6/30, Train Loss: 0.02180507, Test Loss: 0.12593256, Test Accuracy: 0.97200000\n",
            "\n",
            "Epoch: 7/30, Train Loss: 0.01816117, Test Loss: 0.12733417, Test Accuracy: 0.97310000\n",
            "\n",
            "Epoch: 8/30, Train Loss: 0.01443859, Test Loss: 0.13072205, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 9/30, Train Loss: 0.01344358, Test Loss: 0.12650567, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 10/30, Train Loss: 0.01136676, Test Loss: 0.13965019, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 11/30, Train Loss: 0.01070074, Test Loss: 0.14316940, Test Accuracy: 0.97670000\n",
            "\n",
            "Epoch: 12/30, Train Loss: 0.00904946, Test Loss: 0.14612554, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 13/30, Train Loss: 0.00955694, Test Loss: 0.15412143, Test Accuracy: 0.97580000\n",
            "\n",
            "Epoch: 14/30, Train Loss: 0.00717960, Test Loss: 0.13077629, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 15/30, Train Loss: 0.00509850, Test Loss: 0.14536444, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 16/30, Train Loss: 0.00487012, Test Loss: 0.13974073, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 17/30, Train Loss: 0.00534362, Test Loss: 0.16811736, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 18/30, Train Loss: 0.00473905, Test Loss: 0.16352848, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 19/30, Train Loss: 0.00430597, Test Loss: 0.17481484, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 20/30, Train Loss: 0.00319990, Test Loss: 0.17655627, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 21/30, Train Loss: 0.00463349, Test Loss: 0.17776753, Test Accuracy: 0.97710000\n",
            "\n",
            "Epoch: 22/30, Train Loss: 0.00248820, Test Loss: 0.17364453, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 23/30, Train Loss: 0.00299227, Test Loss: 0.16325603, Test Accuracy: 0.98200000\n",
            "\n",
            "Epoch: 24/30, Train Loss: 0.00297922, Test Loss: 0.18069420, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 25/30, Train Loss: 0.00267377, Test Loss: 0.17155096, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 26/30, Train Loss: 0.00402778, Test Loss: 0.19318219, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 27/30, Train Loss: 0.00295781, Test Loss: 0.19273322, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 28/30, Train Loss: 0.00252329, Test Loss: 0.19717679, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 29/30, Train Loss: 0.00166103, Test Loss: 0.22220400, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 30/30, Train Loss: 0.00181171, Test Loss: 0.20970454, Test Accuracy: 0.97850000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}