{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparsity_sorted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/sparsity_sorted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7STrWa0P3z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406c71cf-4210-4eed-81cb-e97ba0af7ceb"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An-NVJcEfVG-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tke0vosw9vt4"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = datasets.MNIST(root='./data', \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4kam-UrTxNl"
      },
      "source": [
        "new_mnist_trainset =  [ [[],[]] for i in range(10)]\n",
        "new_mnist_testset  =  [ [[],[]] for i in range(10)]\n",
        "\n",
        "for i in range(60000):\n",
        "    for j in range(10):\n",
        "        if mnist_trainset[i][1] == j:\n",
        "            # image \n",
        "            new_mnist_trainset[j][0].append(mnist_trainset[i][0])  \n",
        "            # label\n",
        "            new_mnist_trainset[j][1].append(mnist_trainset[i][1])\n",
        "\n",
        "for i in range(10000):\n",
        "    for j in range(10):\n",
        "        if mnist_testset[i][1] == j:\n",
        "            # image \n",
        "            new_mnist_testset[j][0].append(mnist_testset[i][0])  \n",
        "            # label\n",
        "            new_mnist_testset[j][1].append(mnist_testset[i][1])\n",
        "\n",
        "image_trainset = list()\n",
        "label_trainset = list()\n",
        "\n",
        "image_testset = list()\n",
        "label_testset = list()\n",
        "\n",
        "for i in range(10):\n",
        "    image_trainset.append(new_mnist_trainset[i][0])\n",
        "    label_trainset.append(new_mnist_trainset[i][1])\n",
        "\n",
        "for i in range(10):\n",
        "    image_testset.append(new_mnist_testset[i][0])\n",
        "    label_testset.append(new_mnist_testset[i][1])\n",
        "\n",
        "flattened_image_train = list()\n",
        "flattened_label_train = list()\n",
        "\n",
        "flattened_image_test = list()\n",
        "flattened_label_test = list()\n",
        "\n",
        "# flattening image \n",
        "for sublist in image_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_image_train.append(val)\n",
        "\n",
        "# flattening label\n",
        "for sublist in label_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_label_train.append(val)\n",
        "\n",
        "# flattening image \n",
        "for sublist in image_testset:\n",
        "    for val in sublist:\n",
        "        flattened_image_test.append(val)\n",
        "\n",
        "# flattening label\n",
        "for sublist in label_testset:\n",
        "    for val in sublist:\n",
        "        flattened_label_test.append(val)\n",
        "\n",
        "flattened_image_train = torch.stack(flattened_image_train)\n",
        "flattened_label_train = torch.Tensor(flattened_label_train)\n",
        "flattened_label_train = flattened_label_train.type(torch.LongTensor)\n",
        "\n",
        "flattened_image_test = torch.stack(flattened_image_test)\n",
        "flattened_label_test = torch.Tensor(flattened_label_test)\n",
        "flattened_label_test = flattened_label_test.type(torch.LongTensor)\n",
        "\n",
        "train_dataset = TensorDataset(flattened_image_train, flattened_label_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=50)\n",
        "\n",
        "test_dataset = TensorDataset(flattened_image_test, flattened_label_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=50)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 100\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "def sparsity_trainer(optimizer, model):\n",
        "\n",
        "    # reset the model \n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "    final_spareness = list()\n",
        "\n",
        "    # define activation list \n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        hidden_layer_activation_list = list()\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "        for itr, (image, label) in enumerate(train_dataloader):\n",
        "\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(image)\n",
        "\n",
        "            loss = criterion(pred, label)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (image, label) in enumerate(test_dataloader):\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "\n",
        "            loss = criterion(pred, label)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if label[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            hidden_layer_activation_list.append(model.layer_activations)\n",
        "\n",
        "        # this conains activations for all epochs \n",
        "        final_spareness.append(hidden_layer_activation_list)\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "        # if total_test_loss < best_test_loss:\n",
        "        #     best_test_loss = total_test_loss\n",
        "            # print(\"Saving the model state dictionary for Epoch: {} with Test loss: {:.8f}\".format(epoch + 1, total_test_loss))\n",
        "            # torch.save(model.state_dict(), \"model.dth\")\n",
        "\n",
        "    sparseness_list = list()\n",
        "\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "        single_epoch_spareness = torch.stack(single_epoch_spareness)\n",
        "        layer_activations_list = torch.reshape(single_epoch_spareness, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return test_acc, sparseness_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# AdaDelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOb5LovDJjur"
      },
      "source": [
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, Adadelta_sparseness_list = sparsity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"sorted_sparsity_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(Adadelta_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp sorted_sparsity_Adadelta.txt /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXfQe4vMDKB"
      },
      "source": [
        "# AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb-4TPM5MGuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb759c5-5595-49eb-c8e4-c393fd7957c5"
      },
      "source": [
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, Adagrad_sparseness_list = sparsity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"sorted_sparsity_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(Adagrad_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp sorted_sparsity_Adagrad.txt /content/drive/MyDrive"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.13042085, Test Loss: 7.76099041, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09620166, Test Loss: 5.50175055, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.05869379, Test Loss: 4.44656160, Test Accuracy: 0.11530000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.04409782, Test Loss: 4.14679875, Test Accuracy: 0.20030000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.03957421, Test Loss: 3.77036806, Test Accuracy: 0.25950000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.03484181, Test Loss: 3.69523550, Test Accuracy: 0.26800000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.03376216, Test Loss: 3.49587878, Test Accuracy: 0.29890000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.03238552, Test Loss: 3.25392948, Test Accuracy: 0.32170000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.03214524, Test Loss: 3.15860640, Test Accuracy: 0.35740000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.03076729, Test Loss: 3.01343359, Test Accuracy: 0.36730000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.02971740, Test Loss: 2.92935481, Test Accuracy: 0.37980000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.02846869, Test Loss: 2.87473151, Test Accuracy: 0.39610000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.02802577, Test Loss: 2.76391899, Test Accuracy: 0.40360000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.02684719, Test Loss: 2.57556619, Test Accuracy: 0.40900000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.02638409, Test Loss: 2.66438081, Test Accuracy: 0.42210000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.02517885, Test Loss: 2.38533362, Test Accuracy: 0.45060000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.02460295, Test Loss: 2.38308185, Test Accuracy: 0.45140000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.02362544, Test Loss: 2.22032112, Test Accuracy: 0.47330000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.02412544, Test Loss: 2.14633689, Test Accuracy: 0.48190000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.02321929, Test Loss: 2.10256314, Test Accuracy: 0.49210000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.02187667, Test Loss: 2.09769105, Test Accuracy: 0.49130000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.02092471, Test Loss: 1.97839405, Test Accuracy: 0.51720000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.01979493, Test Loss: 2.18259133, Test Accuracy: 0.47460000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.01873413, Test Loss: 2.06154089, Test Accuracy: 0.49160000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.01873686, Test Loss: 1.86905994, Test Accuracy: 0.53150000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.01885119, Test Loss: 1.79169918, Test Accuracy: 0.53660000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.01802162, Test Loss: 1.72872767, Test Accuracy: 0.54580000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.01735746, Test Loss: 1.82122361, Test Accuracy: 0.53080000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.01647207, Test Loss: 1.73831292, Test Accuracy: 0.54620000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01533644, Test Loss: 1.93511474, Test Accuracy: 0.52380000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01494211, Test Loss: 1.64331100, Test Accuracy: 0.57580000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01459872, Test Loss: 1.66620541, Test Accuracy: 0.56460000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01434371, Test Loss: 1.58220633, Test Accuracy: 0.57340000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01363854, Test Loss: 1.50581342, Test Accuracy: 0.59370000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.01370832, Test Loss: 1.55081447, Test Accuracy: 0.58230000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.01345523, Test Loss: 1.54433628, Test Accuracy: 0.58470000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.01297670, Test Loss: 1.37382519, Test Accuracy: 0.62050000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.01228041, Test Loss: 1.45171266, Test Accuracy: 0.60450000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.01222946, Test Loss: 1.36928537, Test Accuracy: 0.61720000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.01231905, Test Loss: 1.33747089, Test Accuracy: 0.62390000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.01170529, Test Loss: 1.32143641, Test Accuracy: 0.62480000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.01188117, Test Loss: 1.34352832, Test Accuracy: 0.62380000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.01172292, Test Loss: 1.32569038, Test Accuracy: 0.63180000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.01125272, Test Loss: 1.29471798, Test Accuracy: 0.64220000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.01124346, Test Loss: 1.26548086, Test Accuracy: 0.64820000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.01096534, Test Loss: 1.20977093, Test Accuracy: 0.66040000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.01049442, Test Loss: 1.25165228, Test Accuracy: 0.65180000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.01025322, Test Loss: 1.19805687, Test Accuracy: 0.66580000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00986333, Test Loss: 1.16457822, Test Accuracy: 0.67620000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00947773, Test Loss: 1.15761508, Test Accuracy: 0.67930000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00953074, Test Loss: 1.11278715, Test Accuracy: 0.68860000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00968601, Test Loss: 1.07530797, Test Accuracy: 0.69930000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00946399, Test Loss: 1.07472580, Test Accuracy: 0.69960000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00935020, Test Loss: 1.04333491, Test Accuracy: 0.70950000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00907732, Test Loss: 1.05992466, Test Accuracy: 0.70940000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00861467, Test Loss: 1.02729252, Test Accuracy: 0.71540000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00897244, Test Loss: 1.02421077, Test Accuracy: 0.71770000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00876957, Test Loss: 1.01131936, Test Accuracy: 0.72200000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00871610, Test Loss: 0.98995184, Test Accuracy: 0.72830000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00842616, Test Loss: 0.96137595, Test Accuracy: 0.73550000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00858039, Test Loss: 1.01942260, Test Accuracy: 0.71900000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00785823, Test Loss: 1.01873872, Test Accuracy: 0.72400000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00791547, Test Loss: 1.11015783, Test Accuracy: 0.71440000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00762284, Test Loss: 0.92576527, Test Accuracy: 0.74690000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00764514, Test Loss: 0.94280599, Test Accuracy: 0.74530000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00742219, Test Loss: 0.91056664, Test Accuracy: 0.75130000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00738832, Test Loss: 0.85808746, Test Accuracy: 0.76100000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00746947, Test Loss: 0.83145397, Test Accuracy: 0.76580000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00716344, Test Loss: 0.78611451, Test Accuracy: 0.77960000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00727398, Test Loss: 0.80011565, Test Accuracy: 0.77690000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00681546, Test Loss: 0.78552984, Test Accuracy: 0.78090000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00671543, Test Loss: 0.77404678, Test Accuracy: 0.78390000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00676629, Test Loss: 0.76562431, Test Accuracy: 0.78600000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00648315, Test Loss: 0.74885307, Test Accuracy: 0.79120000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00626508, Test Loss: 0.72800530, Test Accuracy: 0.79760000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00633550, Test Loss: 0.72955974, Test Accuracy: 0.79510000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00633989, Test Loss: 0.71498366, Test Accuracy: 0.80030000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00619708, Test Loss: 0.71668832, Test Accuracy: 0.79970000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00584506, Test Loss: 0.75209648, Test Accuracy: 0.79380000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00601190, Test Loss: 0.67867461, Test Accuracy: 0.81230000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00595556, Test Loss: 0.67329091, Test Accuracy: 0.81320000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00602206, Test Loss: 0.64990165, Test Accuracy: 0.81960000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00601115, Test Loss: 0.63389718, Test Accuracy: 0.82260000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00562793, Test Loss: 0.60606260, Test Accuracy: 0.82940000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00550527, Test Loss: 0.62599370, Test Accuracy: 0.82330000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00548445, Test Loss: 0.60750851, Test Accuracy: 0.82800000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00535401, Test Loss: 0.60375681, Test Accuracy: 0.82940000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00539700, Test Loss: 0.58508025, Test Accuracy: 0.83350000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00540660, Test Loss: 0.57241656, Test Accuracy: 0.83640000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00538887, Test Loss: 0.55943046, Test Accuracy: 0.83960000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00535751, Test Loss: 0.54716942, Test Accuracy: 0.84360000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00531117, Test Loss: 0.53513718, Test Accuracy: 0.84570000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00520604, Test Loss: 0.51491232, Test Accuracy: 0.84890000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00506719, Test Loss: 0.52477503, Test Accuracy: 0.84790000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00496770, Test Loss: 0.51782446, Test Accuracy: 0.85000000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00498755, Test Loss: 0.50994488, Test Accuracy: 0.85150000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00504415, Test Loss: 0.49477731, Test Accuracy: 0.85500000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00496985, Test Loss: 0.49142738, Test Accuracy: 0.85600000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00466606, Test Loss: 0.47064376, Test Accuracy: 0.86140000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00477999, Test Loss: 0.47960173, Test Accuracy: 0.86020000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLJ4Zr2MnoS"
      },
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ObsEJHuMoPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a99c73a-c038-4b03-b42f-da659e890839"
      },
      "source": [
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, SGD_sparseness_list = sparsity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"sorted_sparsity_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(SGD_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp sorted_sparsity_SGD.txt /content/drive/MyDrive"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.07253962, Test Loss: 8.02195539, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09554920, Test Loss: 7.73677037, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.10922550, Test Loss: 7.40246572, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.10637859, Test Loss: 6.74322132, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.09017775, Test Loss: 5.89124400, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.07428950, Test Loss: 5.22766732, Test Accuracy: 0.10700000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.06468045, Test Loss: 4.79500967, Test Accuracy: 0.13470000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.05956198, Test Loss: 4.49108117, Test Accuracy: 0.16080000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.05663111, Test Loss: 4.25804609, Test Accuracy: 0.18370000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.05470896, Test Loss: 4.07131077, Test Accuracy: 0.20090000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.05330784, Test Loss: 3.92045050, Test Accuracy: 0.21560000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.05222874, Test Loss: 3.79943130, Test Accuracy: 0.22620000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.05137753, Test Loss: 3.70307529, Test Accuracy: 0.23470000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.05069927, Test Loss: 3.62634479, Test Accuracy: 0.24310000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05015527, Test Loss: 3.56454448, Test Accuracy: 0.25050000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.04971492, Test Loss: 3.51371374, Test Accuracy: 0.25740000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.04935312, Test Loss: 3.47084069, Test Accuracy: 0.26270000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.04904947, Test Loss: 3.43382648, Test Accuracy: 0.26750000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04878773, Test Loss: 3.40128429, Test Accuracy: 0.27160000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.04855541, Test Loss: 3.37227339, Test Accuracy: 0.27490000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.04834350, Test Loss: 3.34608041, Test Accuracy: 0.27780000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.04814626, Test Loss: 3.32207639, Test Accuracy: 0.28160000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.04796098, Test Loss: 3.29964097, Test Accuracy: 0.28340000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.04778767, Test Loss: 3.27814823, Test Accuracy: 0.28640000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.04762828, Test Loss: 3.25700436, Test Accuracy: 0.29110000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.04748557, Test Loss: 3.23571397, Test Accuracy: 0.29330000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.04736195, Test Loss: 3.21393053, Test Accuracy: 0.29550000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.04725881, Test Loss: 3.19145545, Test Accuracy: 0.29770000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.04717604, Test Loss: 3.16819759, Test Accuracy: 0.30090000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.04711209, Test Loss: 3.14413101, Test Accuracy: 0.30330000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.04706431, Test Loss: 3.11926097, Test Accuracy: 0.30620000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.04702942, Test Loss: 3.09360812, Test Accuracy: 0.30970000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.04700385, Test Loss: 3.06719689, Test Accuracy: 0.31290000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.04698369, Test Loss: 3.04006793, Test Accuracy: 0.31660000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.04696410, Test Loss: 3.01227896, Test Accuracy: 0.32070000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.04693894, Test Loss: 2.98393726, Test Accuracy: 0.32400000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.04690157, Test Loss: 2.95521583, Test Accuracy: 0.32720000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.04684656, Test Loss: 2.92631213, Test Accuracy: 0.33120000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.04677104, Test Loss: 2.89736253, Test Accuracy: 0.33690000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.04667484, Test Loss: 2.86837274, Test Accuracy: 0.34200000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.04655988, Test Loss: 2.83920133, Test Accuracy: 0.34670000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.04642935, Test Loss: 2.80959262, Test Accuracy: 0.35180000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.04628709, Test Loss: 2.77924730, Test Accuracy: 0.35610000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.04613665, Test Loss: 2.74792996, Test Accuracy: 0.36040000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.04598034, Test Loss: 2.71562522, Test Accuracy: 0.36530000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.04581877, Test Loss: 2.68267519, Test Accuracy: 0.36980000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.04565119, Test Loss: 2.64974117, Test Accuracy: 0.37410000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.04547670, Test Loss: 2.61745380, Test Accuracy: 0.37780000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.04529510, Test Loss: 2.58604882, Test Accuracy: 0.38120000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.04510654, Test Loss: 2.55549393, Test Accuracy: 0.38620000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.04491038, Test Loss: 2.52584449, Test Accuracy: 0.38950000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.04470459, Test Loss: 2.49731696, Test Accuracy: 0.39230000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.04448639, Test Loss: 2.47015087, Test Accuracy: 0.39540000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.04425388, Test Loss: 2.44447678, Test Accuracy: 0.39960000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.04400772, Test Loss: 2.42024227, Test Accuracy: 0.40240000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.04375116, Test Loss: 2.39718308, Test Accuracy: 0.40530000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.04348712, Test Loss: 2.37486868, Test Accuracy: 0.40840000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.04321392, Test Loss: 2.35283932, Test Accuracy: 0.41260000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.04292796, Test Loss: 2.33071455, Test Accuracy: 0.41590000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.04263058, Test Loss: 2.30820647, Test Accuracy: 0.41970000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.04232634, Test Loss: 2.28514250, Test Accuracy: 0.42420000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.04201858, Test Loss: 2.26147088, Test Accuracy: 0.42770000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.04170829, Test Loss: 2.23722485, Test Accuracy: 0.43160000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.04139494, Test Loss: 2.21245322, Test Accuracy: 0.43620000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.04107787, Test Loss: 2.18718621, Test Accuracy: 0.44040000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.04075701, Test Loss: 2.16141528, Test Accuracy: 0.44380000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.04043291, Test Loss: 2.13507660, Test Accuracy: 0.44760000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.04010641, Test Loss: 2.10805141, Test Accuracy: 0.45150000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.03977822, Test Loss: 2.08022002, Test Accuracy: 0.45580000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.03944843, Test Loss: 2.05154523, Test Accuracy: 0.46050000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.03911638, Test Loss: 2.02211234, Test Accuracy: 0.46480000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.03878096, Test Loss: 1.99209397, Test Accuracy: 0.47030000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.03844162, Test Loss: 1.96170227, Test Accuracy: 0.47480000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.03809858, Test Loss: 1.93118480, Test Accuracy: 0.48070000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.03775238, Test Loss: 1.90081826, Test Accuracy: 0.48630000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.03740365, Test Loss: 1.87088798, Test Accuracy: 0.49190000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.03705316, Test Loss: 1.84166064, Test Accuracy: 0.49800000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.03670194, Test Loss: 1.81338070, Test Accuracy: 0.50240000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.03635117, Test Loss: 1.78626670, Test Accuracy: 0.50800000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.03600213, Test Loss: 1.76048034, Test Accuracy: 0.51250000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.03565654, Test Loss: 1.73604605, Test Accuracy: 0.51700000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.03531660, Test Loss: 1.71280696, Test Accuracy: 0.52020000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.03498484, Test Loss: 1.69049751, Test Accuracy: 0.52440000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.03466317, Test Loss: 1.66886987, Test Accuracy: 0.52810000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.03435223, Test Loss: 1.64775193, Test Accuracy: 0.53210000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.03405128, Test Loss: 1.62702122, Test Accuracy: 0.53580000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.03375856, Test Loss: 1.60657410, Test Accuracy: 0.54060000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.03347170, Test Loss: 1.58631746, Test Accuracy: 0.54500000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.03318818, Test Loss: 1.56617983, Test Accuracy: 0.54970000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.03290573, Test Loss: 1.54613228, Test Accuracy: 0.55370000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.03262263, Test Loss: 1.52618953, Test Accuracy: 0.55880000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.03233790, Test Loss: 1.50640269, Test Accuracy: 0.56390000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.03205123, Test Loss: 1.48682708, Test Accuracy: 0.56830000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.03176285, Test Loss: 1.46750518, Test Accuracy: 0.57320000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.03147329, Test Loss: 1.44845436, Test Accuracy: 0.57800000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.03118331, Test Loss: 1.42967410, Test Accuracy: 0.58330000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.03089373, Test Loss: 1.41115243, Test Accuracy: 0.58860000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.03060543, Test Loss: 1.39287676, Test Accuracy: 0.59410000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.03031924, Test Loss: 1.37484192, Test Accuracy: 0.59950000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.03003590, Test Loss: 1.35705408, Test Accuracy: 0.60450000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQxaN_fRXLq"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY35Kab0EeRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f7c0d2-e5e8-4646-a5d3-68dfd6bc1801"
      },
      "source": [
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, Adam_sparseness_list = sparsity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"sorted_sparsity_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(Adam_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp sorted_sparsity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.99978316, Test Loss: 4.81287643, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.55548300, Test Loss: 4.14184658, Test Accuracy: 0.12030000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.20939031, Test Loss: 4.29071359, Test Accuracy: 0.20760000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.13790907, Test Loss: 4.56007608, Test Accuracy: 0.26640000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.12020153, Test Loss: 4.44719206, Test Accuracy: 0.27330000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.10811880, Test Loss: 4.71846524, Test Accuracy: 0.29840000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.09789141, Test Loss: 4.87918231, Test Accuracy: 0.30630000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.08637559, Test Loss: 4.47880004, Test Accuracy: 0.36170000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.08035936, Test Loss: 4.75962087, Test Accuracy: 0.36790000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.07573550, Test Loss: 4.84486974, Test Accuracy: 0.36920000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.07334843, Test Loss: 4.77544440, Test Accuracy: 0.37150000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.06685559, Test Loss: 4.04476407, Test Accuracy: 0.41600000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.06047823, Test Loss: 4.05325173, Test Accuracy: 0.40360000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.06029535, Test Loss: 4.11943891, Test Accuracy: 0.40440000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05686572, Test Loss: 3.50490172, Test Accuracy: 0.44010000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.05252737, Test Loss: 3.42974196, Test Accuracy: 0.44740000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.04689874, Test Loss: 3.20878312, Test Accuracy: 0.45480000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.04388381, Test Loss: 3.08301817, Test Accuracy: 0.48110000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04025675, Test Loss: 3.14270977, Test Accuracy: 0.47860000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.03675571, Test Loss: 2.85151311, Test Accuracy: 0.50410000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.03458970, Test Loss: 2.97947596, Test Accuracy: 0.49910000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.03347704, Test Loss: 2.72088644, Test Accuracy: 0.52290000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.03122221, Test Loss: 2.82640246, Test Accuracy: 0.51910000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.02948165, Test Loss: 2.41617381, Test Accuracy: 0.55880000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.02798834, Test Loss: 2.29261958, Test Accuracy: 0.57660000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.02717852, Test Loss: 2.02089510, Test Accuracy: 0.59340000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.02546054, Test Loss: 1.91883730, Test Accuracy: 0.61110000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.02317300, Test Loss: 1.81007606, Test Accuracy: 0.62230000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.02126008, Test Loss: 1.71003380, Test Accuracy: 0.63870000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01926995, Test Loss: 1.59804770, Test Accuracy: 0.66210000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01727707, Test Loss: 1.52950194, Test Accuracy: 0.67520000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01542416, Test Loss: 1.47233003, Test Accuracy: 0.68570000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01388138, Test Loss: 1.42614702, Test Accuracy: 0.69790000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01261872, Test Loss: 1.42006555, Test Accuracy: 0.69930000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.01152613, Test Loss: 1.32247714, Test Accuracy: 0.71860000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.01017689, Test Loss: 1.32662522, Test Accuracy: 0.71950000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00898472, Test Loss: 1.31212555, Test Accuracy: 0.72810000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00792489, Test Loss: 1.29295607, Test Accuracy: 0.73510000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00689656, Test Loss: 1.26211910, Test Accuracy: 0.74190000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00601743, Test Loss: 1.23942964, Test Accuracy: 0.75260000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00520527, Test Loss: 1.20007745, Test Accuracy: 0.76200000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00448931, Test Loss: 1.16608143, Test Accuracy: 0.76980000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00386023, Test Loss: 1.15831476, Test Accuracy: 0.77420000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00333918, Test Loss: 1.10810398, Test Accuracy: 0.78420000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00289330, Test Loss: 1.08072854, Test Accuracy: 0.78980000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00248752, Test Loss: 1.09374924, Test Accuracy: 0.79110000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00213780, Test Loss: 1.08705834, Test Accuracy: 0.79200000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00181415, Test Loss: 1.09035287, Test Accuracy: 0.79480000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00156748, Test Loss: 1.06826410, Test Accuracy: 0.80310000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00133267, Test Loss: 1.02990347, Test Accuracy: 0.80960000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00117935, Test Loss: 0.98503478, Test Accuracy: 0.82170000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00102313, Test Loss: 0.99547979, Test Accuracy: 0.82280000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00088864, Test Loss: 0.98053723, Test Accuracy: 0.82760000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00075652, Test Loss: 0.98455054, Test Accuracy: 0.83120000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00063736, Test Loss: 0.99784910, Test Accuracy: 0.83360000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00058420, Test Loss: 1.06918783, Test Accuracy: 0.82190000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00055674, Test Loss: 1.05088659, Test Accuracy: 0.82130000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00061961, Test Loss: 1.14655707, Test Accuracy: 0.81600000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00072354, Test Loss: 0.90331988, Test Accuracy: 0.84930000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00082907, Test Loss: 0.83331332, Test Accuracy: 0.86260000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00083584, Test Loss: 0.78892603, Test Accuracy: 0.87120000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00089982, Test Loss: 0.76877587, Test Accuracy: 0.87460000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00093471, Test Loss: 0.76719545, Test Accuracy: 0.87740000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00095480, Test Loss: 0.71938290, Test Accuracy: 0.88340000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00082881, Test Loss: 0.69340959, Test Accuracy: 0.88780000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00065667, Test Loss: 0.68299660, Test Accuracy: 0.89050000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00052300, Test Loss: 0.65656576, Test Accuracy: 0.89520000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00039206, Test Loss: 0.63947816, Test Accuracy: 0.89750000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00029541, Test Loss: 0.63419351, Test Accuracy: 0.89930000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00020385, Test Loss: 0.64798391, Test Accuracy: 0.90000000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00014222, Test Loss: 0.66353278, Test Accuracy: 0.89990000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00009754, Test Loss: 0.68535393, Test Accuracy: 0.89860000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00006680, Test Loss: 0.70812469, Test Accuracy: 0.89700000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00004551, Test Loss: 0.71350169, Test Accuracy: 0.89720000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00003103, Test Loss: 0.73170655, Test Accuracy: 0.89590000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00002142, Test Loss: 0.73886100, Test Accuracy: 0.89630000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00001468, Test Loss: 0.75312340, Test Accuracy: 0.89530000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00001010, Test Loss: 0.76910981, Test Accuracy: 0.89470000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00000703, Test Loss: 0.78222024, Test Accuracy: 0.89520000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00000499, Test Loss: 0.80091640, Test Accuracy: 0.89500000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00000349, Test Loss: 0.82852300, Test Accuracy: 0.89360000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00000245, Test Loss: 0.83101578, Test Accuracy: 0.89510000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00000178, Test Loss: 0.84856121, Test Accuracy: 0.89480000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00000130, Test Loss: 0.85987508, Test Accuracy: 0.89480000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00000097, Test Loss: 0.86925427, Test Accuracy: 0.89610000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00000074, Test Loss: 0.87655228, Test Accuracy: 0.89660000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00000058, Test Loss: 0.89238574, Test Accuracy: 0.89580000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00000046, Test Loss: 0.90140189, Test Accuracy: 0.89580000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00000038, Test Loss: 0.91000775, Test Accuracy: 0.89660000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00000032, Test Loss: 0.90696216, Test Accuracy: 0.89800000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00000028, Test Loss: 0.91180244, Test Accuracy: 0.89820000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00000024, Test Loss: 0.89863627, Test Accuracy: 0.90110000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00000022, Test Loss: 0.88440234, Test Accuracy: 0.90390000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00000020, Test Loss: 0.88326632, Test Accuracy: 0.90460000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00000019, Test Loss: 0.87983983, Test Accuracy: 0.90670000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00000018, Test Loss: 0.88145416, Test Accuracy: 0.90810000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00000017, Test Loss: 0.87661022, Test Accuracy: 0.90920000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00000016, Test Loss: 0.87470689, Test Accuracy: 0.91020000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00000015, Test Loss: 0.86166552, Test Accuracy: 0.91150000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00000015, Test Loss: 0.85290162, Test Accuracy: 0.91330000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S_SuOr9Dpob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}