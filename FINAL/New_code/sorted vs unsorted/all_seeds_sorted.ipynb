{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_seeds_sorted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/all_seeds_sorted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7STrWa0P3z_",
        "outputId": "084a033e-5ad7-4159-f0d7-40ed71b82b59"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIyKF1HE7uQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a21b8c-5672-4762-b077-9c467d91248b"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "root_dir = './'\n",
        "torchvision.datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-08 21:27:26--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-04-08 21:27:26--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.2’\n",
            "\n",
            "MNIST.tar.gz.2          [            <=>     ]  33.20M  14.4MB/s    in 2.3s    \n",
            "\n",
            "2021-04-08 21:27:29 (14.4 MB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4j9WoP-UnAm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = torchvision.datasets.MNIST(root=root_dir, train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = torchvision.datasets.MNIST(root=root_dir, \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow9Sy2SyUYgn"
      },
      "source": [
        "new_mnist_trainset =  [ [[],[]] for i in range(10)]\n",
        "# new_mnist_testset  =  [ [[],[]] for i in range(10)]\n",
        "\n",
        "for i in range(60000):\n",
        "    for j in range(10):\n",
        "        if mnist_trainset[i][1] == j:\n",
        "            # image \n",
        "            new_mnist_trainset[j][0].append(mnist_trainset[i][0])  \n",
        "            # label\n",
        "            new_mnist_trainset[j][1].append(mnist_trainset[i][1])\n",
        "\n",
        "# for i in range(10000):\n",
        "#     for j in range(10):\n",
        "#         if mnist_testset[i][1] == j:\n",
        "#             # image \n",
        "#             new_mnist_testset[j][0].append(mnist_testset[i][0])  \n",
        "#             # label\n",
        "#             new_mnist_testset[j][1].append(mnist_testset[i][1])\n",
        "\n",
        "image_trainset = list()\n",
        "label_trainset = list()\n",
        "\n",
        "# image_testset = list()\n",
        "# label_testset = list()\n",
        "\n",
        "for i in range(10):\n",
        "    image_trainset.append(new_mnist_trainset[i][0])\n",
        "    label_trainset.append(new_mnist_trainset[i][1])\n",
        "\n",
        "# for i in range(10):\n",
        "#     image_testset.append(new_mnist_testset[i][0])\n",
        "#     label_testset.append(new_mnist_testset[i][1])\n",
        "\n",
        "flattened_image_train = list()\n",
        "flattened_label_train = list()\n",
        "\n",
        "# flattened_image_test = list()\n",
        "# flattened_label_test = list()\n",
        "\n",
        "# flattening image \n",
        "for sublist in image_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_image_train.append(val)\n",
        "\n",
        "# flattening label\n",
        "for sublist in label_trainset:\n",
        "    for val in sublist:\n",
        "        flattened_label_train.append(val)\n",
        "\n",
        "# # flattening image \n",
        "# for sublist in image_testset:\n",
        "#     for val in sublist:\n",
        "#         flattened_image_test.append(val)\n",
        "\n",
        "# # flattening label\n",
        "# for sublist in label_testset:\n",
        "#     for val in sublist:\n",
        "#         flattened_label_test.append(val)\n",
        "\n",
        "flattened_image_train = torch.stack(flattened_image_train)\n",
        "flattened_label_train = torch.Tensor(flattened_label_train)\n",
        "flattened_label_train = flattened_label_train.type(torch.LongTensor)\n",
        "\n",
        "# flattened_image_test = torch.stack(flattened_image_test)\n",
        "# flattened_label_test = torch.Tensor(flattened_label_test)\n",
        "# flattened_label_test = flattened_label_test.type(torch.LongTensor)\n",
        "\n",
        "train_dataset = TensorDataset(flattened_image_train, flattened_label_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=50)\n",
        "\n",
        "# test_dataset = TensorDataset(flattened_image_test, flattened_label_test)\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAD1thJ5JvD"
      },
      "source": [
        "def selectivity(hidden_layer_each_neuron):\n",
        "    __selectivity__ = list()\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(256)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 256 lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(256)]\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity\n",
        "        __selectivity__.append(selectivity)\n",
        "\n",
        "    avg_selectivity = np.average(__selectivity__)\n",
        "    std_selectivity = np.std(__selectivity__)\n",
        "                                 \n",
        "    return avg_selectivity, std_selectivity"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9kATNPUz1cA"
      },
      "source": [
        "def sparsity_calculator(final_spareness):\n",
        "    sparseness_list = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 100\n",
        "def selectivity_trainer(optimizer, model):\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "\n",
        "    final_spareness = list()\n",
        "    \n",
        "    final_selectivity_avg_list = list()\n",
        "    final_selectivity_std_list = list()\n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        _hidden_layer_each_neuron_ = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
        "        _hidden_layer_each_neuron_ = np.array(_hidden_layer_each_neuron_)\n",
        "\n",
        "        hidden_layer_activation_list = list()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, labels) in enumerate(train_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print/Append activation of the hidden layer \n",
        "            # print(model.layer_activations.shape)\n",
        "            # model.layer_activations\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            hidden_layer_activation_list.append(model.layer_activations)\n",
        "\n",
        "            \n",
        "            for activation, label in zip(model.layer_activations, labels):\n",
        "                # shape of activation and label: 256 and 1 \n",
        "                \n",
        "                # get the actual value of item. This is because label is now Tensor \n",
        "                label = label.item()\n",
        "\n",
        "                # this is not part of gradient calculcation \n",
        "                with torch.no_grad():\n",
        "                    activation = activation.numpy()\n",
        "\n",
        "                # for each image/label, append activation value of neuron \n",
        "                for i in range(256):    # number of neurons in hidden layer \n",
        "                    _hidden_layer_each_neuron_[i][label].append(activation[i])\n",
        "\n",
        "        avg_selectivity, std_selectivity = selectivity(_hidden_layer_each_neuron_)\n",
        "        \n",
        "        final_selectivity_avg_list.append(avg_selectivity)\n",
        "        final_selectivity_std_list.append(std_selectivity)\n",
        "\n",
        "        final_spareness.append(hidden_layer_activation_list)\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "    sparsity_list = sparsity_calculator(final_spareness)\n",
        "\n",
        "    average_sparsity = list()\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    print(\"average_sparsity:\", average_sparsity)\n",
        "\n",
        "    return test_acc, average_sparsity, final_selectivity_avg_list, final_selectivity_std_list"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# Seed 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WytqcJRZxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c0a04e-8123-4959-8be1-a3ef4c6db908"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Adadelta\n",
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"seed1_sorted_batch_50_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_sorted_batch_50_Adadelta.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adagrad\n",
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"seed1_sorted_batch_50_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_sorted_batch_50_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# SGD \n",
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity, SGD_avg_selectivity_list, SGD_std_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"seed1_sorted_batch_50_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(sparsity)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_sorted_batch_50_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adam \n",
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity, Adam_avg_selectivity_list, Adam_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"seed1_sorted_batch_50_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1_sorted_batch_50_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.33790937, Test Loss: 6.81594052, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.22456002, Test Loss: 5.43881819, Test Accuracy: 0.10110000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.13474283, Test Loss: 5.08087767, Test Accuracy: 0.10190000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.11875450, Test Loss: 4.98107031, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.11267328, Test Loss: 4.97195589, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.11009915, Test Loss: 4.99961284, Test Accuracy: 0.10420000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.10931596, Test Loss: 5.05144711, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.10927144, Test Loss: 5.12864606, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.10955361, Test Loss: 5.22059197, Test Accuracy: 0.10340000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.10995825, Test Loss: 5.29574746, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.11061470, Test Loss: 5.38449665, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.11081145, Test Loss: 5.46861069, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.11072343, Test Loss: 5.55196708, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.11083105, Test Loss: 5.61493147, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.11094058, Test Loss: 5.64578174, Test Accuracy: 0.10430000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.11059758, Test Loss: 5.68853116, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.11079719, Test Loss: 5.75238940, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.11139637, Test Loss: 5.81076868, Test Accuracy: 0.10420000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.11218076, Test Loss: 5.84901536, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.11346650, Test Loss: 5.88190379, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.11413482, Test Loss: 5.93068687, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.11511443, Test Loss: 6.00808119, Test Accuracy: 0.10250000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.11630095, Test Loss: 6.10439691, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.11727020, Test Loss: 6.19285304, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.11814620, Test Loss: 6.25668499, Test Accuracy: 0.10230000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.11869694, Test Loss: 6.31498264, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.11888655, Test Loss: 6.36569999, Test Accuracy: 0.10230000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.11863195, Test Loss: 6.39875876, Test Accuracy: 0.10220000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.11822162, Test Loss: 6.41857545, Test Accuracy: 0.10190000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.11750134, Test Loss: 6.41126901, Test Accuracy: 0.10190000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.11683993, Test Loss: 6.39866228, Test Accuracy: 0.10210000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.11654203, Test Loss: 6.39120950, Test Accuracy: 0.10220000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.11630919, Test Loss: 6.39738660, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.11569639, Test Loss: 6.40870540, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.11530871, Test Loss: 6.42019052, Test Accuracy: 0.10300000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.11568984, Test Loss: 6.44675094, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.11628078, Test Loss: 6.47173245, Test Accuracy: 0.10300000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.11673948, Test Loss: 6.46258912, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.11672536, Test Loss: 6.41262650, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.11609140, Test Loss: 6.35346164, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.11509121, Test Loss: 6.31076732, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.11409479, Test Loss: 6.29851095, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.11353443, Test Loss: 6.31478387, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.11352219, Test Loss: 6.33706081, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.11392520, Test Loss: 6.35705635, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.11441254, Test Loss: 6.37503374, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.11471170, Test Loss: 6.40096287, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.11505801, Test Loss: 6.42411903, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.11529677, Test Loss: 6.43652836, Test Accuracy: 0.10410000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.11514263, Test Loss: 6.46000612, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.11507544, Test Loss: 6.50306072, Test Accuracy: 0.10340000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.11527008, Test Loss: 6.51524168, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.11550438, Test Loss: 6.51919731, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.11615433, Test Loss: 6.54168859, Test Accuracy: 0.10230000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.11689658, Test Loss: 6.57001137, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.11734031, Test Loss: 6.58505879, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.11755663, Test Loss: 6.58847674, Test Accuracy: 0.10250000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.11778348, Test Loss: 6.60006160, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.11764225, Test Loss: 6.61714136, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.11772279, Test Loss: 6.63326949, Test Accuracy: 0.10300000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.11843028, Test Loss: 6.63761170, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.11933203, Test Loss: 6.62910571, Test Accuracy: 0.10290000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.12041387, Test Loss: 6.64364178, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.12131376, Test Loss: 6.66009843, Test Accuracy: 0.10300000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.12164645, Test Loss: 6.65919324, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.12119767, Test Loss: 6.62791332, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.12045417, Test Loss: 6.58352836, Test Accuracy: 0.10450000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.12008505, Test Loss: 6.54204624, Test Accuracy: 0.10490000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.12003351, Test Loss: 6.48838986, Test Accuracy: 0.10500000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.11944640, Test Loss: 6.44504854, Test Accuracy: 0.10490000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.11861921, Test Loss: 6.42293236, Test Accuracy: 0.10470000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.11797753, Test Loss: 6.40374080, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.11795623, Test Loss: 6.39047218, Test Accuracy: 0.10530000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.11884405, Test Loss: 6.39603605, Test Accuracy: 0.10670000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.11996983, Test Loss: 6.38613717, Test Accuracy: 0.10650000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.12057526, Test Loss: 6.35774736, Test Accuracy: 0.10620000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.12069601, Test Loss: 6.33737610, Test Accuracy: 0.10650000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.12049583, Test Loss: 6.33414334, Test Accuracy: 0.10690000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.12014519, Test Loss: 6.33625518, Test Accuracy: 0.10730000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.11988271, Test Loss: 6.36898834, Test Accuracy: 0.10620000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.11951738, Test Loss: 6.41769502, Test Accuracy: 0.10650000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.11931128, Test Loss: 6.44881547, Test Accuracy: 0.10610000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.11923304, Test Loss: 6.48342354, Test Accuracy: 0.10580000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.11926280, Test Loss: 6.52133651, Test Accuracy: 0.10550000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.11930191, Test Loss: 6.54952009, Test Accuracy: 0.10490000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.11914896, Test Loss: 6.56566361, Test Accuracy: 0.10430000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.11890723, Test Loss: 6.57890055, Test Accuracy: 0.10450000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.11881994, Test Loss: 6.60360159, Test Accuracy: 0.10450000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.11900687, Test Loss: 6.60801107, Test Accuracy: 0.10410000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.11896625, Test Loss: 6.61241269, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.11903339, Test Loss: 6.62535943, Test Accuracy: 0.10460000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.11938140, Test Loss: 6.64263158, Test Accuracy: 0.10470000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.11989978, Test Loss: 6.66596651, Test Accuracy: 0.10480000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.12043185, Test Loss: 6.66476950, Test Accuracy: 0.10530000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.12046880, Test Loss: 6.66052679, Test Accuracy: 0.10550000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.12000213, Test Loss: 6.66799875, Test Accuracy: 0.10570000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.11937409, Test Loss: 6.67462026, Test Accuracy: 0.10620000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.11918548, Test Loss: 6.65673181, Test Accuracy: 0.10650000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.11935690, Test Loss: 6.65110898, Test Accuracy: 0.10670000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.11961341, Test Loss: 6.68736742, Test Accuracy: 0.10660000\n",
            "average_sparsity: [0.42688819766044617, 0.3736271858215332, 0.36903607845306396, 0.37545835971832275, 0.38219574093818665, 0.3872601389884949, 0.39067313075065613, 0.3924528956413269, 0.39386993646621704, 0.3937026262283325, 0.3918941617012024, 0.3885154128074646, 0.38321933150291443, 0.3794736862182617, 0.3775952160358429, 0.3746827244758606, 0.37084731459617615, 0.3663804829120636, 0.3613714873790741, 0.35574036836624146, 0.3504035174846649, 0.34493526816368103, 0.3396189212799072, 0.3351214826107025, 0.33274614810943604, 0.33106282353401184, 0.3283371925354004, 0.32470518350601196, 0.32127508521080017, 0.31941843032836914, 0.3187170624732971, 0.3181700110435486, 0.31702762842178345, 0.3147870600223541, 0.3123154640197754, 0.3098728358745575, 0.3084491193294525, 0.30837202072143555, 0.30867287516593933, 0.3083271384239197, 0.30711454153060913, 0.30581530928611755, 0.3047265112400055, 0.30397945642471313, 0.30318814516067505, 0.30236390233039856, 0.3014748990535736, 0.30071061849594116, 0.2998647093772888, 0.29876261949539185, 0.2980736494064331, 0.297954797744751, 0.2976275682449341, 0.29745420813560486, 0.29761549830436707, 0.29781585931777954, 0.29805707931518555, 0.29683348536491394, 0.2946278750896454, 0.2922205924987793, 0.29018327593803406, 0.288567453622818, 0.28706473112106323, 0.2865051329135895, 0.2868441343307495, 0.2874948978424072, 0.28796935081481934, 0.28781846165657043, 0.28744593262672424, 0.2870628535747528, 0.2865816354751587, 0.2858235239982605, 0.2848794460296631, 0.28374359011650085, 0.28238627314567566, 0.280818372964859, 0.27958711981773376, 0.27837759256362915, 0.27681729197502136, 0.27472734451293945, 0.2729323208332062, 0.27163445949554443, 0.27052047848701477, 0.2695857286453247, 0.2692634165287018, 0.26974987983703613, 0.27095165848731995, 0.27252304553985596, 0.273917019367218, 0.2753753066062927, 0.2770770788192749, 0.2786800265312195, 0.2800581157207489, 0.2807568907737732, 0.2810934782028198, 0.28143978118896484, 0.2818838953971863, 0.28229013085365295, 0.2827037274837494, 0.28323686122894287]\n",
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.13000182, Test Loss: 7.62718419, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09373661, Test Loss: 5.86112695, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.05959304, Test Loss: 4.88602888, Test Accuracy: 0.10450000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.04537385, Test Loss: 4.33061474, Test Accuracy: 0.16470000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.03926217, Test Loss: 3.74868808, Test Accuracy: 0.24210000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.03532807, Test Loss: 3.80170952, Test Accuracy: 0.24930000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.03225623, Test Loss: 3.49716935, Test Accuracy: 0.29730000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.03097886, Test Loss: 3.45083193, Test Accuracy: 0.32690000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.02923196, Test Loss: 3.24007276, Test Accuracy: 0.34910000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.02857053, Test Loss: 3.07047339, Test Accuracy: 0.36780000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.02654172, Test Loss: 2.98483451, Test Accuracy: 0.37180000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.02553881, Test Loss: 2.93525274, Test Accuracy: 0.38630000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.02492784, Test Loss: 2.75118509, Test Accuracy: 0.40740000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.02385000, Test Loss: 2.71228798, Test Accuracy: 0.41450000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.02342169, Test Loss: 2.67229428, Test Accuracy: 0.42040000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.02306534, Test Loss: 2.66574907, Test Accuracy: 0.42360000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.02215549, Test Loss: 2.50571207, Test Accuracy: 0.43770000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.02127458, Test Loss: 2.54762763, Test Accuracy: 0.42300000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.02067759, Test Loss: 2.46240492, Test Accuracy: 0.45870000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.01927375, Test Loss: 2.56391445, Test Accuracy: 0.44680000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.01882938, Test Loss: 2.44598864, Test Accuracy: 0.46020000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.01825114, Test Loss: 2.36534951, Test Accuracy: 0.46950000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.01701308, Test Loss: 2.37458892, Test Accuracy: 0.47620000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.01620509, Test Loss: 2.24461256, Test Accuracy: 0.48510000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.01646872, Test Loss: 2.38036075, Test Accuracy: 0.45330000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.01654875, Test Loss: 2.09595769, Test Accuracy: 0.51240000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.01598778, Test Loss: 2.06910469, Test Accuracy: 0.51270000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.01543743, Test Loss: 1.97861712, Test Accuracy: 0.53310000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.01476714, Test Loss: 1.95560478, Test Accuracy: 0.53220000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01446324, Test Loss: 1.93451028, Test Accuracy: 0.53510000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01379317, Test Loss: 1.84778638, Test Accuracy: 0.55770000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01415942, Test Loss: 1.82318455, Test Accuracy: 0.56310000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01374918, Test Loss: 1.79391758, Test Accuracy: 0.56510000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01312678, Test Loss: 1.73392303, Test Accuracy: 0.57650000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.01290056, Test Loss: 1.66481616, Test Accuracy: 0.58820000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.01278628, Test Loss: 1.66926107, Test Accuracy: 0.58840000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.01196367, Test Loss: 1.63674978, Test Accuracy: 0.59340000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.01184246, Test Loss: 1.62180798, Test Accuracy: 0.59930000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.01158098, Test Loss: 1.66343838, Test Accuracy: 0.58980000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.01117134, Test Loss: 1.55961252, Test Accuracy: 0.61440000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.01048403, Test Loss: 1.50440193, Test Accuracy: 0.62480000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.01037155, Test Loss: 1.53357750, Test Accuracy: 0.61950000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.01003478, Test Loss: 1.46890441, Test Accuracy: 0.63620000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.01004855, Test Loss: 1.45106787, Test Accuracy: 0.64230000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00979242, Test Loss: 1.40004404, Test Accuracy: 0.65010000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00978371, Test Loss: 1.39834197, Test Accuracy: 0.65090000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00957203, Test Loss: 1.37764576, Test Accuracy: 0.65410000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00923518, Test Loss: 1.35729540, Test Accuracy: 0.65710000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00873575, Test Loss: 1.36158595, Test Accuracy: 0.65650000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00844347, Test Loss: 1.34547055, Test Accuracy: 0.66100000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00808479, Test Loss: 1.31070442, Test Accuracy: 0.66730000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00841491, Test Loss: 1.23616806, Test Accuracy: 0.68470000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00793352, Test Loss: 1.22133908, Test Accuracy: 0.68920000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00810198, Test Loss: 1.20016629, Test Accuracy: 0.69350000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00830994, Test Loss: 1.23201821, Test Accuracy: 0.68690000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00816696, Test Loss: 1.18046961, Test Accuracy: 0.69800000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00782911, Test Loss: 1.16600459, Test Accuracy: 0.70120000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00759603, Test Loss: 1.15098403, Test Accuracy: 0.70510000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00749323, Test Loss: 1.12983838, Test Accuracy: 0.70770000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00705382, Test Loss: 1.11869928, Test Accuracy: 0.71180000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00678014, Test Loss: 1.11159824, Test Accuracy: 0.71350000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00674979, Test Loss: 1.06955866, Test Accuracy: 0.72330000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00642359, Test Loss: 1.06687503, Test Accuracy: 0.72260000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00662131, Test Loss: 1.02431234, Test Accuracy: 0.73190000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00672269, Test Loss: 1.02290827, Test Accuracy: 0.73340000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00671144, Test Loss: 0.99262083, Test Accuracy: 0.74110000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00647157, Test Loss: 1.00056777, Test Accuracy: 0.73990000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00641648, Test Loss: 0.97307647, Test Accuracy: 0.74600000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00620109, Test Loss: 0.95651734, Test Accuracy: 0.75060000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00628468, Test Loss: 0.93793691, Test Accuracy: 0.75530000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00623237, Test Loss: 0.92933779, Test Accuracy: 0.76080000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00619502, Test Loss: 0.88373585, Test Accuracy: 0.77090000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00624136, Test Loss: 0.87040134, Test Accuracy: 0.77260000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00582305, Test Loss: 0.88040092, Test Accuracy: 0.76790000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00566600, Test Loss: 0.85096164, Test Accuracy: 0.77560000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00587893, Test Loss: 0.82170040, Test Accuracy: 0.78290000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00590219, Test Loss: 0.80883569, Test Accuracy: 0.78710000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00588656, Test Loss: 0.79524290, Test Accuracy: 0.79040000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00584813, Test Loss: 0.78094436, Test Accuracy: 0.79470000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00576670, Test Loss: 0.76657229, Test Accuracy: 0.79730000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00575490, Test Loss: 0.75146517, Test Accuracy: 0.80100000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00567063, Test Loss: 0.73571045, Test Accuracy: 0.80540000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00561626, Test Loss: 0.71779143, Test Accuracy: 0.81000000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00557769, Test Loss: 0.70012158, Test Accuracy: 0.81370000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00552630, Test Loss: 0.68401284, Test Accuracy: 0.81620000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00547578, Test Loss: 0.67073181, Test Accuracy: 0.82040000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00520285, Test Loss: 0.66692515, Test Accuracy: 0.82120000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00521774, Test Loss: 0.66052217, Test Accuracy: 0.82320000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00495595, Test Loss: 0.67519265, Test Accuracy: 0.81950000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00492648, Test Loss: 0.67142483, Test Accuracy: 0.82020000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00494942, Test Loss: 0.62582448, Test Accuracy: 0.83180000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00488202, Test Loss: 0.62823153, Test Accuracy: 0.83180000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00482921, Test Loss: 0.61294874, Test Accuracy: 0.83520000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00482135, Test Loss: 0.60146201, Test Accuracy: 0.83820000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00479392, Test Loss: 0.59135451, Test Accuracy: 0.84220000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00475905, Test Loss: 0.58045372, Test Accuracy: 0.84480000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00471597, Test Loss: 0.57010163, Test Accuracy: 0.84700000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00467588, Test Loss: 0.56384265, Test Accuracy: 0.84940000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00463687, Test Loss: 0.55884096, Test Accuracy: 0.84950000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00459702, Test Loss: 0.55385818, Test Accuracy: 0.85120000\n",
            "average_sparsity: [0.629250168800354, 0.5594016313552856, 0.5224224328994751, 0.5051873326301575, 0.4919070899486542, 0.4774598777294159, 0.4690339267253876, 0.45923203229904175, 0.4467986226081848, 0.4375126361846924, 0.43294110894203186, 0.42027202248573303, 0.41800716519355774, 0.414489209651947, 0.4123325049877167, 0.4078260660171509, 0.4078556001186371, 0.4049776494503021, 0.39527738094329834, 0.3862522840499878, 0.38333678245544434, 0.37592101097106934, 0.3699832558631897, 0.36924517154693604, 0.3775886297225952, 0.3662247657775879, 0.3599206507205963, 0.35780197381973267, 0.3558502793312073, 0.35244500637054443, 0.34646910429000854, 0.34606045484542847, 0.34026917815208435, 0.33969542384147644, 0.3394286036491394, 0.33648696541786194, 0.3336308002471924, 0.32478079199790955, 0.3265601694583893, 0.3210509121417999, 0.3213501572608948, 0.3195391297340393, 0.3153514266014099, 0.312565416097641, 0.31227347254753113, 0.3091471791267395, 0.3061003088951111, 0.3030768632888794, 0.2973693311214447, 0.2978212535381317, 0.2970709800720215, 0.2997657358646393, 0.29662540555000305, 0.2969457805156708, 0.2971574366092682, 0.29460689425468445, 0.2916511595249176, 0.2883971333503723, 0.28803253173828125, 0.2823292315006256, 0.27660316228866577, 0.2762545347213745, 0.27340438961982727, 0.276583194732666, 0.27742868661880493, 0.2767696678638458, 0.27435582876205444, 0.2741478383541107, 0.2740291357040405, 0.27397620677948, 0.27320563793182373, 0.2728801369667053, 0.272760272026062, 0.26700201630592346, 0.2666495740413666, 0.26887357234954834, 0.2687474489212036, 0.2686851918697357, 0.2685447633266449, 0.2683364748954773, 0.2683013081550598, 0.26838183403015137, 0.2685389816761017, 0.2686890661716461, 0.26885080337524414, 0.2689891457557678, 0.2665202021598816, 0.266303151845932, 0.2633554935455322, 0.2640528976917267, 0.26575079560279846, 0.26339221000671387, 0.2634812891483307, 0.26356539130210876, 0.2636702358722687, 0.26377612352371216, 0.2638230323791504, 0.26394927501678467, 0.264126181602478, 0.26434385776519775]\n",
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.07096537, Test Loss: 8.04136714, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09368344, Test Loss: 7.70599746, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.10763442, Test Loss: 7.35084758, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.10550045, Test Loss: 6.67767626, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.08963007, Test Loss: 5.84425429, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.07396639, Test Loss: 5.20666986, Test Accuracy: 0.10570000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.06452936, Test Loss: 4.78558550, Test Accuracy: 0.13130000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.05961153, Test Loss: 4.48932857, Test Accuracy: 0.15520000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.05687979, Test Loss: 4.26176929, Test Accuracy: 0.17890000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.05511638, Test Loss: 4.07819971, Test Accuracy: 0.19590000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.05381976, Test Loss: 3.92891649, Test Accuracy: 0.21050000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.05279210, Test Loss: 3.80884970, Test Accuracy: 0.22190000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.05195112, Test Loss: 3.71346031, Test Accuracy: 0.23130000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.05125674, Test Loss: 3.63788278, Test Accuracy: 0.23970000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05068260, Test Loss: 3.57729519, Test Accuracy: 0.24640000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.05020628, Test Loss: 3.52750507, Test Accuracy: 0.25210000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.04980760, Test Loss: 3.48526641, Test Accuracy: 0.25810000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.04946935, Test Loss: 3.44823784, Test Accuracy: 0.26270000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04917767, Test Loss: 3.41476704, Test Accuracy: 0.26710000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.04892174, Test Loss: 3.38367437, Test Accuracy: 0.27010000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.04869322, Test Loss: 3.35411287, Test Accuracy: 0.27420000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.04848577, Test Loss: 3.32550810, Test Accuracy: 0.27750000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.04829475, Test Loss: 3.29750893, Test Accuracy: 0.28080000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.04811693, Test Loss: 3.26994121, Test Accuracy: 0.28390000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.04795010, Test Loss: 3.24274330, Test Accuracy: 0.28690000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.04779287, Test Loss: 3.21590419, Test Accuracy: 0.28990000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.04764454, Test Loss: 3.18941319, Test Accuracy: 0.29520000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.04750487, Test Loss: 3.16323385, Test Accuracy: 0.29870000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.04737397, Test Loss: 3.13730097, Test Accuracy: 0.30080000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.04725199, Test Loss: 3.11153008, Test Accuracy: 0.30460000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.04713891, Test Loss: 3.08583447, Test Accuracy: 0.30720000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.04703428, Test Loss: 3.06013186, Test Accuracy: 0.31030000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.04693716, Test Loss: 3.03433489, Test Accuracy: 0.31370000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.04684617, Test Loss: 3.00832522, Test Accuracy: 0.31800000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.04675949, Test Loss: 2.98193192, Test Accuracy: 0.32130000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.04667482, Test Loss: 2.95497157, Test Accuracy: 0.32470000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.04658929, Test Loss: 2.92736410, Test Accuracy: 0.32770000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.04649974, Test Loss: 2.89925068, Test Accuracy: 0.33140000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.04640341, Test Loss: 2.87098158, Test Accuracy: 0.33560000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.04629849, Test Loss: 2.84293090, Test Accuracy: 0.34100000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.04618434, Test Loss: 2.81528012, Test Accuracy: 0.34570000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.04606130, Test Loss: 2.78795743, Test Accuracy: 0.34930000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.04593032, Test Loss: 2.76072807, Test Accuracy: 0.35380000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.04579263, Test Loss: 2.73333642, Test Accuracy: 0.35700000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.04564925, Test Loss: 2.70559015, Test Accuracy: 0.36000000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.04550069, Test Loss: 2.67739641, Test Accuracy: 0.36420000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.04534682, Test Loss: 2.64875306, Test Accuracy: 0.36800000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.04518709, Test Loss: 2.61973557, Test Accuracy: 0.37210000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.04502104, Test Loss: 2.59047456, Test Accuracy: 0.37660000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.04484870, Test Loss: 2.56113577, Test Accuracy: 0.38070000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.04467066, Test Loss: 2.53188928, Test Accuracy: 0.38450000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.04448772, Test Loss: 2.50288159, Test Accuracy: 0.38840000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.04430054, Test Loss: 2.47420993, Test Accuracy: 0.39260000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.04410925, Test Loss: 2.44592122, Test Accuracy: 0.39700000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.04391337, Test Loss: 2.41802670, Test Accuracy: 0.40100000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.04371191, Test Loss: 2.39051499, Test Accuracy: 0.40400000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.04350354, Test Loss: 2.36336892, Test Accuracy: 0.40700000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.04328684, Test Loss: 2.33656631, Test Accuracy: 0.41080000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.04306060, Test Loss: 2.31007319, Test Accuracy: 0.41540000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.04282412, Test Loss: 2.28383608, Test Accuracy: 0.41990000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.04257739, Test Loss: 2.25777089, Test Accuracy: 0.42300000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.04232096, Test Loss: 2.23176804, Test Accuracy: 0.42690000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.04205550, Test Loss: 2.20570156, Test Accuracy: 0.42920000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.04178134, Test Loss: 2.17945186, Test Accuracy: 0.43350000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.04149846, Test Loss: 2.15292759, Test Accuracy: 0.43750000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.04120673, Test Loss: 2.12607636, Test Accuracy: 0.44090000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.04090633, Test Loss: 2.09888866, Test Accuracy: 0.44580000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.04059787, Test Loss: 2.07138552, Test Accuracy: 0.44940000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.04028244, Test Loss: 2.04360817, Test Accuracy: 0.45480000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.03996143, Test Loss: 2.01559672, Test Accuracy: 0.45910000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.03963627, Test Loss: 1.98738762, Test Accuracy: 0.46370000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.03930834, Test Loss: 1.95901420, Test Accuracy: 0.46940000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.03897878, Test Loss: 1.93050612, Test Accuracy: 0.47430000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.03864855, Test Loss: 1.90189879, Test Accuracy: 0.47860000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.03831829, Test Loss: 1.87323373, Test Accuracy: 0.48390000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.03798832, Test Loss: 1.84456187, Test Accuracy: 0.49050000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.03765860, Test Loss: 1.81594386, Test Accuracy: 0.49610000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.03732883, Test Loss: 1.78744885, Test Accuracy: 0.50130000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.03699850, Test Loss: 1.75915007, Test Accuracy: 0.50610000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.03666712, Test Loss: 1.73112370, Test Accuracy: 0.51000000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.03633436, Test Loss: 1.70344952, Test Accuracy: 0.51550000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.03600030, Test Loss: 1.67621221, Test Accuracy: 0.52130000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.03566561, Test Loss: 1.64949470, Test Accuracy: 0.52770000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.03533148, Test Loss: 1.62337239, Test Accuracy: 0.53110000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.03499943, Test Loss: 1.59789705, Test Accuracy: 0.53730000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.03467099, Test Loss: 1.57309168, Test Accuracy: 0.54360000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.03434746, Test Loss: 1.54894916, Test Accuracy: 0.54870000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.03402981, Test Loss: 1.52543462, Test Accuracy: 0.55360000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.03371871, Test Loss: 1.50249941, Test Accuracy: 0.55910000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.03341450, Test Loss: 1.48008473, Test Accuracy: 0.56300000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.03311727, Test Loss: 1.45813612, Test Accuracy: 0.56830000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.03282683, Test Loss: 1.43660844, Test Accuracy: 0.57280000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.03254271, Test Loss: 1.41547126, Test Accuracy: 0.57890000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.03226421, Test Loss: 1.39470438, Test Accuracy: 0.58430000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.03199039, Test Loss: 1.37429760, Test Accuracy: 0.59000000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.03172014, Test Loss: 1.35424124, Test Accuracy: 0.59480000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.03145227, Test Loss: 1.33452216, Test Accuracy: 0.60080000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.03118565, Test Loss: 1.31511935, Test Accuracy: 0.60530000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.03091932, Test Loss: 1.29600389, Test Accuracy: 0.60990000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.03065262, Test Loss: 1.27714345, Test Accuracy: 0.61400000\n",
            "average_sparsity: [0.007138531655073166, 0.011954530142247677, 0.024184610694646835, 0.04816533997654915, 0.07848630100488663, 0.10421125590801239, 0.12311127036809921, 0.13725747168064117, 0.1483130156993866, 0.1572367399930954, 0.16461822390556335, 0.1708584576845169, 0.17624600231647491, 0.1809951215982437, 0.18526878952980042, 0.1891922801733017, 0.19285982847213745, 0.19633762538433075, 0.1996668428182602, 0.20286855101585388, 0.205950066447258, 0.20891113579273224, 0.21174877882003784, 0.21446098387241364, 0.2170482873916626, 0.2195136696100235, 0.22186176478862762, 0.22409795224666595, 0.22622890770435333, 0.22826415300369263, 0.23021753132343292, 0.23210729658603668, 0.2339548021554947, 0.23578014969825745, 0.2375977337360382, 0.23941576480865479, 0.2412407249212265, 0.24308283627033234, 0.24495737254619598, 0.24687932431697845, 0.24885685741901398, 0.2508898079395294, 0.2529729902744293, 0.25509965419769287, 0.25726354122161865, 0.25945961475372314, 0.2616848647594452, 0.26393797993659973, 0.2662163972854614, 0.2685152590274811, 0.2708275020122528, 0.2731454074382782, 0.2754621207714081, 0.27777227759361267, 0.28007185459136963, 0.28235721588134766, 0.284623384475708, 0.28686171770095825, 0.2890598177909851, 0.2912030518054962, 0.2932775914669037, 0.2952728867530823, 0.29718291759490967, 0.29900601506233215, 0.30074501037597656, 0.3024066388607025, 0.3040006756782532, 0.3055391013622284, 0.3070337474346161, 0.3084941506385803, 0.3099260628223419, 0.31133174896240234, 0.31271135807037354, 0.3140648901462555, 0.315393328666687, 0.31669893860816956, 0.3179852068424225, 0.3192564845085144, 0.32051730155944824, 0.3217719793319702, 0.3230234682559967, 0.32427334785461426, 0.32552194595336914, 0.32676875591278076, 0.32801303267478943, 0.32925382256507874, 0.33048996329307556, 0.3317199945449829, 0.33294200897216797, 0.3341540992259979, 0.33535444736480713, 0.3365420401096344, 0.33771681785583496, 0.3388800323009491, 0.34003373980522156, 0.34117987751960754, 0.3423192501068115, 0.3434508740901947, 0.34457167983055115, 0.34567707777023315]\n",
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 1.06396564, Test Loss: 5.11713597, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.53222744, Test Loss: 4.04914448, Test Accuracy: 0.11230000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.23354660, Test Loss: 3.91632844, Test Accuracy: 0.21300000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.15632656, Test Loss: 4.09968101, Test Accuracy: 0.25250000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.12545724, Test Loss: 4.44606251, Test Accuracy: 0.27660000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.10685538, Test Loss: 4.78396776, Test Accuracy: 0.29110000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.09559977, Test Loss: 4.36471388, Test Accuracy: 0.32530000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.08802104, Test Loss: 4.20019915, Test Accuracy: 0.34510000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.08137234, Test Loss: 4.41910067, Test Accuracy: 0.35430000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.08166505, Test Loss: 4.24880915, Test Accuracy: 0.37250000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.08034033, Test Loss: 4.06637051, Test Accuracy: 0.39840000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.07371640, Test Loss: 4.02554834, Test Accuracy: 0.37570000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.07203412, Test Loss: 4.17755104, Test Accuracy: 0.39830000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.06842352, Test Loss: 3.97228117, Test Accuracy: 0.43640000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.06313425, Test Loss: 3.65115011, Test Accuracy: 0.44170000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.05846219, Test Loss: 3.75983238, Test Accuracy: 0.46120000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.05574293, Test Loss: 3.25692809, Test Accuracy: 0.46640000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.05055994, Test Loss: 3.49323374, Test Accuracy: 0.46920000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04700953, Test Loss: 3.32043968, Test Accuracy: 0.49320000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.04383233, Test Loss: 3.09891442, Test Accuracy: 0.50770000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.04266111, Test Loss: 2.61793696, Test Accuracy: 0.54370000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.03915415, Test Loss: 2.30827342, Test Accuracy: 0.56840000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.03555940, Test Loss: 2.18784911, Test Accuracy: 0.57260000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.03225238, Test Loss: 2.03469769, Test Accuracy: 0.58980000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.02938009, Test Loss: 1.98754419, Test Accuracy: 0.60110000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.02682382, Test Loss: 1.80375093, Test Accuracy: 0.62920000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.02436407, Test Loss: 1.72054716, Test Accuracy: 0.64440000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.02188349, Test Loss: 1.58200816, Test Accuracy: 0.66360000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.01961410, Test Loss: 1.52946746, Test Accuracy: 0.67200000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01748496, Test Loss: 1.49184056, Test Accuracy: 0.67730000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01603867, Test Loss: 1.47793123, Test Accuracy: 0.68480000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01407983, Test Loss: 1.44042946, Test Accuracy: 0.69650000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01242009, Test Loss: 1.44336641, Test Accuracy: 0.70100000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01096877, Test Loss: 1.44781782, Test Accuracy: 0.70570000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00962314, Test Loss: 1.40965315, Test Accuracy: 0.71750000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00832603, Test Loss: 1.41871317, Test Accuracy: 0.72290000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00733000, Test Loss: 1.45862133, Test Accuracy: 0.72440000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00645696, Test Loss: 1.45878971, Test Accuracy: 0.73250000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00567502, Test Loss: 1.54595837, Test Accuracy: 0.73290000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00493740, Test Loss: 1.49032435, Test Accuracy: 0.74250000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00421711, Test Loss: 1.51355128, Test Accuracy: 0.74600000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00358336, Test Loss: 1.49402438, Test Accuracy: 0.75020000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00301044, Test Loss: 1.41929145, Test Accuracy: 0.76280000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00252188, Test Loss: 1.43356563, Test Accuracy: 0.76400000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00211024, Test Loss: 1.42156146, Test Accuracy: 0.76990000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00180080, Test Loss: 1.33955116, Test Accuracy: 0.77470000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00159884, Test Loss: 1.30892351, Test Accuracy: 0.78220000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00153314, Test Loss: 1.22849927, Test Accuracy: 0.79000000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00139766, Test Loss: 1.23092629, Test Accuracy: 0.79020000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00129978, Test Loss: 1.27328563, Test Accuracy: 0.79090000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00118143, Test Loss: 1.23676394, Test Accuracy: 0.79780000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00103095, Test Loss: 1.27416382, Test Accuracy: 0.79750000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00091587, Test Loss: 1.15599322, Test Accuracy: 0.81390000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00076285, Test Loss: 1.19614661, Test Accuracy: 0.81240000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00067357, Test Loss: 1.21332360, Test Accuracy: 0.81230000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00057928, Test Loss: 1.29583685, Test Accuracy: 0.80630000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00048792, Test Loss: 1.10043092, Test Accuracy: 0.82570000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00041058, Test Loss: 1.10839646, Test Accuracy: 0.83120000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00033381, Test Loss: 1.12646683, Test Accuracy: 0.83050000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00027363, Test Loss: 1.13307392, Test Accuracy: 0.83040000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00023803, Test Loss: 1.20789853, Test Accuracy: 0.82390000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00020960, Test Loss: 1.08340585, Test Accuracy: 0.83940000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00020291, Test Loss: 1.07724083, Test Accuracy: 0.84410000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00018067, Test Loss: 1.15935038, Test Accuracy: 0.83660000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00018923, Test Loss: 1.03329799, Test Accuracy: 0.85160000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00018231, Test Loss: 1.24403522, Test Accuracy: 0.83360000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00035625, Test Loss: 1.14814446, Test Accuracy: 0.84200000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00046597, Test Loss: 1.01447647, Test Accuracy: 0.86180000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00067147, Test Loss: 0.81278058, Test Accuracy: 0.88020000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00087343, Test Loss: 0.73272961, Test Accuracy: 0.89060000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00090450, Test Loss: 0.79426386, Test Accuracy: 0.88550000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00083232, Test Loss: 0.65894694, Test Accuracy: 0.90350000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00066145, Test Loss: 0.64041812, Test Accuracy: 0.90610000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00057445, Test Loss: 0.62602921, Test Accuracy: 0.90820000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00043552, Test Loss: 0.60336834, Test Accuracy: 0.91260000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00033488, Test Loss: 0.63115031, Test Accuracy: 0.91110000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00032330, Test Loss: 0.62415741, Test Accuracy: 0.91180000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00030991, Test Loss: 0.77574412, Test Accuracy: 0.89060000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00031779, Test Loss: 0.65589456, Test Accuracy: 0.90780000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00026585, Test Loss: 0.59644680, Test Accuracy: 0.91520000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00020040, Test Loss: 0.56078789, Test Accuracy: 0.92120000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00015990, Test Loss: 0.54664645, Test Accuracy: 0.92330000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00012802, Test Loss: 0.50947889, Test Accuracy: 0.92850000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00008840, Test Loss: 0.53142716, Test Accuracy: 0.92690000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00006453, Test Loss: 0.55867294, Test Accuracy: 0.92500000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00004637, Test Loss: 0.54612135, Test Accuracy: 0.92740000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00003127, Test Loss: 0.53376967, Test Accuracy: 0.92780000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00002113, Test Loss: 0.53197044, Test Accuracy: 0.92850000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00001425, Test Loss: 0.53595012, Test Accuracy: 0.92840000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00000982, Test Loss: 0.54859161, Test Accuracy: 0.92670000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00001274, Test Loss: 0.58912023, Test Accuracy: 0.92340000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00006148, Test Loss: 0.73847266, Test Accuracy: 0.91040000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00011545, Test Loss: 0.55920998, Test Accuracy: 0.92800000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00018778, Test Loss: 0.54422118, Test Accuracy: 0.92720000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00043922, Test Loss: 0.50751491, Test Accuracy: 0.93310000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00044525, Test Loss: 0.45457717, Test Accuracy: 0.94130000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00042512, Test Loss: 0.40737886, Test Accuracy: 0.94630000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00044527, Test Loss: 0.42034141, Test Accuracy: 0.94330000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00037943, Test Loss: 0.40105668, Test Accuracy: 0.94590000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00026768, Test Loss: 0.36392020, Test Accuracy: 0.95130000\n",
            "average_sparsity: [0.7456409931182861, 0.7038335800170898, 0.6430164575576782, 0.598738431930542, 0.5738499760627747, 0.5444427132606506, 0.5428259968757629, 0.550389289855957, 0.5370200276374817, 0.5289546847343445, 0.5204793214797974, 0.51202392578125, 0.49513116478919983, 0.4990174174308777, 0.5069782137870789, 0.5003031492233276, 0.5065550804138184, 0.5022373199462891, 0.49870723485946655, 0.5002046823501587, 0.5060134530067444, 0.5113179683685303, 0.5120696425437927, 0.5153279304504395, 0.5154300332069397, 0.516782820224762, 0.5163893699645996, 0.5164898633956909, 0.5166704058647156, 0.5152699947357178, 0.5159577131271362, 0.5160768628120422, 0.5153517723083496, 0.5152047872543335, 0.5144950747489929, 0.5136379599571228, 0.5115231275558472, 0.5126634240150452, 0.51130211353302, 0.5108159780502319, 0.5091978311538696, 0.5088566541671753, 0.5080093741416931, 0.506665825843811, 0.5067145228385925, 0.506920576095581, 0.5040930509567261, 0.505249559879303, 0.5034313797950745, 0.5038610100746155, 0.5025341510772705, 0.5035597085952759, 0.5048105716705322, 0.5043923854827881, 0.5040284991264343, 0.5034887790679932, 0.5042858719825745, 0.5045467615127563, 0.503239095211029, 0.5020118355751038, 0.5024460554122925, 0.5031745433807373, 0.5034002065658569, 0.5028550624847412, 0.5016748309135437, 0.5032812356948853, 0.50514817237854, 0.5043633580207825, 0.5068482160568237, 0.5080029964447021, 0.5058271288871765, 0.5069035887718201, 0.5074372291564941, 0.507662832736969, 0.5085926055908203, 0.5066296458244324, 0.5058367252349854, 0.5042245388031006, 0.5017712116241455, 0.5048069953918457, 0.5064828395843506, 0.5041499137878418, 0.5058046579360962, 0.5056549310684204, 0.5032845139503479, 0.503379225730896, 0.5026930570602417, 0.5036488771438599, 0.5023769736289978, 0.5021045804023743, 0.5010451078414917, 0.49901264905929565, 0.5038614869117737, 0.5049234628677368, 0.5046200156211853, 0.505719006061554, 0.5047135949134827, 0.505554735660553, 0.5057031512260437, 0.504280149936676]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjdKTiNvEvHD"
      },
      "source": [
        "# Seed 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b66PG-F6EvQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebd07ed-19f1-4272-aa76-3e44280a5b89"
      },
      "source": [
        "torch.manual_seed(100)\n",
        "np.random.seed(100)\n",
        "\n",
        "# Adadelta\n",
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"seed100_sorted_batch_50_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_sorted_batch_50_Adadelta.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adagrad\n",
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"seed100_sorted_batch_50_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_sorted_batch_50_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# SGD \n",
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity, SGD_avg_selectivity_list, SGD_std_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"seed100_sorted_batch_50_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(sparsity)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_sorted_batch_50_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adam \n",
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity, Adam_avg_selectivity_list, Adam_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"seed100_sorted_batch_50_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed100_sorted_batch_50_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.34253885, Test Loss: 6.66815546, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.22628764, Test Loss: 5.36613784, Test Accuracy: 0.10140000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.13400766, Test Loss: 5.02574993, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.11760036, Test Loss: 4.93105430, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.11161971, Test Loss: 4.92887002, Test Accuracy: 0.10410000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.10908001, Test Loss: 4.97523542, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.10863417, Test Loss: 5.05306170, Test Accuracy: 0.10470000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.10906262, Test Loss: 5.11528571, Test Accuracy: 0.10480000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.10971677, Test Loss: 5.19222917, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.11097025, Test Loss: 5.27387152, Test Accuracy: 0.10530000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.11235884, Test Loss: 5.35281497, Test Accuracy: 0.10550000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.11317595, Test Loss: 5.41805524, Test Accuracy: 0.10560000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.11332806, Test Loss: 5.49194956, Test Accuracy: 0.10540000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.11304655, Test Loss: 5.57474816, Test Accuracy: 0.10540000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.11262951, Test Loss: 5.64088178, Test Accuracy: 0.10550000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.11273466, Test Loss: 5.70883589, Test Accuracy: 0.10480000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.11325461, Test Loss: 5.78852899, Test Accuracy: 0.10500000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.11364664, Test Loss: 5.86437279, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.11430594, Test Loss: 5.92963930, Test Accuracy: 0.10510000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.11532097, Test Loss: 5.99759503, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.11664144, Test Loss: 6.08043769, Test Accuracy: 0.10510000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.11808307, Test Loss: 6.16815946, Test Accuracy: 0.10450000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.11928243, Test Loss: 6.26090934, Test Accuracy: 0.10430000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.11983245, Test Loss: 6.33704208, Test Accuracy: 0.10410000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.11959879, Test Loss: 6.39015703, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.11884279, Test Loss: 6.41855732, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.11821877, Test Loss: 6.43504009, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.11827073, Test Loss: 6.45892199, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.11845406, Test Loss: 6.48284335, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.11830304, Test Loss: 6.50588940, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.11761554, Test Loss: 6.52649585, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.11680177, Test Loss: 6.53086292, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.11604019, Test Loss: 6.53608659, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.11564321, Test Loss: 6.54927047, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.11574817, Test Loss: 6.56777578, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.11598775, Test Loss: 6.59463874, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.11637558, Test Loss: 6.64269420, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.11653211, Test Loss: 6.67951892, Test Accuracy: 0.10340000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.11641319, Test Loss: 6.68128970, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.11631998, Test Loss: 6.67064168, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.11605129, Test Loss: 6.66143510, Test Accuracy: 0.10340000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.11572903, Test Loss: 6.64075400, Test Accuracy: 0.10340000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.11536253, Test Loss: 6.62227982, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.11552779, Test Loss: 6.61530282, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.11641850, Test Loss: 6.59370268, Test Accuracy: 0.10410000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.11715213, Test Loss: 6.55368239, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.11749103, Test Loss: 6.52583885, Test Accuracy: 0.10580000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.11763680, Test Loss: 6.51887451, Test Accuracy: 0.10650000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.11788096, Test Loss: 6.50067894, Test Accuracy: 0.10690000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.11774087, Test Loss: 6.47153782, Test Accuracy: 0.10760000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.11697944, Test Loss: 6.44670679, Test Accuracy: 0.10790000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.11617927, Test Loss: 6.42953599, Test Accuracy: 0.10780000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.11560176, Test Loss: 6.43072704, Test Accuracy: 0.10780000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.11515765, Test Loss: 6.44408049, Test Accuracy: 0.10720000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.11476817, Test Loss: 6.44442578, Test Accuracy: 0.10690000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.11441900, Test Loss: 6.42742081, Test Accuracy: 0.10610000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.11402286, Test Loss: 6.42679491, Test Accuracy: 0.10540000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.11371019, Test Loss: 6.42783273, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.11359215, Test Loss: 6.42611248, Test Accuracy: 0.10570000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.11350861, Test Loss: 6.43002464, Test Accuracy: 0.10540000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.11337716, Test Loss: 6.43934681, Test Accuracy: 0.10580000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.11344829, Test Loss: 6.43419694, Test Accuracy: 0.10600000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.11336916, Test Loss: 6.41596145, Test Accuracy: 0.10610000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.11284656, Test Loss: 6.39678004, Test Accuracy: 0.10570000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.11255512, Test Loss: 6.40588602, Test Accuracy: 0.10540000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.11248208, Test Loss: 6.43939042, Test Accuracy: 0.10450000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.11257187, Test Loss: 6.44964000, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.11317179, Test Loss: 6.42857186, Test Accuracy: 0.10460000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.11446072, Test Loss: 6.43754356, Test Accuracy: 0.10580000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.11550505, Test Loss: 6.45285221, Test Accuracy: 0.10580000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.11603993, Test Loss: 6.47430922, Test Accuracy: 0.10530000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.11670102, Test Loss: 6.50134908, Test Accuracy: 0.10480000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.11747111, Test Loss: 6.52599477, Test Accuracy: 0.10470000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.11806475, Test Loss: 6.54671147, Test Accuracy: 0.10430000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.11827156, Test Loss: 6.56953479, Test Accuracy: 0.10470000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.11843121, Test Loss: 6.58813045, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.11888765, Test Loss: 6.59714508, Test Accuracy: 0.10350000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.11930356, Test Loss: 6.60059161, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.11937891, Test Loss: 6.59438335, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.11943502, Test Loss: 6.60455442, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.11960019, Test Loss: 6.64489911, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.11962767, Test Loss: 6.67737486, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.11952802, Test Loss: 6.70144461, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.11982274, Test Loss: 6.71938272, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.12058290, Test Loss: 6.73894559, Test Accuracy: 0.10360000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.12095208, Test Loss: 6.76959270, Test Accuracy: 0.10460000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.12070217, Test Loss: 6.77575568, Test Accuracy: 0.10530000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.11974306, Test Loss: 6.74049930, Test Accuracy: 0.10570000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.11835040, Test Loss: 6.69582117, Test Accuracy: 0.10650000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.11720408, Test Loss: 6.67672827, Test Accuracy: 0.10750000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.11694617, Test Loss: 6.70163193, Test Accuracy: 0.10780000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.11730488, Test Loss: 6.74434381, Test Accuracy: 0.10830000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.11770269, Test Loss: 6.77985708, Test Accuracy: 0.10810000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.11778983, Test Loss: 6.82071520, Test Accuracy: 0.10800000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.11800195, Test Loss: 6.86333605, Test Accuracy: 0.10780000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.11835083, Test Loss: 6.90261873, Test Accuracy: 0.10820000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.11865406, Test Loss: 6.93399737, Test Accuracy: 0.10800000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.11894785, Test Loss: 6.95510164, Test Accuracy: 0.10810000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.11932798, Test Loss: 6.97348580, Test Accuracy: 0.10780000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.11966309, Test Loss: 7.00105610, Test Accuracy: 0.10740000\n",
            "average_sparsity: [0.42721429467201233, 0.3882482051849365, 0.3822999894618988, 0.3828319311141968, 0.3823857307434082, 0.3826139569282532, 0.3837595582008362, 0.3836630880832672, 0.38157519698143005, 0.3822669982910156, 0.38087859749794006, 0.37896111607551575, 0.37595272064208984, 0.372639536857605, 0.36842024326324463, 0.3634364604949951, 0.3585801124572754, 0.353324830532074, 0.34954744577407837, 0.3459615409374237, 0.34178629517555237, 0.33755382895469666, 0.33326372504234314, 0.32980167865753174, 0.3266192674636841, 0.32389312982559204, 0.322516530752182, 0.32162463665008545, 0.32057544589042664, 0.3194963037967682, 0.3179258406162262, 0.3152756690979004, 0.3127287030220032, 0.3105338215827942, 0.3081717789173126, 0.3055768609046936, 0.3027406632900238, 0.3008280098438263, 0.3004607558250427, 0.3009496331214905, 0.3017084002494812, 0.3020421862602234, 0.3023121654987335, 0.3041304349899292, 0.30732840299606323, 0.3102317154407501, 0.31252405047416687, 0.3139451742172241, 0.3154555857181549, 0.3168703019618988, 0.3179786205291748, 0.31836163997650146, 0.3178003132343292, 0.3170553743839264, 0.31678077578544617, 0.31641125679016113, 0.31532400846481323, 0.31368643045425415, 0.31098175048828125, 0.30775904655456543, 0.3051811456680298, 0.3037293553352356, 0.3028383255004883, 0.30173739790916443, 0.30057770013809204, 0.2996663451194763, 0.29913148283958435, 0.2990759611129761, 0.29898375272750854, 0.29858580231666565, 0.29800233244895935, 0.2975143790245056, 0.297011137008667, 0.2964803874492645, 0.29602259397506714, 0.2953338027000427, 0.2942720055580139, 0.2930205464363098, 0.2923423945903778, 0.291861891746521, 0.2913280725479126, 0.29108303785324097, 0.2910694181919098, 0.2910422384738922, 0.2907056510448456, 0.2905155420303345, 0.2905484139919281, 0.290980726480484, 0.29155081510543823, 0.2919788658618927, 0.2923245131969452, 0.29271844029426575, 0.29293930530548096, 0.2929055094718933, 0.2928631901741028, 0.29293307662010193, 0.29318034648895264, 0.29337576031684875, 0.2931498885154724, 0.29253098368644714]\n",
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.13029181, Test Loss: 7.52368907, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09978468, Test Loss: 6.06976309, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.06037081, Test Loss: 4.91067327, Test Accuracy: 0.12010000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.04360264, Test Loss: 4.34164892, Test Accuracy: 0.17700000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.03753936, Test Loss: 3.93751297, Test Accuracy: 0.20660000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.03418012, Test Loss: 3.72822810, Test Accuracy: 0.25330000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.03203084, Test Loss: 3.31242460, Test Accuracy: 0.30050000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.03060871, Test Loss: 3.35817113, Test Accuracy: 0.30910000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.03006954, Test Loss: 3.11992646, Test Accuracy: 0.33860000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.02900660, Test Loss: 3.04738623, Test Accuracy: 0.35890000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.02806450, Test Loss: 2.87537155, Test Accuracy: 0.36540000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.02825313, Test Loss: 2.76289004, Test Accuracy: 0.38460000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.02738642, Test Loss: 2.82497193, Test Accuracy: 0.38580000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.02635898, Test Loss: 2.74023478, Test Accuracy: 0.40100000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.02573559, Test Loss: 2.64060163, Test Accuracy: 0.40680000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.02488988, Test Loss: 2.57646699, Test Accuracy: 0.41090000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.02459803, Test Loss: 2.45291151, Test Accuracy: 0.42670000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.02388637, Test Loss: 2.31496651, Test Accuracy: 0.43560000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.02301650, Test Loss: 2.30650877, Test Accuracy: 0.45830000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.02256025, Test Loss: 2.24649445, Test Accuracy: 0.46570000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.02255201, Test Loss: 2.10933161, Test Accuracy: 0.47150000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.02169769, Test Loss: 2.02665804, Test Accuracy: 0.49460000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.02058755, Test Loss: 2.02690600, Test Accuracy: 0.49850000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.01955655, Test Loss: 1.93152277, Test Accuracy: 0.50050000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.01907856, Test Loss: 1.85502945, Test Accuracy: 0.51370000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.01784711, Test Loss: 2.08634382, Test Accuracy: 0.47680000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.01749523, Test Loss: 2.01667005, Test Accuracy: 0.49280000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.01708860, Test Loss: 1.76481804, Test Accuracy: 0.52500000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.01629143, Test Loss: 1.92498234, Test Accuracy: 0.49860000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01601777, Test Loss: 1.86619068, Test Accuracy: 0.50740000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01538054, Test Loss: 1.74566652, Test Accuracy: 0.54390000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01503109, Test Loss: 1.77473055, Test Accuracy: 0.54550000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01442903, Test Loss: 1.63896831, Test Accuracy: 0.56560000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01402085, Test Loss: 1.68000933, Test Accuracy: 0.56640000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.01403678, Test Loss: 1.55971457, Test Accuracy: 0.58360000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.01326187, Test Loss: 1.55891941, Test Accuracy: 0.58710000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.01331329, Test Loss: 1.59408256, Test Accuracy: 0.58690000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.01232151, Test Loss: 1.50637697, Test Accuracy: 0.59510000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.01231473, Test Loss: 1.42635280, Test Accuracy: 0.62210000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.01161045, Test Loss: 1.54601712, Test Accuracy: 0.59490000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.01160184, Test Loss: 1.69033661, Test Accuracy: 0.58310000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.01124286, Test Loss: 1.44275431, Test Accuracy: 0.63010000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.01146667, Test Loss: 1.32538747, Test Accuracy: 0.63870000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.01091747, Test Loss: 1.35174264, Test Accuracy: 0.63610000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.01071983, Test Loss: 1.43959272, Test Accuracy: 0.63030000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.01044198, Test Loss: 1.30334102, Test Accuracy: 0.65540000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00998862, Test Loss: 1.29677675, Test Accuracy: 0.65430000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00991208, Test Loss: 1.26035103, Test Accuracy: 0.66510000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00995287, Test Loss: 1.26121939, Test Accuracy: 0.67030000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00970520, Test Loss: 1.16887307, Test Accuracy: 0.68450000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00973751, Test Loss: 1.12916894, Test Accuracy: 0.69090000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00929984, Test Loss: 1.10897638, Test Accuracy: 0.69410000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00891020, Test Loss: 1.11903103, Test Accuracy: 0.69370000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00892260, Test Loss: 1.05287048, Test Accuracy: 0.71050000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00879123, Test Loss: 1.07172101, Test Accuracy: 0.70850000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00830779, Test Loss: 1.03867707, Test Accuracy: 0.71610000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00850723, Test Loss: 1.00761556, Test Accuracy: 0.72450000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00850673, Test Loss: 0.98949650, Test Accuracy: 0.72730000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00841965, Test Loss: 0.96471847, Test Accuracy: 0.73220000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00808565, Test Loss: 0.94792168, Test Accuracy: 0.73830000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00789128, Test Loss: 0.92699680, Test Accuracy: 0.74180000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00747723, Test Loss: 0.94793164, Test Accuracy: 0.74290000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00756257, Test Loss: 0.93909030, Test Accuracy: 0.73960000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00757001, Test Loss: 0.98142609, Test Accuracy: 0.73450000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00763360, Test Loss: 0.88661212, Test Accuracy: 0.75600000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00703424, Test Loss: 0.93467421, Test Accuracy: 0.74570000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00744589, Test Loss: 0.85061513, Test Accuracy: 0.76420000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00753741, Test Loss: 0.83011864, Test Accuracy: 0.76790000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00704906, Test Loss: 0.81983594, Test Accuracy: 0.77230000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00695225, Test Loss: 0.82842675, Test Accuracy: 0.77140000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00678913, Test Loss: 0.84896159, Test Accuracy: 0.76640000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00662817, Test Loss: 0.77005360, Test Accuracy: 0.78520000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00658422, Test Loss: 0.75830136, Test Accuracy: 0.78740000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00637484, Test Loss: 0.80755098, Test Accuracy: 0.77530000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00646812, Test Loss: 0.72449651, Test Accuracy: 0.79420000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00648457, Test Loss: 0.76761385, Test Accuracy: 0.78460000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00614095, Test Loss: 0.72299349, Test Accuracy: 0.79760000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00619544, Test Loss: 0.69244980, Test Accuracy: 0.80390000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00570161, Test Loss: 0.70361321, Test Accuracy: 0.80360000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00551068, Test Loss: 0.67588904, Test Accuracy: 0.81040000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00565460, Test Loss: 0.71158530, Test Accuracy: 0.80260000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00531489, Test Loss: 0.70458495, Test Accuracy: 0.80280000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00544373, Test Loss: 0.65956467, Test Accuracy: 0.81560000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00547393, Test Loss: 0.63704176, Test Accuracy: 0.82110000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00545643, Test Loss: 0.62547470, Test Accuracy: 0.82340000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00541556, Test Loss: 0.61220046, Test Accuracy: 0.82670000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00518777, Test Loss: 0.61143229, Test Accuracy: 0.82680000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00500694, Test Loss: 0.60116118, Test Accuracy: 0.82910000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00499919, Test Loss: 0.58431895, Test Accuracy: 0.83430000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00482130, Test Loss: 0.58361048, Test Accuracy: 0.83520000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00481918, Test Loss: 0.56921880, Test Accuracy: 0.83830000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00481666, Test Loss: 0.55440410, Test Accuracy: 0.84210000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00479947, Test Loss: 0.56727010, Test Accuracy: 0.83920000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00460355, Test Loss: 0.53983564, Test Accuracy: 0.84740000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00455787, Test Loss: 0.54716760, Test Accuracy: 0.84690000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00455470, Test Loss: 0.53413185, Test Accuracy: 0.84970000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00455016, Test Loss: 0.52565008, Test Accuracy: 0.85270000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00454808, Test Loss: 0.51723070, Test Accuracy: 0.85560000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00450816, Test Loss: 0.51167030, Test Accuracy: 0.85770000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00448109, Test Loss: 0.50314605, Test Accuracy: 0.85930000\n",
            "average_sparsity: [0.6212347745895386, 0.5902302265167236, 0.5508681535720825, 0.5126428008079529, 0.4941006004810333, 0.4864855110645294, 0.4748772382736206, 0.46790653467178345, 0.461488276720047, 0.4481211006641388, 0.44948598742485046, 0.4472997486591339, 0.4458715319633484, 0.44164004921913147, 0.440030038356781, 0.43716031312942505, 0.43267303705215454, 0.4309222996234894, 0.4261963367462158, 0.419769287109375, 0.420118510723114, 0.4164781868457794, 0.40696457028388977, 0.40302184224128723, 0.3993396759033203, 0.3983074724674225, 0.3977615535259247, 0.3947407901287079, 0.3905690312385559, 0.3876558840274811, 0.3806838095188141, 0.37260547280311584, 0.3747723400592804, 0.3707379996776581, 0.36753711104393005, 0.36132216453552246, 0.35583731532096863, 0.3572644591331482, 0.3549978733062744, 0.35758236050605774, 0.3565059006214142, 0.3547041118144989, 0.3544028699398041, 0.35425812005996704, 0.34841230511665344, 0.3444741666316986, 0.34157595038414, 0.34090206027030945, 0.3352939486503601, 0.3350972533226013, 0.3345975875854492, 0.3342145085334778, 0.3313368260860443, 0.3315522372722626, 0.32825011014938354, 0.32502931356430054, 0.3247593641281128, 0.327873170375824, 0.3279971480369568, 0.32496383786201477, 0.3251507878303528, 0.3251747488975525, 0.3200368285179138, 0.32242220640182495, 0.32003265619277954, 0.3220939338207245, 0.3201046884059906, 0.3198944926261902, 0.31655365228652954, 0.31267887353897095, 0.313701868057251, 0.3126639425754547, 0.3095349073410034, 0.310884028673172, 0.3094506859779358, 0.31167957186698914, 0.3063017725944519, 0.30609002709388733, 0.30024394392967224, 0.2994166612625122, 0.2973693013191223, 0.29925718903541565, 0.2969352900981903, 0.29744282364845276, 0.29674431681632996, 0.29650431871414185, 0.29336345195770264, 0.292904257774353, 0.2928687632083893, 0.28994572162628174, 0.2898406386375427, 0.28950178623199463, 0.2865271270275116, 0.2860337495803833, 0.2841329574584961, 0.2826775014400482, 0.2820965349674225, 0.2818581163883209, 0.28178244829177856, 0.28217563033103943]\n",
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.07157977, Test Loss: 8.02664633, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09526137, Test Loss: 7.72914442, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.10877519, Test Loss: 7.37529991, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.10578042, Test Loss: 6.68467108, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.08958448, Test Loss: 5.83625563, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.07378143, Test Loss: 5.19355082, Test Accuracy: 0.10730000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.06420931, Test Loss: 4.77310317, Test Accuracy: 0.13240000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.05908737, Test Loss: 4.47618608, Test Accuracy: 0.15740000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.05615898, Test Loss: 4.24718460, Test Accuracy: 0.18030000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.05427008, Test Loss: 4.06314611, Test Accuracy: 0.19620000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.05293226, Test Loss: 3.91456308, Test Accuracy: 0.21220000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.05193485, Test Loss: 3.79546597, Test Accuracy: 0.22270000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.05117482, Test Loss: 3.70038399, Test Accuracy: 0.23270000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.05059339, Test Loss: 3.62405380, Test Accuracy: 0.24160000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05015088, Test Loss: 3.56176506, Test Accuracy: 0.24960000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.04981631, Test Loss: 3.50963951, Test Accuracy: 0.25670000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.04956384, Test Loss: 3.46468256, Test Accuracy: 0.26270000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.04937206, Test Loss: 3.42468006, Test Accuracy: 0.26770000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04922399, Test Loss: 3.38802507, Test Accuracy: 0.27220000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.04910682, Test Loss: 3.35356683, Test Accuracy: 0.27540000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.04901119, Test Loss: 3.32049405, Test Accuracy: 0.27930000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.04893041, Test Loss: 3.28827468, Test Accuracy: 0.28270000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.04885973, Test Loss: 3.25661104, Test Accuracy: 0.28550000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.04879578, Test Loss: 3.22539582, Test Accuracy: 0.28860000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.04873606, Test Loss: 3.19464672, Test Accuracy: 0.29220000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.04867853, Test Loss: 3.16443298, Test Accuracy: 0.29470000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.04862121, Test Loss: 3.13482428, Test Accuracy: 0.29840000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.04856200, Test Loss: 3.10585722, Test Accuracy: 0.30160000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.04849861, Test Loss: 3.07753157, Test Accuracy: 0.30460000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.04842856, Test Loss: 3.04985238, Test Accuracy: 0.30730000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.04834908, Test Loss: 3.02294768, Test Accuracy: 0.31000000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.04825732, Test Loss: 2.99717023, Test Accuracy: 0.31360000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.04815117, Test Loss: 2.97293741, Test Accuracy: 0.31690000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.04803059, Test Loss: 2.95040068, Test Accuracy: 0.31900000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.04789825, Test Loss: 2.92935389, Test Accuracy: 0.32120000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.04775880, Test Loss: 2.90937031, Test Accuracy: 0.32410000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.04761710, Test Loss: 2.88993134, Test Accuracy: 0.32760000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.04747667, Test Loss: 2.87054358, Test Accuracy: 0.33080000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.04733839, Test Loss: 2.85084188, Test Accuracy: 0.33290000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.04719991, Test Loss: 2.83067931, Test Accuracy: 0.33650000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.04705652, Test Loss: 2.81013012, Test Accuracy: 0.34070000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.04690397, Test Loss: 2.78937190, Test Accuracy: 0.34410000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.04674439, Test Loss: 2.76833648, Test Accuracy: 0.34720000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.04658992, Test Loss: 2.74630728, Test Accuracy: 0.35010000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.04645051, Test Loss: 2.72227298, Test Accuracy: 0.35470000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.04632225, Test Loss: 2.69576111, Test Accuracy: 0.35960000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.04619617, Test Loss: 2.66696419, Test Accuracy: 0.36510000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.04606559, Test Loss: 2.63639738, Test Accuracy: 0.36990000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.04592481, Test Loss: 2.60466222, Test Accuracy: 0.37510000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.04576711, Test Loss: 2.57231254, Test Accuracy: 0.38050000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.04558564, Test Loss: 2.53971091, Test Accuracy: 0.38530000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.04537646, Test Loss: 2.50696612, Test Accuracy: 0.39080000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.04514006, Test Loss: 2.47401764, Test Accuracy: 0.39610000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.04488023, Test Loss: 2.44078807, Test Accuracy: 0.40100000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.04460187, Test Loss: 2.40726115, Test Accuracy: 0.40670000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.04430976, Test Loss: 2.37346681, Test Accuracy: 0.41140000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.04400848, Test Loss: 2.33942323, Test Accuracy: 0.41600000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.04370261, Test Loss: 2.30513552, Test Accuracy: 0.42170000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.04339643, Test Loss: 2.27068642, Test Accuracy: 0.42710000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.04309277, Test Loss: 2.23627483, Test Accuracy: 0.43320000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.04279231, Test Loss: 2.20213492, Test Accuracy: 0.43840000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.04249419, Test Loss: 2.16842798, Test Accuracy: 0.44380000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.04219727, Test Loss: 2.13523273, Test Accuracy: 0.44960000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.04190069, Test Loss: 2.10263996, Test Accuracy: 0.45430000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.04160352, Test Loss: 2.07085309, Test Accuracy: 0.46020000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.04130446, Test Loss: 2.04019865, Test Accuracy: 0.46610000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.04100205, Test Loss: 2.01103429, Test Accuracy: 0.47050000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.04069542, Test Loss: 1.98360595, Test Accuracy: 0.47560000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.04038457, Test Loss: 1.95797093, Test Accuracy: 0.48070000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.04007016, Test Loss: 1.93399843, Test Accuracy: 0.48580000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.03975301, Test Loss: 1.91143386, Test Accuracy: 0.48950000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.03943368, Test Loss: 1.88995240, Test Accuracy: 0.49340000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.03911246, Test Loss: 1.86919259, Test Accuracy: 0.49640000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.03878951, Test Loss: 1.84877869, Test Accuracy: 0.49960000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.03846504, Test Loss: 1.82836731, Test Accuracy: 0.50340000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.03813952, Test Loss: 1.80770331, Test Accuracy: 0.50670000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.03781358, Test Loss: 1.78665673, Test Accuracy: 0.51110000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.03748793, Test Loss: 1.76522539, Test Accuracy: 0.51410000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.03716314, Test Loss: 1.74349690, Test Accuracy: 0.51720000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.03683964, Test Loss: 1.72160620, Test Accuracy: 0.52190000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.03651764, Test Loss: 1.69969095, Test Accuracy: 0.52650000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.03619735, Test Loss: 1.67786564, Test Accuracy: 0.53130000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.03587898, Test Loss: 1.65619081, Test Accuracy: 0.53550000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.03556287, Test Loss: 1.63465572, Test Accuracy: 0.53970000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.03524953, Test Loss: 1.61317211, Test Accuracy: 0.54390000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.03493961, Test Loss: 1.59159608, Test Accuracy: 0.54830000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.03463374, Test Loss: 1.56977528, Test Accuracy: 0.55260000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.03433235, Test Loss: 1.54759381, Test Accuracy: 0.55780000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.03403550, Test Loss: 1.52499376, Test Accuracy: 0.56160000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.03374286, Test Loss: 1.50197692, Test Accuracy: 0.56630000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.03345366, Test Loss: 1.47859298, Test Accuracy: 0.57140000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.03316682, Test Loss: 1.45492988, Test Accuracy: 0.57630000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.03288113, Test Loss: 1.43110221, Test Accuracy: 0.58200000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.03259540, Test Loss: 1.40724359, Test Accuracy: 0.58820000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.03230862, Test Loss: 1.38349149, Test Accuracy: 0.59470000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.03202009, Test Loss: 1.35997688, Test Accuracy: 0.60150000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.03172938, Test Loss: 1.33681465, Test Accuracy: 0.60650000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.03143638, Test Loss: 1.31409798, Test Accuracy: 0.61260000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.03114124, Test Loss: 1.29189590, Test Accuracy: 0.61800000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.03084429, Test Loss: 1.27025215, Test Accuracy: 0.62340000\n",
            "average_sparsity: [0.007292159367352724, 0.012420893646776676, 0.025288062170147896, 0.04976729676127434, 0.0795758068561554, 0.1045018807053566, 0.1228514164686203, 0.13660062849521637, 0.14733800292015076, 0.1560266613960266, 0.16327233612537384, 0.1694699227809906, 0.17487967014312744, 0.1796768307685852, 0.18398363888263702, 0.1878879964351654, 0.19145503640174866, 0.19473513960838318, 0.19777007400989532, 0.20059742033481598, 0.2032528668642044, 0.20577028393745422, 0.20817974209785461, 0.2105044424533844, 0.21275903284549713, 0.21495209634304047, 0.21709148585796356, 0.21918947994709015, 0.22126571834087372, 0.2233482152223587, 0.22547422349452972, 0.22768162190914154, 0.22998608648777008, 0.23236852884292603, 0.23479558527469635, 0.23724402487277985, 0.23970447480678558, 0.24217349290847778, 0.24464714527130127, 0.2471187561750412, 0.24958208203315735, 0.2520396113395691, 0.25451093912124634, 0.25702396035194397, 0.2595873177051544, 0.26218369603157043, 0.26478296518325806, 0.26735183596611023, 0.26986080408096313, 0.2722889184951782, 0.274627685546875, 0.27688169479370117, 0.27906516194343567, 0.2811976969242096, 0.28329998254776, 0.2853910028934479, 0.28748705983161926, 0.28959983587265015, 0.29173383116722107, 0.29388558864593506, 0.2960461974143982, 0.29820454120635986, 0.30035001039505005, 0.30247464776039124, 0.30457448959350586, 0.3066490590572357, 0.30869975686073303, 0.31072625517845154, 0.3127240538597107, 0.31468403339385986, 0.3165944218635559, 0.3184446394443512, 0.320226788520813, 0.32193705439567566, 0.3235756456851959, 0.32514721155166626, 0.3266602158546448, 0.3281252384185791, 0.3295532763004303, 0.3309538662433624, 0.33233362436294556, 0.33369606733322144, 0.33504122495651245, 0.33636611700057983, 0.33766525983810425, 0.33893153071403503, 0.34015795588493347, 0.3413398861885071, 0.34247681498527527, 0.34357213973999023, 0.34463217854499817, 0.34566375613212585, 0.34667259454727173, 0.34766238927841187, 0.34863463044166565, 0.3495887815952301, 0.35052308440208435, 0.3514345586299896, 0.3523198068141937, 0.35317543148994446]\n",
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 1.05764004, Test Loss: 4.74753216, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.51947367, Test Loss: 3.94413684, Test Accuracy: 0.11610000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.23277673, Test Loss: 4.00840275, Test Accuracy: 0.17820000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.14786223, Test Loss: 3.86226352, Test Accuracy: 0.25500000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.12162582, Test Loss: 4.50308749, Test Accuracy: 0.25790000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.10961696, Test Loss: 4.79491838, Test Accuracy: 0.26260000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.09516972, Test Loss: 4.87519114, Test Accuracy: 0.31540000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.08682754, Test Loss: 4.70418207, Test Accuracy: 0.35040000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.08030805, Test Loss: 4.60248623, Test Accuracy: 0.35340000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.07507535, Test Loss: 4.55372999, Test Accuracy: 0.37240000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.07275428, Test Loss: 4.27316503, Test Accuracy: 0.39080000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.06891609, Test Loss: 4.50622649, Test Accuracy: 0.38100000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.06290723, Test Loss: 4.14638008, Test Accuracy: 0.39650000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.06017181, Test Loss: 4.16122381, Test Accuracy: 0.40800000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05397640, Test Loss: 4.24567883, Test Accuracy: 0.40370000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.05113797, Test Loss: 3.83619081, Test Accuracy: 0.44350000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.05317003, Test Loss: 3.82977814, Test Accuracy: 0.46160000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.05277407, Test Loss: 3.15282711, Test Accuracy: 0.50180000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.05237044, Test Loss: 3.32179075, Test Accuracy: 0.47750000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.05211416, Test Loss: 2.63805034, Test Accuracy: 0.52940000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.04919215, Test Loss: 2.45111012, Test Accuracy: 0.54520000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.04767025, Test Loss: 2.21985748, Test Accuracy: 0.57350000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.04528268, Test Loss: 1.98336207, Test Accuracy: 0.59610000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.04068648, Test Loss: 1.78492155, Test Accuracy: 0.61820000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.03691679, Test Loss: 1.57228429, Test Accuracy: 0.64790000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.03252997, Test Loss: 1.50559469, Test Accuracy: 0.66220000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.02803394, Test Loss: 1.48139440, Test Accuracy: 0.66140000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.02513794, Test Loss: 1.44955210, Test Accuracy: 0.66850000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.02139210, Test Loss: 1.45321302, Test Accuracy: 0.67100000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01887065, Test Loss: 1.41565507, Test Accuracy: 0.68480000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01635280, Test Loss: 1.41754587, Test Accuracy: 0.68610000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01430384, Test Loss: 1.40593218, Test Accuracy: 0.69690000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01239155, Test Loss: 1.40754500, Test Accuracy: 0.69810000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01083535, Test Loss: 1.37363057, Test Accuracy: 0.70700000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00944238, Test Loss: 1.38075977, Test Accuracy: 0.70810000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00828455, Test Loss: 1.34121907, Test Accuracy: 0.71830000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00720729, Test Loss: 1.32270847, Test Accuracy: 0.72490000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00633673, Test Loss: 1.27146449, Test Accuracy: 0.73730000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00546771, Test Loss: 1.28395249, Test Accuracy: 0.74260000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00476481, Test Loss: 1.29270470, Test Accuracy: 0.74810000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00407853, Test Loss: 1.29015764, Test Accuracy: 0.75530000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00359823, Test Loss: 1.20503175, Test Accuracy: 0.76920000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00311409, Test Loss: 1.15336984, Test Accuracy: 0.78070000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00271745, Test Loss: 1.17458480, Test Accuracy: 0.77740000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00234425, Test Loss: 1.18103044, Test Accuracy: 0.77730000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00205791, Test Loss: 1.15135160, Test Accuracy: 0.78620000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00175660, Test Loss: 1.15047114, Test Accuracy: 0.78810000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00151310, Test Loss: 1.14411772, Test Accuracy: 0.79450000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00128803, Test Loss: 1.13774974, Test Accuracy: 0.79730000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00108094, Test Loss: 1.12930275, Test Accuracy: 0.80430000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00090405, Test Loss: 1.09773295, Test Accuracy: 0.81300000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00073325, Test Loss: 1.06897048, Test Accuracy: 0.81830000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00057901, Test Loss: 1.06461323, Test Accuracy: 0.82140000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00043878, Test Loss: 1.06749866, Test Accuracy: 0.82410000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00032099, Test Loss: 1.09338083, Test Accuracy: 0.82290000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00025302, Test Loss: 1.08401694, Test Accuracy: 0.82730000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00019776, Test Loss: 1.09445245, Test Accuracy: 0.82920000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00016272, Test Loss: 1.18276667, Test Accuracy: 0.82350000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00015158, Test Loss: 1.09884070, Test Accuracy: 0.83050000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00014008, Test Loss: 1.13859999, Test Accuracy: 0.83030000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00013542, Test Loss: 1.10254008, Test Accuracy: 0.82940000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00013964, Test Loss: 1.12153469, Test Accuracy: 0.83600000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00015990, Test Loss: 1.31403547, Test Accuracy: 0.82580000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00042648, Test Loss: 1.09419469, Test Accuracy: 0.84180000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00058546, Test Loss: 0.77414427, Test Accuracy: 0.88690000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00082758, Test Loss: 0.77296877, Test Accuracy: 0.88700000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00088335, Test Loss: 0.80184857, Test Accuracy: 0.87760000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00108360, Test Loss: 0.77490115, Test Accuracy: 0.88430000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00102274, Test Loss: 0.69611278, Test Accuracy: 0.89630000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00100176, Test Loss: 0.75441645, Test Accuracy: 0.89090000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00093800, Test Loss: 0.71324700, Test Accuracy: 0.89690000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00070968, Test Loss: 0.66045228, Test Accuracy: 0.90520000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00065664, Test Loss: 0.63645403, Test Accuracy: 0.90710000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00051677, Test Loss: 0.63557178, Test Accuracy: 0.90750000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00039412, Test Loss: 0.60274715, Test Accuracy: 0.91260000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00029719, Test Loss: 0.62172230, Test Accuracy: 0.91040000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00023022, Test Loss: 0.63385152, Test Accuracy: 0.90880000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00017269, Test Loss: 0.65373787, Test Accuracy: 0.90670000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00013999, Test Loss: 0.63861377, Test Accuracy: 0.90910000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00009973, Test Loss: 0.57836421, Test Accuracy: 0.91620000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00007449, Test Loss: 0.56061011, Test Accuracy: 0.92060000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00007513, Test Loss: 0.57038504, Test Accuracy: 0.92000000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00006736, Test Loss: 0.57242069, Test Accuracy: 0.92070000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00005757, Test Loss: 0.55917254, Test Accuracy: 0.92340000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00005841, Test Loss: 0.54545560, Test Accuracy: 0.92290000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00004462, Test Loss: 0.56684018, Test Accuracy: 0.92150000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00004000, Test Loss: 0.54540131, Test Accuracy: 0.92400000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00003479, Test Loss: 0.54518011, Test Accuracy: 0.92520000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00003010, Test Loss: 0.56871586, Test Accuracy: 0.92420000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00011692, Test Loss: 0.57730284, Test Accuracy: 0.92000000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00024953, Test Loss: 0.63209182, Test Accuracy: 0.91410000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00060159, Test Loss: 0.47990891, Test Accuracy: 0.93360000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00060576, Test Loss: 0.47652850, Test Accuracy: 0.93410000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00061036, Test Loss: 0.44015324, Test Accuracy: 0.93850000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00059275, Test Loss: 0.45379175, Test Accuracy: 0.93820000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00043513, Test Loss: 0.45345910, Test Accuracy: 0.93690000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00037335, Test Loss: 0.40693856, Test Accuracy: 0.94420000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00026099, Test Loss: 0.40186846, Test Accuracy: 0.94410000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00016845, Test Loss: 0.39438442, Test Accuracy: 0.94670000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00010723, Test Loss: 0.39662052, Test Accuracy: 0.94620000\n",
            "average_sparsity: [0.7525463104248047, 0.7144788503646851, 0.6459507942199707, 0.6085421442985535, 0.566763162612915, 0.5419018268585205, 0.5289127230644226, 0.5318166613578796, 0.5120419263839722, 0.5034035444259644, 0.49275830388069153, 0.47522684931755066, 0.48138290643692017, 0.470488578081131, 0.4710094630718231, 0.47867056727409363, 0.4769432544708252, 0.48547059297561646, 0.4767043888568878, 0.48573821783065796, 0.4845014214515686, 0.48920589685440063, 0.4918367266654968, 0.4939539134502411, 0.4946765601634979, 0.4906468689441681, 0.48921987414360046, 0.48510313034057617, 0.4849178194999695, 0.4849490821361542, 0.4841020107269287, 0.4829857051372528, 0.4828817844390869, 0.4819571375846863, 0.48124071955680847, 0.480637788772583, 0.4802083969116211, 0.4795342683792114, 0.47812989354133606, 0.47805625200271606, 0.476742148399353, 0.47826412320137024, 0.4770650863647461, 0.4770090878009796, 0.4748864769935608, 0.4756217300891876, 0.47580674290657043, 0.47612157464027405, 0.4755576252937317, 0.47538575530052185, 0.4748513698577881, 0.4752640128135681, 0.47433990240097046, 0.4738384783267975, 0.4744512140750885, 0.47437015175819397, 0.4736076295375824, 0.4728749394416809, 0.47377490997314453, 0.4728158712387085, 0.4719754755496979, 0.47208642959594727, 0.474076509475708, 0.47204092144966125, 0.47158437967300415, 0.47270357608795166, 0.4750587046146393, 0.47316282987594604, 0.47382256388664246, 0.4733729362487793, 0.472806453704834, 0.4724333584308624, 0.4741349518299103, 0.4722873568534851, 0.47224634885787964, 0.4727542996406555, 0.4727281332015991, 0.4723649024963379, 0.47297403216362, 0.4721021056175232, 0.4710051715373993, 0.470538467168808, 0.47074371576309204, 0.46957656741142273, 0.4712815284729004, 0.47027119994163513, 0.47001826763153076, 0.4701163172721863, 0.4696875512599945, 0.4711907207965851, 0.47023066878318787, 0.4721813499927521, 0.47020336985588074, 0.47193804383277893, 0.4707927703857422, 0.4722164571285248, 0.4717051386833191, 0.4712255001068115, 0.47111180424690247, 0.47037938237190247]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xuZk4enEvWV"
      },
      "source": [
        "# Seed 1234"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYAsf9zeEvcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943979f1-f588-49f7-987d-e05be3265940"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Adadelta\n",
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, sparsity, Adadelta_avg_selectivity_list, Adadelta_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"seed1234_sorted_batch_50_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adadelta_avg_selectivity_list)+'\\n'+str(Adadelta_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_sorted_batch_50_Adadelta.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adagrad\n",
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, sparsity, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"seed1234_sorted_batch_50_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_sorted_batch_50_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# SGD \n",
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, sparsity, SGD_avg_selectivity_list, SGD_std_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"seed1234_sorted_batch_50_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(sparsity)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_sorted_batch_50_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "\n",
        "# Adam \n",
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, sparsity, Adam_avg_selectivity_list, Adam_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"seed1234_sorted_batch_50_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(sparsity)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp seed1234_sorted_batch_50_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.33591804, Test Loss: 6.77225713, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.22175279, Test Loss: 5.33478603, Test Accuracy: 0.10100000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.13385248, Test Loss: 4.95120373, Test Accuracy: 0.10220000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.11782450, Test Loss: 4.83367791, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.11225529, Test Loss: 4.82234744, Test Accuracy: 0.10460000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.11045434, Test Loss: 4.86903218, Test Accuracy: 0.10470000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.11021173, Test Loss: 4.95318904, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.11140450, Test Loss: 5.05721367, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.11243132, Test Loss: 5.16634407, Test Accuracy: 0.10340000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.11322253, Test Loss: 5.25695338, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.11353741, Test Loss: 5.32133599, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.11369136, Test Loss: 5.38823013, Test Accuracy: 0.10300000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.11473928, Test Loss: 5.45755475, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.11590206, Test Loss: 5.53794964, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.11642350, Test Loss: 5.62643661, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.11605621, Test Loss: 5.70021931, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.11555873, Test Loss: 5.77600324, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.11524817, Test Loss: 5.86074392, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.11506120, Test Loss: 5.94678373, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.11506274, Test Loss: 6.01275220, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.11509568, Test Loss: 6.06183725, Test Accuracy: 0.10290000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.11491199, Test Loss: 6.09963762, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.11428046, Test Loss: 6.11911821, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.11405352, Test Loss: 6.15121440, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.11437774, Test Loss: 6.19527265, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.11449925, Test Loss: 6.23600418, Test Accuracy: 0.10220000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.11442009, Test Loss: 6.26809725, Test Accuracy: 0.10200000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.11476581, Test Loss: 6.29514317, Test Accuracy: 0.10200000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.11568816, Test Loss: 6.31997740, Test Accuracy: 0.10200000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.11630089, Test Loss: 6.35266756, Test Accuracy: 0.10200000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.11661699, Test Loss: 6.39577524, Test Accuracy: 0.10220000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.11711547, Test Loss: 6.45924857, Test Accuracy: 0.10210000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.11791429, Test Loss: 6.52420631, Test Accuracy: 0.10180000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.11854265, Test Loss: 6.55378015, Test Accuracy: 0.10190000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.11896456, Test Loss: 6.57782208, Test Accuracy: 0.10190000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.11944667, Test Loss: 6.61529333, Test Accuracy: 0.10180000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.12031781, Test Loss: 6.63423685, Test Accuracy: 0.10210000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.12088935, Test Loss: 6.60637207, Test Accuracy: 0.10230000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.12092492, Test Loss: 6.59923373, Test Accuracy: 0.10230000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.12057425, Test Loss: 6.63196136, Test Accuracy: 0.10230000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.12060602, Test Loss: 6.65959791, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.12061489, Test Loss: 6.67759625, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.12041330, Test Loss: 6.69128338, Test Accuracy: 0.10300000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.12003096, Test Loss: 6.69006434, Test Accuracy: 0.10290000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.11977143, Test Loss: 6.69288192, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.11997089, Test Loss: 6.69472433, Test Accuracy: 0.10250000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.12020376, Test Loss: 6.69024605, Test Accuracy: 0.10210000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.12010459, Test Loss: 6.67937267, Test Accuracy: 0.10220000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.11952143, Test Loss: 6.67129503, Test Accuracy: 0.10240000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.11856408, Test Loss: 6.69294464, Test Accuracy: 0.10250000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.11760953, Test Loss: 6.72134632, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.11681663, Test Loss: 6.72503225, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.11614810, Test Loss: 6.72530800, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.11545949, Test Loss: 6.72603292, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.11473039, Test Loss: 6.73906884, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.11450608, Test Loss: 6.75642854, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.11458121, Test Loss: 6.78305116, Test Accuracy: 0.10260000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.11476121, Test Loss: 6.82119101, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.11515279, Test Loss: 6.84594124, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.11591496, Test Loss: 6.87704443, Test Accuracy: 0.10270000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.11705144, Test Loss: 6.92887444, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.11813823, Test Loss: 6.99662035, Test Accuracy: 0.10290000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.11895730, Test Loss: 7.04746431, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.11980477, Test Loss: 7.07304892, Test Accuracy: 0.10280000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.12053694, Test Loss: 7.07315860, Test Accuracy: 0.10290000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.12105056, Test Loss: 7.04947999, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.12142106, Test Loss: 7.01439534, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.12174842, Test Loss: 6.97632714, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.12203636, Test Loss: 6.94238517, Test Accuracy: 0.10430000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.12242422, Test Loss: 6.91963966, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.12257233, Test Loss: 6.89633488, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.12188814, Test Loss: 6.88262261, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.12137939, Test Loss: 6.85145616, Test Accuracy: 0.10320000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.12118591, Test Loss: 6.80245074, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.12075800, Test Loss: 6.75829304, Test Accuracy: 0.10330000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.12044711, Test Loss: 6.72037635, Test Accuracy: 0.10380000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.11995122, Test Loss: 6.67709924, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.11923770, Test Loss: 6.64049371, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.11875875, Test Loss: 6.64746532, Test Accuracy: 0.10390000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.11891010, Test Loss: 6.68685338, Test Accuracy: 0.10370000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.11943065, Test Loss: 6.70702705, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.11972349, Test Loss: 6.71294396, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.11957688, Test Loss: 6.71020432, Test Accuracy: 0.10420000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.11953641, Test Loss: 6.69697638, Test Accuracy: 0.10430000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.11951876, Test Loss: 6.69378933, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.11945195, Test Loss: 6.70877159, Test Accuracy: 0.10410000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.11934291, Test Loss: 6.72689511, Test Accuracy: 0.10400000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.11903591, Test Loss: 6.72215724, Test Accuracy: 0.10420000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.11862538, Test Loss: 6.69184022, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.11829612, Test Loss: 6.65382414, Test Accuracy: 0.10440000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.11803091, Test Loss: 6.61389099, Test Accuracy: 0.10500000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.11825951, Test Loss: 6.57635777, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.11850570, Test Loss: 6.54751361, Test Accuracy: 0.10530000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.11820447, Test Loss: 6.52733693, Test Accuracy: 0.10570000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.11750807, Test Loss: 6.50812885, Test Accuracy: 0.10620000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.11712953, Test Loss: 6.49922739, Test Accuracy: 0.10730000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.11712989, Test Loss: 6.50416175, Test Accuracy: 0.10720000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.11729544, Test Loss: 6.50312472, Test Accuracy: 0.10710000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.11731303, Test Loss: 6.48794528, Test Accuracy: 0.10730000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.11722347, Test Loss: 6.47328645, Test Accuracy: 0.10790000\n",
            "average_sparsity: [0.43566781282424927, 0.37546825408935547, 0.37055346369743347, 0.3734463155269623, 0.3770914673805237, 0.3793446719646454, 0.3797175884246826, 0.37897181510925293, 0.37899360060691833, 0.378841370344162, 0.3792148530483246, 0.37855595350265503, 0.37789326906204224, 0.37708571553230286, 0.3758178651332855, 0.3739530146121979, 0.3707928955554962, 0.3678675889968872, 0.36563169956207275, 0.36410394310951233, 0.3618656396865845, 0.3586415648460388, 0.35560494661331177, 0.3521336019039154, 0.3477463722229004, 0.3429640233516693, 0.3377116620540619, 0.33323001861572266, 0.32966089248657227, 0.32606077194213867, 0.32191285490989685, 0.31802934408187866, 0.3154372572898865, 0.31403958797454834, 0.3127894997596741, 0.3115479350090027, 0.3107353150844574, 0.3101567029953003, 0.30857858061790466, 0.3064373731613159, 0.30462852120399475, 0.3028515577316284, 0.30119505524635315, 0.29949042201042175, 0.29804670810699463, 0.29719308018684387, 0.29682186245918274, 0.2976255416870117, 0.2998429834842682, 0.3022996485233307, 0.30433404445648193, 0.30611586570739746, 0.3076261579990387, 0.3092339038848877, 0.31067144870758057, 0.3115719258785248, 0.3123377561569214, 0.31335723400115967, 0.31427958607673645, 0.314592182636261, 0.31395405530929565, 0.31284210085868835, 0.31230080127716064, 0.31235551834106445, 0.31276580691337585, 0.31352323293685913, 0.31428778171539307, 0.31457382440567017, 0.31471049785614014, 0.3146061599254608, 0.31433436274528503, 0.3146045506000519, 0.3160408139228821, 0.3184557557106018, 0.3214014768600464, 0.3235309422016144, 0.3240979313850403, 0.32248449325561523, 0.3204908072948456, 0.31929174065589905, 0.31852662563323975, 0.31822606921195984, 0.3184044361114502, 0.3182072639465332, 0.3170652389526367, 0.31580981612205505, 0.3151051700115204, 0.31525227427482605, 0.3156209886074066, 0.315693199634552, 0.31593334674835205, 0.31595009565353394, 0.316091924905777, 0.3166746199131012, 0.3175065815448761, 0.3182777762413025, 0.3187687397003174, 0.31942683458328247, 0.3200121819972992, 0.32038414478302]\n",
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.12220196, Test Loss: 7.85323755, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.10598629, Test Loss: 5.52130537, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.06905007, Test Loss: 4.84587723, Test Accuracy: 0.10310000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.04875726, Test Loss: 4.08344539, Test Accuracy: 0.15570000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.03995411, Test Loss: 4.04545963, Test Accuracy: 0.19390000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.03690345, Test Loss: 3.51317985, Test Accuracy: 0.25060000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.03464242, Test Loss: 3.39494062, Test Accuracy: 0.28420000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.03324447, Test Loss: 3.38403138, Test Accuracy: 0.30480000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.03178344, Test Loss: 3.21723452, Test Accuracy: 0.34370000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.02986799, Test Loss: 3.10068907, Test Accuracy: 0.35730000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.02897340, Test Loss: 3.00624527, Test Accuracy: 0.36830000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.02894021, Test Loss: 2.91818118, Test Accuracy: 0.38050000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.02804331, Test Loss: 2.82627300, Test Accuracy: 0.38210000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.02685466, Test Loss: 3.02981568, Test Accuracy: 0.37380000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.02636076, Test Loss: 2.87923126, Test Accuracy: 0.40630000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.02487218, Test Loss: 2.76680504, Test Accuracy: 0.41160000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.02422796, Test Loss: 2.66485182, Test Accuracy: 0.42680000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.02371284, Test Loss: 2.45148837, Test Accuracy: 0.44470000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.02271048, Test Loss: 2.59058142, Test Accuracy: 0.42560000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.02227534, Test Loss: 2.43796425, Test Accuracy: 0.44080000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.02121605, Test Loss: 2.27846961, Test Accuracy: 0.45850000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.02174645, Test Loss: 2.31362155, Test Accuracy: 0.45030000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.02107233, Test Loss: 2.14925298, Test Accuracy: 0.47100000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.02040383, Test Loss: 2.13073390, Test Accuracy: 0.46780000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.01971288, Test Loss: 2.18510133, Test Accuracy: 0.47350000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.01850399, Test Loss: 2.13891740, Test Accuracy: 0.46700000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.01894543, Test Loss: 2.27632986, Test Accuracy: 0.45940000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.01816735, Test Loss: 2.14445537, Test Accuracy: 0.48520000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.01761325, Test Loss: 2.07988147, Test Accuracy: 0.48910000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01723174, Test Loss: 2.00465510, Test Accuracy: 0.50100000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01659813, Test Loss: 1.99069055, Test Accuracy: 0.50830000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01554292, Test Loss: 1.95921285, Test Accuracy: 0.50990000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01598645, Test Loss: 1.85096906, Test Accuracy: 0.52470000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01503709, Test Loss: 1.83047315, Test Accuracy: 0.52790000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.01484392, Test Loss: 1.84800811, Test Accuracy: 0.52700000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.01434101, Test Loss: 1.73299987, Test Accuracy: 0.54430000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.01452515, Test Loss: 1.70352946, Test Accuracy: 0.55340000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.01361943, Test Loss: 1.66867013, Test Accuracy: 0.56040000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.01340380, Test Loss: 1.59319129, Test Accuracy: 0.58360000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.01360532, Test Loss: 1.63075922, Test Accuracy: 0.57000000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.01342599, Test Loss: 1.60353146, Test Accuracy: 0.56830000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.01309215, Test Loss: 1.57660398, Test Accuracy: 0.58390000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.01247537, Test Loss: 1.53143643, Test Accuracy: 0.58480000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.01166615, Test Loss: 1.52788085, Test Accuracy: 0.58880000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.01201209, Test Loss: 1.45581171, Test Accuracy: 0.61240000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.01130768, Test Loss: 1.52045169, Test Accuracy: 0.59970000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.01137771, Test Loss: 1.47599515, Test Accuracy: 0.62050000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.01105974, Test Loss: 1.55807752, Test Accuracy: 0.59420000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.01077625, Test Loss: 1.55928101, Test Accuracy: 0.60060000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.01031576, Test Loss: 1.54722129, Test Accuracy: 0.62590000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.01045111, Test Loss: 1.48063297, Test Accuracy: 0.62970000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.01047238, Test Loss: 1.41320468, Test Accuracy: 0.64590000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.01020560, Test Loss: 1.28630584, Test Accuracy: 0.67430000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00980863, Test Loss: 1.30720751, Test Accuracy: 0.66760000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00992241, Test Loss: 1.26869581, Test Accuracy: 0.67630000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00984017, Test Loss: 1.21327330, Test Accuracy: 0.68740000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00958667, Test Loss: 1.17712674, Test Accuracy: 0.69500000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00877282, Test Loss: 1.14570077, Test Accuracy: 0.70550000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00866231, Test Loss: 1.08031236, Test Accuracy: 0.71900000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00903226, Test Loss: 1.07785247, Test Accuracy: 0.71610000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00874294, Test Loss: 1.07300915, Test Accuracy: 0.71530000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00839198, Test Loss: 1.03422206, Test Accuracy: 0.72430000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00806377, Test Loss: 1.05781916, Test Accuracy: 0.71590000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00789947, Test Loss: 0.99575343, Test Accuracy: 0.73400000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00791899, Test Loss: 0.92767232, Test Accuracy: 0.75060000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00792234, Test Loss: 0.91837786, Test Accuracy: 0.75110000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00776875, Test Loss: 0.88115744, Test Accuracy: 0.75960000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00786805, Test Loss: 0.84696329, Test Accuracy: 0.77100000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00759634, Test Loss: 0.83609377, Test Accuracy: 0.77190000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00768656, Test Loss: 0.82475559, Test Accuracy: 0.77480000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00733317, Test Loss: 0.80232219, Test Accuracy: 0.78360000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00725908, Test Loss: 0.81235699, Test Accuracy: 0.77860000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00711734, Test Loss: 0.80463974, Test Accuracy: 0.78030000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00701280, Test Loss: 0.77750901, Test Accuracy: 0.78690000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00706660, Test Loss: 0.76366081, Test Accuracy: 0.79020000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00710832, Test Loss: 0.74925069, Test Accuracy: 0.79240000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00683997, Test Loss: 0.75167573, Test Accuracy: 0.79140000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00673357, Test Loss: 0.72914429, Test Accuracy: 0.79720000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00667746, Test Loss: 0.71059769, Test Accuracy: 0.80170000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00645486, Test Loss: 0.70640757, Test Accuracy: 0.80310000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00629806, Test Loss: 0.70305748, Test Accuracy: 0.80380000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00604325, Test Loss: 0.67538339, Test Accuracy: 0.81170000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00602607, Test Loss: 0.65289839, Test Accuracy: 0.81830000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00603119, Test Loss: 0.63163428, Test Accuracy: 0.82370000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00595893, Test Loss: 0.61375770, Test Accuracy: 0.82820000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00596677, Test Loss: 0.59808315, Test Accuracy: 0.83340000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00590151, Test Loss: 0.58343087, Test Accuracy: 0.83740000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00561496, Test Loss: 0.56612437, Test Accuracy: 0.84290000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00573762, Test Loss: 0.57803295, Test Accuracy: 0.83950000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00548087, Test Loss: 0.56375954, Test Accuracy: 0.84350000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00546559, Test Loss: 0.55497793, Test Accuracy: 0.84670000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00517410, Test Loss: 0.53908130, Test Accuracy: 0.85080000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00521650, Test Loss: 0.52567947, Test Accuracy: 0.85470000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00544852, Test Loss: 0.51894064, Test Accuracy: 0.85670000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00546093, Test Loss: 0.51067089, Test Accuracy: 0.85870000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00542630, Test Loss: 0.50244523, Test Accuracy: 0.86100000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00525958, Test Loss: 0.50844330, Test Accuracy: 0.85910000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00496964, Test Loss: 0.47939181, Test Accuracy: 0.86670000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00513664, Test Loss: 0.48795841, Test Accuracy: 0.86500000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00515440, Test Loss: 0.47696091, Test Accuracy: 0.86710000\n",
            "average_sparsity: [0.6148084402084351, 0.6223792433738708, 0.5788204669952393, 0.5548815727233887, 0.5424625277519226, 0.528937578201294, 0.5131034255027771, 0.5048015713691711, 0.49320343136787415, 0.48517218232154846, 0.48053276538848877, 0.4790864884853363, 0.4795670807361603, 0.47512221336364746, 0.46572011709213257, 0.45893794298171997, 0.4532552659511566, 0.44763046503067017, 0.43883445858955383, 0.4335807263851166, 0.4326913058757782, 0.4286682605743408, 0.43316441774368286, 0.42686161398887634, 0.420451819896698, 0.4185734987258911, 0.4120531380176544, 0.40898260474205017, 0.4065617024898529, 0.40546536445617676, 0.4072170555591583, 0.4024983048439026, 0.3976607024669647, 0.3938213288784027, 0.3943176865577698, 0.3941335082054138, 0.39219021797180176, 0.389460951089859, 0.38450726866722107, 0.38856804370880127, 0.3857022821903229, 0.3814949691295624, 0.3783581852912903, 0.3742907643318176, 0.3731403946876526, 0.3713628947734833, 0.37114250659942627, 0.3708955943584442, 0.3668445646762848, 0.36087527871131897, 0.36041751503944397, 0.3597368001937866, 0.3581429719924927, 0.3553348481655121, 0.35491958260536194, 0.3543715476989746, 0.35385552048683167, 0.3499312698841095, 0.3493708670139313, 0.34730949997901917, 0.3441831171512604, 0.3408242166042328, 0.3435913324356079, 0.3375341594219208, 0.34027260541915894, 0.33720946311950684, 0.33690395951271057, 0.339534193277359, 0.33912193775177, 0.3363195061683655, 0.3354455232620239, 0.3324444890022278, 0.329225093126297, 0.33168089389801025, 0.33143869042396545, 0.33113062381744385, 0.3280719518661499, 0.32774245738983154, 0.32752668857574463, 0.3246387839317322, 0.32200518250465393, 0.32148122787475586, 0.32147639989852905, 0.32143983244895935, 0.3215085566043854, 0.3214631974697113, 0.3213329315185547, 0.3198232054710388, 0.31886622309684753, 0.32007187604904175, 0.31970980763435364, 0.3204548954963684, 0.3205145597457886, 0.320492684841156, 0.32034122943878174, 0.3202417492866516, 0.31740278005599976, 0.31716883182525635, 0.3171694874763489, 0.31979289650917053]\n",
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.07188815, Test Loss: 8.03594959, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09457783, Test Loss: 7.72066192, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.10806838, Test Loss: 7.35494859, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.10518980, Test Loss: 6.65342834, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.08928283, Test Loss: 5.82095388, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.07402646, Test Loss: 5.20819009, Test Accuracy: 0.10520000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.06472894, Test Loss: 4.80202919, Test Accuracy: 0.12990000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.05967019, Test Loss: 4.50689798, Test Accuracy: 0.15470000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.05674928, Test Loss: 4.27438377, Test Accuracy: 0.17790000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.05486428, Test Loss: 4.08564608, Test Accuracy: 0.19460000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.05353471, Test Loss: 3.93270465, Test Accuracy: 0.20940000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.05254664, Test Loss: 3.80995646, Test Accuracy: 0.22050000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.05179048, Test Loss: 3.71193503, Test Accuracy: 0.22950000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.05120036, Test Loss: 3.63337435, Test Accuracy: 0.23760000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05073114, Test Loss: 3.56963116, Test Accuracy: 0.24690000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.05034877, Test Loss: 3.51692912, Test Accuracy: 0.25350000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.05002650, Test Loss: 3.47235950, Test Accuracy: 0.25900000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.04974351, Test Loss: 3.43372632, Test Accuracy: 0.26410000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04948450, Test Loss: 3.39936756, Test Accuracy: 0.26830000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.04923939, Test Loss: 3.36801611, Test Accuracy: 0.27240000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.04900281, Test Loss: 3.33873028, Test Accuracy: 0.27560000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.04877355, Test Loss: 3.31084944, Test Accuracy: 0.27980000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.04855331, Test Loss: 3.28393281, Test Accuracy: 0.28360000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.04834520, Test Loss: 3.25767573, Test Accuracy: 0.28590000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.04815203, Test Loss: 3.23181615, Test Accuracy: 0.28880000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.04797495, Test Loss: 3.20607945, Test Accuracy: 0.29210000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.04781285, Test Loss: 3.18017086, Test Accuracy: 0.29500000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.04766249, Test Loss: 3.15380162, Test Accuracy: 0.29760000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.04751921, Test Loss: 3.12674104, Test Accuracy: 0.30080000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.04737808, Test Loss: 3.09887492, Test Accuracy: 0.30580000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.04723492, Test Loss: 3.07025560, Test Accuracy: 0.31010000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.04708707, Test Loss: 3.04112481, Test Accuracy: 0.31400000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.04693338, Test Loss: 3.01187968, Test Accuracy: 0.31810000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.04677399, Test Loss: 2.98297437, Test Accuracy: 0.32330000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.04660995, Test Loss: 2.95477224, Test Accuracy: 0.32750000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.04644306, Test Loss: 2.92742547, Test Accuracy: 0.33160000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.04627575, Test Loss: 2.90085782, Test Accuracy: 0.33500000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.04611088, Test Loss: 2.87484318, Test Accuracy: 0.33920000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.04595127, Test Loss: 2.84911419, Test Accuracy: 0.34420000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.04579899, Test Loss: 2.82341049, Test Accuracy: 0.34830000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.04565467, Test Loss: 2.79749049, Test Accuracy: 0.35140000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.04551727, Test Loss: 2.77113495, Test Accuracy: 0.35670000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.04538448, Test Loss: 2.74416931, Test Accuracy: 0.36010000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.04525329, Test Loss: 2.71648830, Test Accuracy: 0.36500000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.04512045, Test Loss: 2.68806291, Test Accuracy: 0.36930000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.04498263, Test Loss: 2.65893675, Test Accuracy: 0.37280000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.04483668, Test Loss: 2.62921415, Test Accuracy: 0.37700000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.04467995, Test Loss: 2.59903842, Test Accuracy: 0.38100000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.04451054, Test Loss: 2.56857757, Test Accuracy: 0.38550000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.04432764, Test Loss: 2.53800680, Test Accuracy: 0.38950000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.04413167, Test Loss: 2.50750261, Test Accuracy: 0.39410000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.04392430, Test Loss: 2.47722149, Test Accuracy: 0.39820000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.04370819, Test Loss: 2.44727343, Test Accuracy: 0.40270000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.04348660, Test Loss: 2.41770613, Test Accuracy: 0.40720000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.04326286, Test Loss: 2.38850646, Test Accuracy: 0.41240000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.04303999, Test Loss: 2.35962550, Test Accuracy: 0.41540000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.04282035, Test Loss: 2.33099904, Test Accuracy: 0.41880000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.04260541, Test Loss: 2.30256481, Test Accuracy: 0.42290000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.04239578, Test Loss: 2.27425633, Test Accuracy: 0.42800000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.04219113, Test Loss: 2.24600942, Test Accuracy: 0.43230000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.04199030, Test Loss: 2.21776755, Test Accuracy: 0.43620000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.04179132, Test Loss: 2.18950067, Test Accuracy: 0.44030000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.04159165, Test Loss: 2.16122189, Test Accuracy: 0.44280000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.04138851, Test Loss: 2.13298701, Test Accuracy: 0.44690000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.04117945, Test Loss: 2.10487393, Test Accuracy: 0.45150000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.04096287, Test Loss: 2.07695604, Test Accuracy: 0.45560000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.04073839, Test Loss: 2.04927845, Test Accuracy: 0.46000000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.04050670, Test Loss: 2.02184927, Test Accuracy: 0.46440000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.04026912, Test Loss: 1.99464641, Test Accuracy: 0.46840000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.04002708, Test Loss: 1.96763610, Test Accuracy: 0.47270000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.03978165, Test Loss: 1.94078751, Test Accuracy: 0.47640000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.03953333, Test Loss: 1.91409536, Test Accuracy: 0.48190000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.03928205, Test Loss: 1.88758414, Test Accuracy: 0.48670000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.03902714, Test Loss: 1.86131891, Test Accuracy: 0.49090000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.03876757, Test Loss: 1.83539025, Test Accuracy: 0.49550000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.03850218, Test Loss: 1.80990185, Test Accuracy: 0.49930000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.03822989, Test Loss: 1.78494516, Test Accuracy: 0.50370000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.03795000, Test Loss: 1.76057702, Test Accuracy: 0.50830000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.03766221, Test Loss: 1.73680871, Test Accuracy: 0.51280000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.03736674, Test Loss: 1.71361290, Test Accuracy: 0.51780000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.03706416, Test Loss: 1.69092772, Test Accuracy: 0.52290000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.03675538, Test Loss: 1.66867458, Test Accuracy: 0.52660000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.03644153, Test Loss: 1.64676585, Test Accuracy: 0.53180000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.03612392, Test Loss: 1.62511398, Test Accuracy: 0.53560000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.03580393, Test Loss: 1.60363348, Test Accuracy: 0.54030000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.03548289, Test Loss: 1.58224348, Test Accuracy: 0.54470000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.03516199, Test Loss: 1.56087069, Test Accuracy: 0.54960000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.03484215, Test Loss: 1.53945308, Test Accuracy: 0.55540000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.03452401, Test Loss: 1.51794339, Test Accuracy: 0.56050000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.03420794, Test Loss: 1.49631394, Test Accuracy: 0.56540000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.03389397, Test Loss: 1.47456526, Test Accuracy: 0.57070000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.03358195, Test Loss: 1.45273670, Test Accuracy: 0.57650000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.03327154, Test Loss: 1.43090673, Test Accuracy: 0.58240000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.03296236, Test Loss: 1.40918709, Test Accuracy: 0.58790000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.03265408, Test Loss: 1.38771486, Test Accuracy: 0.59270000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.03234653, Test Loss: 1.36663024, Test Accuracy: 0.59830000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.03203966, Test Loss: 1.34606074, Test Accuracy: 0.60310000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.03173355, Test Loss: 1.32610707, Test Accuracy: 0.60770000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.03142846, Test Loss: 1.30683488, Test Accuracy: 0.61300000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.03112474, Test Loss: 1.28827425, Test Accuracy: 0.61670000\n",
            "average_sparsity: [0.006831657607108355, 0.012209131382405758, 0.025628790259361267, 0.0507710836827755, 0.08100958913564682, 0.10623331367969513, 0.12491137534379959, 0.13903121650218964, 0.15012004971504211, 0.15906570851802826, 0.16643062233924866, 0.17260758578777313, 0.17787984013557434, 0.18245267868041992, 0.18647660315036774, 0.1900644600391388, 0.19330357015132904, 0.1962640881538391, 0.19900386035442352, 0.20157043635845184, 0.2040001004934311, 0.20631630718708038, 0.20853012800216675, 0.21064387261867523, 0.212656170129776, 0.21456709504127502, 0.21638263761997223, 0.21811750531196594, 0.21979600191116333, 0.22144892811775208, 0.22310632467269897, 0.22478869557380676, 0.22650407254695892, 0.2282533496618271, 0.23003675043582916, 0.23185451328754425, 0.23370690643787384, 0.23559823632240295, 0.2375398427248001, 0.2395450472831726, 0.24162012338638306, 0.24375952780246735, 0.24594934284687042, 0.2481737732887268, 0.2504206895828247, 0.2526835799217224, 0.2549613416194916, 0.25725501775741577, 0.2595657706260681, 0.26189330220222473, 0.2642362117767334, 0.2665933668613434, 0.2689647078514099, 0.27135008573532104, 0.27374744415283203, 0.27615150809288025, 0.27855414152145386, 0.2809460759162903, 0.2833191752433777, 0.28566843271255493, 0.2879928946495056, 0.290294885635376, 0.2925778925418854, 0.2948437035083771, 0.2970903217792511, 0.2993108034133911, 0.301493763923645, 0.3036254644393921, 0.3056928515434265, 0.3076866567134857, 0.3096023499965668, 0.3114403188228607, 0.31320464611053467, 0.31490185856819153, 0.31653931736946106, 0.31812384724617004, 0.3196602165699005, 0.3211510181427002, 0.32259735465049744, 0.3239994943141937, 0.32535767555236816, 0.32667210698127747, 0.327942818403244, 0.3291696608066559, 0.3303528428077698, 0.3314937353134155, 0.3325957655906677, 0.33366480469703674, 0.3347087800502777, 0.3357366919517517, 0.33675724267959595, 0.3377772867679596, 0.33880066871643066, 0.3398277461528778, 0.3408559262752533, 0.3418806195259094, 0.3428962826728821, 0.34389710426330566, 0.344877690076828, 0.3458331823348999]\n",
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 1.10031075, Test Loss: 4.01909903, Test Accuracy: 0.10090000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.53833463, Test Loss: 4.05385364, Test Accuracy: 0.12730000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.23309692, Test Loss: 3.80070496, Test Accuracy: 0.20430000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.16086641, Test Loss: 3.97841413, Test Accuracy: 0.29140000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.12659945, Test Loss: 4.52598934, Test Accuracy: 0.27850000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.10771019, Test Loss: 4.35666140, Test Accuracy: 0.31980000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.10235983, Test Loss: 4.70853412, Test Accuracy: 0.32930000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.09752820, Test Loss: 5.07527573, Test Accuracy: 0.33350000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.08808949, Test Loss: 4.79712376, Test Accuracy: 0.35110000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.08359344, Test Loss: 4.59711161, Test Accuracy: 0.34980000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.07943142, Test Loss: 4.60401670, Test Accuracy: 0.34600000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.07172030, Test Loss: 4.47677645, Test Accuracy: 0.37570000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.06933873, Test Loss: 4.13548190, Test Accuracy: 0.38090000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.06252593, Test Loss: 4.09276466, Test Accuracy: 0.40580000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.05756212, Test Loss: 3.73755399, Test Accuracy: 0.41320000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.05663607, Test Loss: 3.56742018, Test Accuracy: 0.43230000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.04983606, Test Loss: 3.16689743, Test Accuracy: 0.45810000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.04710658, Test Loss: 3.25934134, Test Accuracy: 0.47250000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.04491209, Test Loss: 2.81038662, Test Accuracy: 0.50510000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.04095736, Test Loss: 2.75928055, Test Accuracy: 0.52660000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.03925275, Test Loss: 2.44738222, Test Accuracy: 0.55190000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.03725837, Test Loss: 2.34138838, Test Accuracy: 0.56960000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.03633050, Test Loss: 2.13001037, Test Accuracy: 0.59670000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.03637452, Test Loss: 1.91666841, Test Accuracy: 0.61760000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.03442677, Test Loss: 1.63756113, Test Accuracy: 0.64460000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.03169357, Test Loss: 1.54782546, Test Accuracy: 0.65910000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.02752529, Test Loss: 1.41859665, Test Accuracy: 0.67680000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.02480675, Test Loss: 1.34364989, Test Accuracy: 0.68920000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.02163046, Test Loss: 1.28751971, Test Accuracy: 0.69780000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.01897218, Test Loss: 1.31586019, Test Accuracy: 0.70560000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.01687801, Test Loss: 1.30871427, Test Accuracy: 0.70820000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.01505190, Test Loss: 1.27408789, Test Accuracy: 0.71830000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.01322814, Test Loss: 1.23578607, Test Accuracy: 0.73080000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.01149503, Test Loss: 1.18591353, Test Accuracy: 0.74150000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00996603, Test Loss: 1.20812462, Test Accuracy: 0.73950000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00883190, Test Loss: 1.09507976, Test Accuracy: 0.76050000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00750262, Test Loss: 1.08345969, Test Accuracy: 0.76390000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00643714, Test Loss: 1.06872953, Test Accuracy: 0.76930000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00536726, Test Loss: 1.11339057, Test Accuracy: 0.76740000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00451698, Test Loss: 1.13774461, Test Accuracy: 0.76470000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00377273, Test Loss: 1.14119872, Test Accuracy: 0.76410000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00319577, Test Loss: 1.17993957, Test Accuracy: 0.76220000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00266453, Test Loss: 1.16172110, Test Accuracy: 0.76770000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00229246, Test Loss: 1.18623113, Test Accuracy: 0.77040000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00193550, Test Loss: 1.19238352, Test Accuracy: 0.77620000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00162299, Test Loss: 1.22203306, Test Accuracy: 0.77570000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00133898, Test Loss: 1.23186908, Test Accuracy: 0.77890000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00108507, Test Loss: 1.27434089, Test Accuracy: 0.78030000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00090644, Test Loss: 1.28389270, Test Accuracy: 0.78130000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00078642, Test Loss: 1.30028183, Test Accuracy: 0.78780000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00066386, Test Loss: 1.24839165, Test Accuracy: 0.79490000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00055931, Test Loss: 1.25549046, Test Accuracy: 0.79850000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00046261, Test Loss: 1.24387493, Test Accuracy: 0.80350000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00038483, Test Loss: 1.24523515, Test Accuracy: 0.80670000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00031101, Test Loss: 1.20553539, Test Accuracy: 0.81330000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00025487, Test Loss: 1.19806304, Test Accuracy: 0.81810000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00021841, Test Loss: 1.17713594, Test Accuracy: 0.82290000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00017901, Test Loss: 1.28938967, Test Accuracy: 0.81340000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00015249, Test Loss: 1.34957257, Test Accuracy: 0.81240000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00032493, Test Loss: 1.29589360, Test Accuracy: 0.81650000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00063677, Test Loss: 1.16083156, Test Accuracy: 0.82920000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00104957, Test Loss: 1.11231252, Test Accuracy: 0.83660000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00093883, Test Loss: 0.98531018, Test Accuracy: 0.84780000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00076339, Test Loss: 0.97013608, Test Accuracy: 0.85070000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00059327, Test Loss: 0.88235406, Test Accuracy: 0.86140000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00050371, Test Loss: 0.82946545, Test Accuracy: 0.86600000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00042883, Test Loss: 0.81261112, Test Accuracy: 0.87100000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00039303, Test Loss: 0.87002130, Test Accuracy: 0.86520000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00035268, Test Loss: 0.87266179, Test Accuracy: 0.86350000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00035018, Test Loss: 0.83205214, Test Accuracy: 0.87200000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00036248, Test Loss: 0.79633506, Test Accuracy: 0.87550000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00029674, Test Loss: 0.92559892, Test Accuracy: 0.86220000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00024917, Test Loss: 0.80747710, Test Accuracy: 0.87780000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00017791, Test Loss: 0.75653285, Test Accuracy: 0.88540000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00012428, Test Loss: 0.74715742, Test Accuracy: 0.88700000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00008765, Test Loss: 0.76252384, Test Accuracy: 0.88580000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00006388, Test Loss: 0.78384508, Test Accuracy: 0.88390000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00004431, Test Loss: 0.78132457, Test Accuracy: 0.88730000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00002982, Test Loss: 0.73986519, Test Accuracy: 0.89410000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00001967, Test Loss: 0.73731069, Test Accuracy: 0.89580000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00001284, Test Loss: 0.73606589, Test Accuracy: 0.89700000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00000839, Test Loss: 0.76062069, Test Accuracy: 0.89520000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00000550, Test Loss: 0.78061615, Test Accuracy: 0.89530000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00000364, Test Loss: 0.80283094, Test Accuracy: 0.89470000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00000243, Test Loss: 0.82673721, Test Accuracy: 0.89460000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00000164, Test Loss: 0.85043417, Test Accuracy: 0.89330000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00000112, Test Loss: 0.87507775, Test Accuracy: 0.89200000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00000079, Test Loss: 0.89849567, Test Accuracy: 0.89130000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00000057, Test Loss: 0.91840656, Test Accuracy: 0.89080000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00000042, Test Loss: 0.93296174, Test Accuracy: 0.89040000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00000033, Test Loss: 0.94235265, Test Accuracy: 0.89090000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00000026, Test Loss: 0.94487063, Test Accuracy: 0.89200000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00000022, Test Loss: 0.94219475, Test Accuracy: 0.89320000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00000019, Test Loss: 0.93529953, Test Accuracy: 0.89560000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00000017, Test Loss: 0.92649646, Test Accuracy: 0.89770000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00000015, Test Loss: 0.91879798, Test Accuracy: 0.89870000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00000014, Test Loss: 0.91000930, Test Accuracy: 0.90090000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00000013, Test Loss: 0.90365000, Test Accuracy: 0.90310000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00000013, Test Loss: 0.89700828, Test Accuracy: 0.90460000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00000012, Test Loss: 0.89239847, Test Accuracy: 0.90540000\n",
            "average_sparsity: [0.7703942060470581, 0.7088980674743652, 0.636671781539917, 0.6021402478218079, 0.5725269913673401, 0.5537888407707214, 0.5127103924751282, 0.48901963233947754, 0.4850417375564575, 0.48501190543174744, 0.48083069920539856, 0.49710243940353394, 0.49560797214508057, 0.4900054335594177, 0.4989006817340851, 0.5008727312088013, 0.5073590874671936, 0.5051964521408081, 0.5149542689323425, 0.5125081539154053, 0.5198582410812378, 0.5151672959327698, 0.5210272669792175, 0.5254974961280823, 0.5278899073600769, 0.524996280670166, 0.5270345211029053, 0.5267647504806519, 0.5241597890853882, 0.5220052599906921, 0.5196812152862549, 0.5190473198890686, 0.5172591209411621, 0.5177476406097412, 0.5133537650108337, 0.5156581401824951, 0.5158548355102539, 0.515781819820404, 0.5142369866371155, 0.5104882121086121, 0.5117831826210022, 0.5105692148208618, 0.5105671286582947, 0.5111477971076965, 0.5112496614456177, 0.5096072554588318, 0.5088174939155579, 0.5079690217971802, 0.508064866065979, 0.506784200668335, 0.5065722465515137, 0.5065017342567444, 0.5059938430786133, 0.5051613450050354, 0.503730058670044, 0.5033711194992065, 0.5040075182914734, 0.5042386054992676, 0.5028917193412781, 0.5006831288337708, 0.49803492426872253, 0.5059126019477844, 0.5057653188705444, 0.5060620307922363, 0.5074645280838013, 0.5070151090621948, 0.5055915117263794, 0.5060185790061951, 0.5073351860046387, 0.5048775672912598, 0.5055659413337708, 0.5045615434646606, 0.5025289058685303, 0.5023365020751953, 0.5017833113670349, 0.5014244914054871, 0.5014172792434692, 0.5015247464179993, 0.5020010471343994, 0.5008664131164551, 0.5001654028892517, 0.49920782446861267, 0.4983469843864441, 0.4977818429470062, 0.49719926714897156, 0.49674057960510254, 0.4963407814502716, 0.4959579110145569, 0.49562153220176697, 0.4953451156616211, 0.495135635137558, 0.49501898884773254, 0.49493271112442017, 0.49492841958999634, 0.4949207603931427, 0.49495184421539307, 0.49499642848968506, 0.4950355589389801, 0.4950273931026459, 0.495074987411499]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}