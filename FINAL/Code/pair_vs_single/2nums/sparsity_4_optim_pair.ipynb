{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparsity_4_optim_pair.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/sparsity_4_optim_pair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MU1dnFxiZMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c732e1-b191-498e-d389-78bbf4af2cb5"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOk6y_H5IWHx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iJa_LOiivEN"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = datasets.MNIST(root='./data', \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-pSE5X3i3l5"
      },
      "source": [
        "# class_inds 이거는 그냥 위에있는거를 list 로 만들어준 형태임 \n",
        "class_inds = [torch.where(mnist_trainset.targets == class_idx)[0]\n",
        "              for class_idx in mnist_trainset.class_to_idx.values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2bTkOMQj_3t",
        "outputId": "4dca8fa3-bd2a-4af5-af2e-e5ca4e79704c"
      },
      "source": [
        "train_dataloaders = [\n",
        "                     DataLoader(dataset=Subset(mnist_trainset, inds),\n",
        "                                batch_size=25,\n",
        "                                shuffle=True,\n",
        "                                drop_last=False\n",
        "                     )\n",
        "                     for inds in class_inds\n",
        "]\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)\n",
        "\n",
        "print(\"Training dataset size: \", len(mnist_trainset))\n",
        "print(\"Testing dataset size: \",  len(mnist_testset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size:  60000\n",
            "Testing dataset size:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSkAos_Jq7jP"
      },
      "source": [
        "# ************* modify this section for later use *************\n",
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # modify this section for later use \n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid12  = torch.nn.Sigmoid()\n",
        "\n",
        "        self.layer_activations = dict()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # modify this section for later use \n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid12(x)\n",
        "        pred = self.linear_2(x)\n",
        "        return pred\n",
        "# ************* modify this section for later use *************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLpFwF1dIueK"
      },
      "source": [
        "def get_activation(model, layer_name):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations[layer_name] = output\n",
        "    return hook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZAZN91tIvF0"
      },
      "source": [
        "def sparsity_calculator(final_spareness):\n",
        "    sparseness_list = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sT7PSGTIwjO"
      },
      "source": [
        "def model_factory(optimizer_name):\n",
        "    '''\n",
        "    optimizer_name : choose one of Adagrad, Adadelta, SGD, and Adam \n",
        "\n",
        "    '''\n",
        "    my_model = Model()\n",
        "    print(\"my_model:\", my_model)\n",
        "    my_model.to(device)\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    # modify this section for later use \n",
        "    my_model.sigmoid12.register_forward_hook(get_activation(my_model, 's12'))\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    if optimizer_name == 'Adadelta':\n",
        "        my_optimizer = torch.optim.Adadelta(my_model.parameters(), lr=1.0)\n",
        "\n",
        "    elif optimizer_name == 'Adagrad':\n",
        "        my_optimizer = torch.optim.Adagrad(my_model.parameters(), lr=0.1)\n",
        "\n",
        "    elif optimizer_name == 'SGD':\n",
        "        my_optimizer = torch.optim.SGD(my_model.parameters(), lr=0.1)\n",
        "\n",
        "    elif optimizer_name == 'Adam':\n",
        "        my_optimizer = torch.optim.Adam(my_model.parameters(), lr=0.001)\n",
        "\n",
        "    else:\n",
        "        print(\"ERROR\")\n",
        "    \n",
        "    print(\"my_optimizer:\", my_optimizer)\n",
        "    test_acc, sparseness_list = sparsity_trainer(optimizer=my_optimizer, model=my_model)\n",
        "    # ************* modify this section for later use *************\n",
        "    file_saver = open(f\"sparsity_4_optim_pair_{optimizer_name}.txt\", \"w\")\n",
        "    # ************* modify this section for later use *************\n",
        "    file_saver.write(str(test_acc)+'\\n'+str(sparseness_list)+'\\n\\n')\n",
        "    file_saver.close()\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    if optimizer_name == 'Adadelta':\n",
        "        !cp sparsity_4_optim_pair_Adadelta.txt /content/drive/MyDrive\n",
        "    \n",
        "    elif optimizer_name == 'Adagrad':\n",
        "        !cp sparsity_4_optim_pair_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "    elif optimizer_name == 'SGD':\n",
        "        !cp sparsity_4_optim_pair_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "    elif optimizer_name == 'Adam':\n",
        "        !cp sparsity_4_optim_pair_Adam.txt /content/drive/MyDrive\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    else:\n",
        "        print(\"ERROR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnD7OdVYlo7H"
      },
      "source": [
        "def sparsity_trainer(optimizer, model):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    no_epochs = 30\n",
        "    test_acc   = list()\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    final_spareness_12 = list()\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        print(f\"epoch {epoch} started\")\n",
        "\n",
        "        # ************* modify this section for later use *************\n",
        "        hidden_layer_activation_list_12 = list()\n",
        "        # ************* modify this section for later use *************\n",
        "\n",
        "        # TRAINING \n",
        "        model.train()\n",
        "        iterators = list(map(iter, train_dataloaders))   \n",
        "        while iterators:    # This part is same as for loop \n",
        "            iterator = np.random.choice(iterators, 2, replace=False)\n",
        "            try:\n",
        "                image0, label0 = next(iterator[0]) \n",
        "                image1, label1 = next(iterator[1]) \n",
        "\n",
        "                image = torch.cat((image0, image1), 0)\n",
        "                label = torch.cat((label0, label1), 0)\n",
        "\n",
        "                # This is needed!!\n",
        "                indexes = torch.randperm(label.shape[0])\n",
        "                image = image[indexes]\n",
        "                label = label[indexes]\n",
        "                # This is needed!!\n",
        "\n",
        "                image, label = image.to(device), label.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                pred = model(image)\n",
        "\n",
        "                loss = criterion(pred, label)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "            except StopIteration:\n",
        "                iterators.remove(iterator[0])\n",
        "                iterators.remove(iterator[1])\n",
        "\n",
        "        # TESTING\n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (image, label) in enumerate(test_dataloader):\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "\n",
        "            loss = criterion(pred, label)\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if label[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            # ***************** sparsity calculation ***************** #\n",
        "            hidden_layer_activation_list_12.append(model.layer_activations['s12'])\n",
        "\n",
        "        # this conains activations for all epochs \n",
        "        final_spareness_12.append(hidden_layer_activation_list_12)\n",
        "        # ***************** sparsity calculation ***************** # \n",
        "\n",
        "        accuracy = total / len(mnist_testset)\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, accuracy))\n",
        "\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "    sparsity_list12 = sparsity_calculator(final_spareness_12)\n",
        "\n",
        "    average_sparsity = list()\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list12[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    print(\"average_sparsity:\", average_sparsity)\n",
        "\n",
        "    return test_acc, average_sparsity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFYvV3lWUdrH"
      },
      "source": [
        "# Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCJH9d7XUbNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7983a8d5-b7f2-45db-bc43-c43a55af550b"
      },
      "source": [
        "model_factory('Adadelta')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-06\n",
            "    lr: 1.0\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.71160000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.85490000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.86920000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.82560000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.91520000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.93710000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.93940000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.95850000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.91250000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.93130000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.95890000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.95410000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.92460000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.97410000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.95990000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.97490000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.97050000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.95310000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.96740000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.97200000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.97060000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.97470000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.96980000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.97740000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.97250000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.97530000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.97660000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.97360000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.97460000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.97730000\n",
            "average_sparsity: [0.23166777193546295, 0.27380794286727905, 0.2914932072162628, 0.3103908896446228, 0.318589985370636, 0.3234449625015259, 0.3309441804885864, 0.3305570185184479, 0.3346746861934662, 0.33517447113990784, 0.33786696195602417, 0.3382599353790283, 0.34111976623535156, 0.3382435441017151, 0.3404232859611511, 0.3397424519062042, 0.34085583686828613, 0.3410276770591736, 0.3396528959274292, 0.3392779231071472, 0.3413742780685425, 0.34128591418266296, 0.34152963757514954, 0.34035855531692505, 0.3420051336288452, 0.34242117404937744, 0.34190693497657776, 0.34184297919273376, 0.3409082293510437, 0.3420644700527191]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0epauTHjUfJ4"
      },
      "source": [
        "# Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO-2R8L9UbsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039720e4-87ce-4fcb-d861-d14a4f156030"
      },
      "source": [
        "model_factory('Adagrad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.1\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.83230000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.94260000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.95630000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.95980000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.95310000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.96700000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.96470000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.96950000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.97160000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.96750000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.97250000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.97080000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.97490000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.97640000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.97650000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.97530000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.97690000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.97720000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.97730000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.97740000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.97540000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.97710000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.97700000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.97690000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.97630000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.97770000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.97790000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.97730000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.97750000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.97830000\n",
            "average_sparsity: [0.5728862285614014, 0.5844084024429321, 0.588485836982727, 0.59225994348526, 0.5817651152610779, 0.5831990242004395, 0.5906397700309753, 0.5817526578903198, 0.5803399085998535, 0.5848724246025085, 0.5826888680458069, 0.578300952911377, 0.5802327394485474, 0.5784422159194946, 0.5778511762619019, 0.5786556005477905, 0.5771688222885132, 0.5770535469055176, 0.5774509906768799, 0.5778053998947144, 0.5754936933517456, 0.5754261016845703, 0.5771382451057434, 0.5756393671035767, 0.575100839138031, 0.5762434601783752, 0.5740160346031189, 0.5741292834281921, 0.5753452777862549, 0.574831485748291]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xsh5pRjUhz_"
      },
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em71M6KcUbup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c551c89-f7c9-4aa3-8e3d-1bb9f9642a9f"
      },
      "source": [
        "model_factory('SGD')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.62950000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.87690000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.82530000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.87220000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.84410000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.86830000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.88090000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.89440000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.91920000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.93780000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.92810000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.92370000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.91490000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.95510000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.92830000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.93970000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.94650000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.95430000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.94490000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.96100000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.95230000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.96020000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.94940000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.96140000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.95160000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.96830000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.96850000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.96340000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.96730000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.96210000\n",
            "average_sparsity: [0.1571091264486313, 0.17815673351287842, 0.19581343233585358, 0.21104097366333008, 0.2268022894859314, 0.2416137158870697, 0.2538661062717438, 0.26896151900291443, 0.2798875868320465, 0.28954261541366577, 0.2973926365375519, 0.30111703276634216, 0.3117227852344513, 0.3148600459098816, 0.3212759792804718, 0.326869934797287, 0.33047157526016235, 0.3329704999923706, 0.3360951244831085, 0.33999988436698914, 0.3441324532032013, 0.34338074922561646, 0.34635525941848755, 0.34923189878463745, 0.3518449068069458, 0.3512856066226959, 0.3536544740200043, 0.3552187383174896, 0.35747888684272766, 0.35802018642425537]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1YSFjUZUjtH"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdoLly2DUb0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c7a379-8408-4528-83be-d7cedf7dc92c"
      },
      "source": [
        "model_factory('Adam')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.86250000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.84770000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.89480000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.86000000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.89620000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.91890000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.91880000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.91830000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.94840000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.92830000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.96860000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.96520000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.96690000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.96390000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.97570000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.96650000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.97400000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.97370000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.97530000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.97260000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.97320000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.97990000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.97050000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.97670000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.98040000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.97200000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.97840000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.97800000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.97820000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.97920000\n",
            "average_sparsity: [0.1880270391702652, 0.21928754448890686, 0.23307466506958008, 0.2563428580760956, 0.2705974280834198, 0.2810235321521759, 0.2863481640815735, 0.29070430994033813, 0.2944151759147644, 0.30053943395614624, 0.30660679936408997, 0.30772635340690613, 0.31130728125572205, 0.31456637382507324, 0.3163769543170929, 0.31488683819770813, 0.3161180317401886, 0.3178153336048126, 0.31920570135116577, 0.31792229413986206, 0.3188897967338562, 0.32101988792419434, 0.3229570686817169, 0.3217028081417084, 0.32114964723587036, 0.3219515085220337, 0.3256753385066986, 0.3249970078468323, 0.3242623805999756, 0.3254129886627197]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}