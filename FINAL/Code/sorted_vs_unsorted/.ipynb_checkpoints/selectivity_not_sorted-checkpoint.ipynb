{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/selectivity_not_sorted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7STrWa0P3z_",
    "outputId": "741edaf5-e472-489b-ce73-6f955f6f23d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4j9WoP-UnAm"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApOU7hvb95W4"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTW5TOUnP5XY"
   },
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, \n",
    "                                download=True, \n",
    "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_testset  = datasets.MNIST(root='./data', \n",
    "                                train=False, \n",
    "                                download=True, \n",
    "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, \n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
    "                                               batch_size=50, \n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXTkEUJ5P6kU"
   },
   "outputs": [],
   "source": [
    "# Define the model \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear_1 = torch.nn.Linear(784, 256)\n",
    "        self.linear_2 = torch.nn.Linear(256, 10)\n",
    "        self.sigmoid  = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        pred = self.linear_2(x)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfgvKH6eP9Ou"
   },
   "outputs": [],
   "source": [
    "def get_activation(model):    \n",
    "    def hook(module, input, output):\n",
    "        model.layer_activations = output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvHGO5RSvi6I"
   },
   "outputs": [],
   "source": [
    "def selectivity(hidden_layer_each_neuron):\n",
    "    __selectivity__ = list()\n",
    "    # I will now try to find the average of each class for each neuron.\n",
    "    # check out the next cell \n",
    "    avg_activations = [dict() for x in range(256)]\n",
    "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
    "        for k, v in neuron.items():\n",
    "            # v is the list of activations for hidden layer's neuron k \n",
    "            avg_activations[i][k] = sum(v) / float(len(v))\n",
    "\n",
    "    # generate 256 lists to get only values in avg_activations\n",
    "    only_activation_vals = [list() for x in range(256)]\n",
    "\n",
    "    # get only values from avg_activations\n",
    "    for i, avg_activation in enumerate(avg_activations):\n",
    "        for value in avg_activation.values():\n",
    "            only_activation_vals[i].append(value)\n",
    "\n",
    "\n",
    "    for activation_val in only_activation_vals:\n",
    "        # find u_max \n",
    "        u_max = np.max(activation_val)\n",
    "\n",
    "        # find u_minus_max \n",
    "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
    "\n",
    "        # find selectivity \n",
    "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
    "\n",
    "        # append selectivity value to selectivity\n",
    "        __selectivity__.append(selectivity)\n",
    "\n",
    "    avg_selectivity = np.average(__selectivity__)\n",
    "    std_selectivity = np.std(__selectivity__)\n",
    "                                 \n",
    "    return avg_selectivity, std_selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXOpwTXEQFKY"
   },
   "outputs": [],
   "source": [
    "no_epochs = 100\n",
    "def selectivity_trainer(optimizer, model):\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    train_loss = list()\n",
    "    test_loss  = list()\n",
    "    test_acc   = list()\n",
    "    \n",
    "    final_selectivity_avg_list = list()\n",
    "    final_selectivity_std_list = list()\n",
    "\n",
    "    best_test_loss = 1\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "\n",
    "        _hidden_layer_each_neuron_ = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
    "        _hidden_layer_each_neuron_ = np.array(_hidden_layer_each_neuron_)\n",
    "\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0\n",
    "\n",
    "        # training\n",
    "        # set up training mode \n",
    "        model.train()\n",
    "\n",
    "        for itr, (images, labels) in enumerate(train_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(images)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print/Append activation of the hidden layer \n",
    "            # print(model.layer_activations.shape)\n",
    "            # model.layer_activations\n",
    "\n",
    "        total_train_loss = total_train_loss / (itr + 1)\n",
    "        train_loss.append(total_train_loss)\n",
    "\n",
    "        # testing \n",
    "        # change to evaluation mode \n",
    "        model.eval()\n",
    "        total = 0\n",
    "        for itr, (images, labels) in enumerate(test_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            pred = model(images)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # we now need softmax because we are testing.\n",
    "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "            for i, p in enumerate(pred):\n",
    "                if labels[i] == torch.max(p.data, 0)[1]:\n",
    "                    total = total + 1\n",
    "\n",
    "            \n",
    "            for activation, label in zip(model.layer_activations, labels):\n",
    "                # shape of activation and label: 256 and 1 \n",
    "                \n",
    "                # get the actual value of item. This is because label is now Tensor \n",
    "                label = label.item()\n",
    "\n",
    "                # this is not part of gradient calculcation \n",
    "                with torch.no_grad():\n",
    "                    activation = activation.numpy()\n",
    "\n",
    "                # for each image/label, append activation value of neuron \n",
    "                for i in range(256):    # number of neurons in hidden layer \n",
    "                    _hidden_layer_each_neuron_[i][label].append(activation[i])\n",
    "\n",
    "        avg_selectivity, std_selectivity = selectivity(_hidden_layer_each_neuron_)\n",
    "        \n",
    "        final_selectivity_avg_list.append(avg_selectivity)\n",
    "        final_selectivity_std_list.append(std_selectivity)\n",
    "\n",
    "        # caculate accuracy \n",
    "        accuracy = total / len(mnist_testset)\n",
    "\n",
    "        # append accuracy here\n",
    "        test_acc.append(accuracy)\n",
    "\n",
    "        # append test loss here \n",
    "        total_test_loss = total_test_loss / (itr + 1)\n",
    "        test_loss.append(total_test_loss)\n",
    "\n",
    "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
    "\n",
    "        # if total_test_loss < best_test_loss:\n",
    "        #     best_test_loss = total_test_loss\n",
    "        #     print(\"Saving the model state dictionary for Epoch: {} with Test loss: {:.8f}\".format(epoch + 1, total_test_loss))\n",
    "        #     torch.save(model.state_dict(), \"model.dth\")\n",
    "    return test_acc, final_selectivity_avg_list, final_selectivity_std_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WKq9qSgMADr"
   },
   "source": [
    "# AdaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4WytqcJRZxA"
   },
   "outputs": [],
   "source": [
    "# model_Adadelta = Model()\n",
    "# print(\"model_Adadelta:\", model_Adadelta)\n",
    "# model_Adadelta.to(device)\n",
    "# model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
    "# optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
    "# Adadelta_test_acc, Adadelta_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
    "\n",
    "# f = open(\"not_sorted_selectivity_Adadelta.txt\", \"a\")\n",
    "# f.write(str(0)+'\\n'+str(Adadelta_test_acc)+'\\n'+str(np.average(Adadelta_selectivity_list))+'\\n'+str(np.std(Adadelta_selectivity_list))+'\\n\\n')\n",
    "# f.close()\n",
    "\n",
    "# !cp not_sorted_selectivity_Adadelta.txt /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hXfQe4vMDKB"
   },
   "source": [
    "# AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vb-4TPM5MGuE",
    "outputId": "d3a86ce2-05b7-408b-dad8-e9aad45a53bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_Adagrad: Model(\n",
      "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Epoch: 1/100, Train Loss: 0.25991212, Test Loss: 0.13518088, Test Accuracy: 0.95940000\n",
      "\n",
      "Epoch: 2/100, Train Loss: 0.10772082, Test Loss: 0.10730438, Test Accuracy: 0.96670000\n",
      "\n",
      "Epoch: 3/100, Train Loss: 0.07730075, Test Loss: 0.09437794, Test Accuracy: 0.97170000\n",
      "\n",
      "Epoch: 4/100, Train Loss: 0.06004756, Test Loss: 0.08623242, Test Accuracy: 0.97310000\n",
      "\n",
      "Epoch: 5/100, Train Loss: 0.04821885, Test Loss: 0.08072426, Test Accuracy: 0.97450000\n",
      "\n",
      "Epoch: 6/100, Train Loss: 0.03976153, Test Loss: 0.07850647, Test Accuracy: 0.97590000\n",
      "\n",
      "Epoch: 7/100, Train Loss: 0.03311729, Test Loss: 0.07610964, Test Accuracy: 0.97600000\n",
      "\n",
      "Epoch: 8/100, Train Loss: 0.02807933, Test Loss: 0.07284206, Test Accuracy: 0.97700000\n",
      "\n",
      "Epoch: 9/100, Train Loss: 0.02394365, Test Loss: 0.07120005, Test Accuracy: 0.97760000\n",
      "\n",
      "Epoch: 10/100, Train Loss: 0.02048800, Test Loss: 0.06949534, Test Accuracy: 0.97770000\n",
      "\n",
      "Epoch: 11/100, Train Loss: 0.01788564, Test Loss: 0.06949797, Test Accuracy: 0.97830000\n",
      "\n",
      "Epoch: 12/100, Train Loss: 0.01572675, Test Loss: 0.07080617, Test Accuracy: 0.97840000\n",
      "\n",
      "Epoch: 13/100, Train Loss: 0.01386326, Test Loss: 0.06908261, Test Accuracy: 0.97870000\n",
      "\n",
      "Epoch: 14/100, Train Loss: 0.01213107, Test Loss: 0.06871218, Test Accuracy: 0.97860000\n",
      "\n",
      "Epoch: 15/100, Train Loss: 0.01086478, Test Loss: 0.06913372, Test Accuracy: 0.97840000\n",
      "\n",
      "Epoch: 16/100, Train Loss: 0.00975914, Test Loss: 0.06876140, Test Accuracy: 0.97830000\n",
      "\n",
      "Epoch: 17/100, Train Loss: 0.00879150, Test Loss: 0.06823755, Test Accuracy: 0.97810000\n",
      "\n",
      "Epoch: 18/100, Train Loss: 0.00792174, Test Loss: 0.06880270, Test Accuracy: 0.97840000\n",
      "\n",
      "Epoch: 19/100, Train Loss: 0.00722151, Test Loss: 0.06920910, Test Accuracy: 0.97850000\n",
      "\n",
      "Epoch: 20/100, Train Loss: 0.00656302, Test Loss: 0.06771094, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 21/100, Train Loss: 0.00605669, Test Loss: 0.06884877, Test Accuracy: 0.97890000\n",
      "\n",
      "Epoch: 22/100, Train Loss: 0.00557988, Test Loss: 0.06822984, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 23/100, Train Loss: 0.00515051, Test Loss: 0.06941052, Test Accuracy: 0.97860000\n",
      "\n",
      "Epoch: 24/100, Train Loss: 0.00479494, Test Loss: 0.06905907, Test Accuracy: 0.97880000\n",
      "\n",
      "Epoch: 25/100, Train Loss: 0.00447520, Test Loss: 0.06893124, Test Accuracy: 0.97890000\n",
      "\n",
      "Epoch: 26/100, Train Loss: 0.00417597, Test Loss: 0.06928553, Test Accuracy: 0.97840000\n",
      "\n",
      "Epoch: 27/100, Train Loss: 0.00393235, Test Loss: 0.06882239, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 28/100, Train Loss: 0.00367781, Test Loss: 0.06926425, Test Accuracy: 0.97890000\n",
      "\n",
      "Epoch: 29/100, Train Loss: 0.00345856, Test Loss: 0.06949939, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 30/100, Train Loss: 0.00328343, Test Loss: 0.06956773, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 31/100, Train Loss: 0.00309110, Test Loss: 0.07012851, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 32/100, Train Loss: 0.00294115, Test Loss: 0.06972354, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 33/100, Train Loss: 0.00278938, Test Loss: 0.06988461, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 34/100, Train Loss: 0.00266083, Test Loss: 0.07007884, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 35/100, Train Loss: 0.00253293, Test Loss: 0.07028523, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 36/100, Train Loss: 0.00240633, Test Loss: 0.07016433, Test Accuracy: 0.97890000\n",
      "\n",
      "Epoch: 37/100, Train Loss: 0.00230189, Test Loss: 0.07091544, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 38/100, Train Loss: 0.00220037, Test Loss: 0.07037710, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 39/100, Train Loss: 0.00210983, Test Loss: 0.07061377, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 40/100, Train Loss: 0.00202270, Test Loss: 0.07074198, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 41/100, Train Loss: 0.00194012, Test Loss: 0.07038092, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 42/100, Train Loss: 0.00186594, Test Loss: 0.07063373, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 43/100, Train Loss: 0.00179969, Test Loss: 0.07095188, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 44/100, Train Loss: 0.00173294, Test Loss: 0.07103089, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 45/100, Train Loss: 0.00167516, Test Loss: 0.07136050, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 46/100, Train Loss: 0.00161668, Test Loss: 0.07127537, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 47/100, Train Loss: 0.00156568, Test Loss: 0.07172138, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 48/100, Train Loss: 0.00151332, Test Loss: 0.07168891, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 49/100, Train Loss: 0.00146573, Test Loss: 0.07168499, Test Accuracy: 0.97910000\n",
      "\n",
      "Epoch: 50/100, Train Loss: 0.00141894, Test Loss: 0.07159850, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 51/100, Train Loss: 0.00137535, Test Loss: 0.07179178, Test Accuracy: 0.97910000\n",
      "\n",
      "Epoch: 52/100, Train Loss: 0.00133554, Test Loss: 0.07182154, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 53/100, Train Loss: 0.00129652, Test Loss: 0.07226441, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 54/100, Train Loss: 0.00125541, Test Loss: 0.07219685, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 55/100, Train Loss: 0.00121805, Test Loss: 0.07212857, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 56/100, Train Loss: 0.00117894, Test Loss: 0.07272433, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 57/100, Train Loss: 0.00114402, Test Loss: 0.07242898, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 58/100, Train Loss: 0.00111094, Test Loss: 0.07286164, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 59/100, Train Loss: 0.00108170, Test Loss: 0.07292940, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 60/100, Train Loss: 0.00105140, Test Loss: 0.07264235, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 61/100, Train Loss: 0.00102534, Test Loss: 0.07282099, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 62/100, Train Loss: 0.00099660, Test Loss: 0.07294887, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 63/100, Train Loss: 0.00097173, Test Loss: 0.07333168, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 64/100, Train Loss: 0.00094510, Test Loss: 0.07348701, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 65/100, Train Loss: 0.00092200, Test Loss: 0.07347081, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 66/100, Train Loss: 0.00089943, Test Loss: 0.07329201, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 67/100, Train Loss: 0.00087784, Test Loss: 0.07368729, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 68/100, Train Loss: 0.00085764, Test Loss: 0.07331770, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 69/100, Train Loss: 0.00083757, Test Loss: 0.07352593, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 70/100, Train Loss: 0.00081911, Test Loss: 0.07382968, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 71/100, Train Loss: 0.00080107, Test Loss: 0.07355839, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 72/100, Train Loss: 0.00078470, Test Loss: 0.07392995, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 73/100, Train Loss: 0.00076849, Test Loss: 0.07404079, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 74/100, Train Loss: 0.00075052, Test Loss: 0.07383818, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 75/100, Train Loss: 0.00073666, Test Loss: 0.07413360, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 76/100, Train Loss: 0.00072169, Test Loss: 0.07388982, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 77/100, Train Loss: 0.00070782, Test Loss: 0.07407606, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 78/100, Train Loss: 0.00069362, Test Loss: 0.07417842, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 79/100, Train Loss: 0.00068110, Test Loss: 0.07416843, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 80/100, Train Loss: 0.00066859, Test Loss: 0.07446482, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 81/100, Train Loss: 0.00065600, Test Loss: 0.07408740, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 82/100, Train Loss: 0.00064474, Test Loss: 0.07427760, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 83/100, Train Loss: 0.00063253, Test Loss: 0.07431365, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 84/100, Train Loss: 0.00062251, Test Loss: 0.07431236, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 85/100, Train Loss: 0.00061130, Test Loss: 0.07476259, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 86/100, Train Loss: 0.00059982, Test Loss: 0.07458504, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 87/100, Train Loss: 0.00059024, Test Loss: 0.07480253, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 88/100, Train Loss: 0.00058129, Test Loss: 0.07475651, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 89/100, Train Loss: 0.00057155, Test Loss: 0.07481845, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 90/100, Train Loss: 0.00056228, Test Loss: 0.07496297, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 91/100, Train Loss: 0.00055335, Test Loss: 0.07504579, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 92/100, Train Loss: 0.00054436, Test Loss: 0.07471257, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 93/100, Train Loss: 0.00053603, Test Loss: 0.07528328, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 94/100, Train Loss: 0.00052736, Test Loss: 0.07507313, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 95/100, Train Loss: 0.00052011, Test Loss: 0.07495995, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 96/100, Train Loss: 0.00051265, Test Loss: 0.07527985, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 97/100, Train Loss: 0.00050459, Test Loss: 0.07551497, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 98/100, Train Loss: 0.00049768, Test Loss: 0.07549823, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 99/100, Train Loss: 0.00049033, Test Loss: 0.07549127, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 100/100, Train Loss: 0.00048331, Test Loss: 0.07562007, Test Accuracy: 0.97950000\n"
     ]
    }
   ],
   "source": [
    "model_Adagrad = Model()\n",
    "print(\"model_Adagrad:\", model_Adagrad)\n",
    "model_Adagrad.to(device)\n",
    "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
    "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
    "Adagrad_test_acc, Adagrad_avg_selectivity_list, Adagrad_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
    "\n",
    "f = open(\"not_sorted_selectivity_Adagrad.txt\", \"w\")\n",
    "f.write(str(0)+'\\n'+str(Adagrad_test_acc)+'\\n'+str(Adagrad_avg_selectivity_list)+'\\n'+str(Adagrad_std_selectivity_list)+'\\n\\n')\n",
    "f.close()\n",
    "\n",
    "!cp not_sorted_selectivity_Adagrad.txt /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmLJ4Zr2MnoS"
   },
   "source": [
    "# SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ObsEJHuMoPy",
    "outputId": "1767914a-d812-4bf1-f57d-cda35ca46bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_SGD: Model(\n",
      "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Epoch: 1/100, Train Loss: 0.77304522, Test Loss: 0.36418165, Test Accuracy: 0.89840000\n",
      "\n",
      "Epoch: 2/100, Train Loss: 0.34704096, Test Loss: 0.30548018, Test Accuracy: 0.91170000\n",
      "\n",
      "Epoch: 3/100, Train Loss: 0.30649352, Test Loss: 0.28101154, Test Accuracy: 0.92020000\n",
      "\n",
      "Epoch: 4/100, Train Loss: 0.28406920, Test Loss: 0.26883305, Test Accuracy: 0.92400000\n",
      "\n",
      "Epoch: 5/100, Train Loss: 0.26625526, Test Loss: 0.24813460, Test Accuracy: 0.92940000\n",
      "\n",
      "Epoch: 6/100, Train Loss: 0.24977460, Test Loss: 0.23419707, Test Accuracy: 0.93340000\n",
      "\n",
      "Epoch: 7/100, Train Loss: 0.23342673, Test Loss: 0.22418329, Test Accuracy: 0.93350000\n",
      "\n",
      "Epoch: 8/100, Train Loss: 0.21817594, Test Loss: 0.20744120, Test Accuracy: 0.93990000\n",
      "\n",
      "Epoch: 9/100, Train Loss: 0.20454982, Test Loss: 0.19622140, Test Accuracy: 0.94370000\n",
      "\n",
      "Epoch: 10/100, Train Loss: 0.19181236, Test Loss: 0.18651966, Test Accuracy: 0.94760000\n",
      "\n",
      "Epoch: 11/100, Train Loss: 0.18054359, Test Loss: 0.17965582, Test Accuracy: 0.94730000\n",
      "\n",
      "Epoch: 12/100, Train Loss: 0.17007053, Test Loss: 0.16727231, Test Accuracy: 0.95130000\n",
      "\n",
      "Epoch: 13/100, Train Loss: 0.16077745, Test Loss: 0.15874475, Test Accuracy: 0.95400000\n",
      "\n",
      "Epoch: 14/100, Train Loss: 0.15188780, Test Loss: 0.15048181, Test Accuracy: 0.95630000\n",
      "\n",
      "Epoch: 15/100, Train Loss: 0.14445284, Test Loss: 0.14408200, Test Accuracy: 0.95870000\n",
      "\n",
      "Epoch: 16/100, Train Loss: 0.13728132, Test Loss: 0.14104152, Test Accuracy: 0.95760000\n",
      "\n",
      "Epoch: 17/100, Train Loss: 0.13080234, Test Loss: 0.13486424, Test Accuracy: 0.96100000\n",
      "\n",
      "Epoch: 18/100, Train Loss: 0.12485028, Test Loss: 0.13031152, Test Accuracy: 0.96220000\n",
      "\n",
      "Epoch: 19/100, Train Loss: 0.11911650, Test Loss: 0.12658506, Test Accuracy: 0.96240000\n",
      "\n",
      "Epoch: 20/100, Train Loss: 0.11398865, Test Loss: 0.12292395, Test Accuracy: 0.96340000\n",
      "\n",
      "Epoch: 21/100, Train Loss: 0.10956008, Test Loss: 0.11904879, Test Accuracy: 0.96560000\n",
      "\n",
      "Epoch: 22/100, Train Loss: 0.10465137, Test Loss: 0.11557978, Test Accuracy: 0.96580000\n",
      "\n",
      "Epoch: 23/100, Train Loss: 0.10070475, Test Loss: 0.11492618, Test Accuracy: 0.96760000\n",
      "\n",
      "Epoch: 24/100, Train Loss: 0.09703324, Test Loss: 0.10846605, Test Accuracy: 0.96870000\n",
      "\n",
      "Epoch: 25/100, Train Loss: 0.09349081, Test Loss: 0.10442900, Test Accuracy: 0.96800000\n",
      "\n",
      "Epoch: 26/100, Train Loss: 0.09002743, Test Loss: 0.10280091, Test Accuracy: 0.96910000\n",
      "\n",
      "Epoch: 27/100, Train Loss: 0.08680643, Test Loss: 0.10278310, Test Accuracy: 0.96920000\n",
      "\n",
      "Epoch: 28/100, Train Loss: 0.08358246, Test Loss: 0.09832759, Test Accuracy: 0.97070000\n",
      "\n",
      "Epoch: 29/100, Train Loss: 0.08120762, Test Loss: 0.09648867, Test Accuracy: 0.97090000\n",
      "\n",
      "Epoch: 30/100, Train Loss: 0.07837218, Test Loss: 0.09562739, Test Accuracy: 0.97160000\n",
      "\n",
      "Epoch: 31/100, Train Loss: 0.07582563, Test Loss: 0.09283365, Test Accuracy: 0.97120000\n",
      "\n",
      "Epoch: 32/100, Train Loss: 0.07340684, Test Loss: 0.09124078, Test Accuracy: 0.97320000\n",
      "\n",
      "Epoch: 33/100, Train Loss: 0.07132771, Test Loss: 0.09046772, Test Accuracy: 0.97240000\n",
      "\n",
      "Epoch: 34/100, Train Loss: 0.06905778, Test Loss: 0.08888305, Test Accuracy: 0.97350000\n",
      "\n",
      "Epoch: 35/100, Train Loss: 0.06703843, Test Loss: 0.08832805, Test Accuracy: 0.97420000\n",
      "\n",
      "Epoch: 36/100, Train Loss: 0.06506515, Test Loss: 0.08705467, Test Accuracy: 0.97290000\n",
      "\n",
      "Epoch: 37/100, Train Loss: 0.06330964, Test Loss: 0.08516533, Test Accuracy: 0.97460000\n",
      "\n",
      "Epoch: 38/100, Train Loss: 0.06138358, Test Loss: 0.08330021, Test Accuracy: 0.97450000\n",
      "\n",
      "Epoch: 39/100, Train Loss: 0.05974144, Test Loss: 0.08219658, Test Accuracy: 0.97520000\n",
      "\n",
      "Epoch: 40/100, Train Loss: 0.05814002, Test Loss: 0.08115716, Test Accuracy: 0.97540000\n",
      "\n",
      "Epoch: 41/100, Train Loss: 0.05657985, Test Loss: 0.08136533, Test Accuracy: 0.97510000\n",
      "\n",
      "Epoch: 42/100, Train Loss: 0.05502984, Test Loss: 0.07997686, Test Accuracy: 0.97520000\n",
      "\n",
      "Epoch: 43/100, Train Loss: 0.05355263, Test Loss: 0.07871224, Test Accuracy: 0.97610000\n",
      "\n",
      "Epoch: 44/100, Train Loss: 0.05221533, Test Loss: 0.07823853, Test Accuracy: 0.97580000\n",
      "\n",
      "Epoch: 45/100, Train Loss: 0.05073021, Test Loss: 0.07688875, Test Accuracy: 0.97610000\n",
      "\n",
      "Epoch: 46/100, Train Loss: 0.04940798, Test Loss: 0.07788710, Test Accuracy: 0.97640000\n",
      "\n",
      "Epoch: 47/100, Train Loss: 0.04829604, Test Loss: 0.07688785, Test Accuracy: 0.97600000\n",
      "\n",
      "Epoch: 48/100, Train Loss: 0.04710609, Test Loss: 0.07609456, Test Accuracy: 0.97710000\n",
      "\n",
      "Epoch: 49/100, Train Loss: 0.04587262, Test Loss: 0.07637403, Test Accuracy: 0.97670000\n",
      "\n",
      "Epoch: 50/100, Train Loss: 0.04481555, Test Loss: 0.07516327, Test Accuracy: 0.97660000\n",
      "\n",
      "Epoch: 51/100, Train Loss: 0.04362564, Test Loss: 0.07653908, Test Accuracy: 0.97670000\n",
      "\n",
      "Epoch: 52/100, Train Loss: 0.04260830, Test Loss: 0.07538897, Test Accuracy: 0.97640000\n",
      "\n",
      "Epoch: 53/100, Train Loss: 0.04168103, Test Loss: 0.07384931, Test Accuracy: 0.97700000\n",
      "\n",
      "Epoch: 54/100, Train Loss: 0.04058628, Test Loss: 0.07371967, Test Accuracy: 0.97730000\n",
      "\n",
      "Epoch: 55/100, Train Loss: 0.03974894, Test Loss: 0.07188791, Test Accuracy: 0.97760000\n",
      "\n",
      "Epoch: 56/100, Train Loss: 0.03878604, Test Loss: 0.07203482, Test Accuracy: 0.97780000\n",
      "\n",
      "Epoch: 57/100, Train Loss: 0.03791949, Test Loss: 0.07143374, Test Accuracy: 0.97770000\n",
      "\n",
      "Epoch: 58/100, Train Loss: 0.03706348, Test Loss: 0.07047056, Test Accuracy: 0.97760000\n",
      "\n",
      "Epoch: 59/100, Train Loss: 0.03609778, Test Loss: 0.07135153, Test Accuracy: 0.97790000\n",
      "\n",
      "Epoch: 60/100, Train Loss: 0.03529019, Test Loss: 0.07022137, Test Accuracy: 0.97760000\n",
      "\n",
      "Epoch: 61/100, Train Loss: 0.03451809, Test Loss: 0.06927896, Test Accuracy: 0.97910000\n",
      "\n",
      "Epoch: 62/100, Train Loss: 0.03375712, Test Loss: 0.06907573, Test Accuracy: 0.97860000\n",
      "\n",
      "Epoch: 63/100, Train Loss: 0.03289079, Test Loss: 0.06899347, Test Accuracy: 0.97840000\n",
      "\n",
      "Epoch: 64/100, Train Loss: 0.03231409, Test Loss: 0.06921707, Test Accuracy: 0.97790000\n",
      "\n",
      "Epoch: 65/100, Train Loss: 0.03152403, Test Loss: 0.06904746, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 66/100, Train Loss: 0.03080801, Test Loss: 0.06896618, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 67/100, Train Loss: 0.03015933, Test Loss: 0.06857450, Test Accuracy: 0.97850000\n",
      "\n",
      "Epoch: 68/100, Train Loss: 0.02949472, Test Loss: 0.06820077, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 69/100, Train Loss: 0.02884499, Test Loss: 0.06706784, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 70/100, Train Loss: 0.02822457, Test Loss: 0.06712038, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 71/100, Train Loss: 0.02767502, Test Loss: 0.06901035, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 72/100, Train Loss: 0.02705174, Test Loss: 0.06650616, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 73/100, Train Loss: 0.02643980, Test Loss: 0.06585230, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 74/100, Train Loss: 0.02599506, Test Loss: 0.06725993, Test Accuracy: 0.97890000\n",
      "\n",
      "Epoch: 75/100, Train Loss: 0.02531535, Test Loss: 0.06666286, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 76/100, Train Loss: 0.02486254, Test Loss: 0.06629881, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 77/100, Train Loss: 0.02435332, Test Loss: 0.06554061, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 78/100, Train Loss: 0.02379368, Test Loss: 0.06729083, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 79/100, Train Loss: 0.02338318, Test Loss: 0.06559799, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 80/100, Train Loss: 0.02286411, Test Loss: 0.06548337, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 81/100, Train Loss: 0.02243061, Test Loss: 0.06531846, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 82/100, Train Loss: 0.02203697, Test Loss: 0.06529911, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 83/100, Train Loss: 0.02155416, Test Loss: 0.06580144, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 84/100, Train Loss: 0.02113121, Test Loss: 0.06493808, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 85/100, Train Loss: 0.02069419, Test Loss: 0.06483268, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 86/100, Train Loss: 0.02026956, Test Loss: 0.06471731, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 87/100, Train Loss: 0.01992800, Test Loss: 0.06456490, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 88/100, Train Loss: 0.01945995, Test Loss: 0.06522241, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 89/100, Train Loss: 0.01912454, Test Loss: 0.06413910, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 90/100, Train Loss: 0.01873283, Test Loss: 0.06489888, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 91/100, Train Loss: 0.01840309, Test Loss: 0.06517314, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 92/100, Train Loss: 0.01802704, Test Loss: 0.06460208, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 93/100, Train Loss: 0.01776864, Test Loss: 0.06421083, Test Accuracy: 0.98030000\n",
      "\n",
      "Epoch: 94/100, Train Loss: 0.01731340, Test Loss: 0.06406031, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 95/100, Train Loss: 0.01712266, Test Loss: 0.06435844, Test Accuracy: 0.98070000\n",
      "\n",
      "Epoch: 96/100, Train Loss: 0.01673393, Test Loss: 0.06437269, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 97/100, Train Loss: 0.01646551, Test Loss: 0.06411162, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 98/100, Train Loss: 0.01620960, Test Loss: 0.06359143, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 99/100, Train Loss: 0.01583798, Test Loss: 0.06441634, Test Accuracy: 0.98030000\n",
      "\n",
      "Epoch: 100/100, Train Loss: 0.01559136, Test Loss: 0.06406923, Test Accuracy: 0.98020000\n"
     ]
    }
   ],
   "source": [
    "model_SGD = Model()\n",
    "print(\"model_SGD:\", model_SGD)\n",
    "model_SGD.to(device)\n",
    "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
    "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
    "SGD_test_acc, SGD_avg_selectivity_list, SGD_std_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
    "\n",
    "f = open(\"not_sorted_selectivity_SGD.txt\", \"w\")\n",
    "f.write(str(0)+'\\n'+str(SGD_test_acc)+'\\n'+str(SGD_avg_selectivity_list)+'\\n'+str(SGD_std_selectivity_list)+'\\n\\n')\n",
    "f.close()\n",
    "\n",
    "!cp not_sorted_selectivity_SGD.txt /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvQxaN_fRXLq"
   },
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkqfFoVkRXxP",
    "outputId": "f7c742fb-2abc-42e8-84b5-16319f78b332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_Adam: Model(\n",
      "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "Epoch: 1/100, Train Loss: 0.43107659, Test Loss: 0.22976869, Test Accuracy: 0.93250000\n",
      "\n",
      "Epoch: 2/100, Train Loss: 0.19925471, Test Loss: 0.16393335, Test Accuracy: 0.95310000\n",
      "\n",
      "Epoch: 3/100, Train Loss: 0.14473584, Test Loss: 0.12926079, Test Accuracy: 0.96040000\n",
      "\n",
      "Epoch: 4/100, Train Loss: 0.11039049, Test Loss: 0.10603982, Test Accuracy: 0.96750000\n",
      "\n",
      "Epoch: 5/100, Train Loss: 0.08714783, Test Loss: 0.09090163, Test Accuracy: 0.97170000\n",
      "\n",
      "Epoch: 6/100, Train Loss: 0.07017244, Test Loss: 0.08507129, Test Accuracy: 0.97350000\n",
      "\n",
      "Epoch: 7/100, Train Loss: 0.05659168, Test Loss: 0.07701848, Test Accuracy: 0.97720000\n",
      "\n",
      "Epoch: 8/100, Train Loss: 0.04584417, Test Loss: 0.07639988, Test Accuracy: 0.97590000\n",
      "\n",
      "Epoch: 9/100, Train Loss: 0.03741483, Test Loss: 0.07191781, Test Accuracy: 0.97810000\n",
      "\n",
      "Epoch: 10/100, Train Loss: 0.03062514, Test Loss: 0.06715800, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 11/100, Train Loss: 0.02542774, Test Loss: 0.06646954, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 12/100, Train Loss: 0.02028703, Test Loss: 0.06694840, Test Accuracy: 0.97940000\n",
      "\n",
      "Epoch: 13/100, Train Loss: 0.01624218, Test Loss: 0.06324425, Test Accuracy: 0.98220000\n",
      "\n",
      "Epoch: 14/100, Train Loss: 0.01319193, Test Loss: 0.06615228, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 15/100, Train Loss: 0.01090292, Test Loss: 0.06475997, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 16/100, Train Loss: 0.00837825, Test Loss: 0.06627818, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 17/100, Train Loss: 0.00696289, Test Loss: 0.06714617, Test Accuracy: 0.98090000\n",
      "\n",
      "Epoch: 18/100, Train Loss: 0.00518308, Test Loss: 0.07248326, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 19/100, Train Loss: 0.00458563, Test Loss: 0.07784819, Test Accuracy: 0.97890000\n",
      "\n",
      "Epoch: 20/100, Train Loss: 0.00370364, Test Loss: 0.07224785, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 21/100, Train Loss: 0.00271014, Test Loss: 0.06996878, Test Accuracy: 0.98140000\n",
      "\n",
      "Epoch: 22/100, Train Loss: 0.00218512, Test Loss: 0.07134290, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 23/100, Train Loss: 0.00213719, Test Loss: 0.07497441, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 24/100, Train Loss: 0.00141444, Test Loss: 0.07362121, Test Accuracy: 0.98100000\n",
      "\n",
      "Epoch: 25/100, Train Loss: 0.00103337, Test Loss: 0.07574759, Test Accuracy: 0.98150000\n",
      "\n",
      "Epoch: 26/100, Train Loss: 0.00159324, Test Loss: 0.07830260, Test Accuracy: 0.98070000\n",
      "\n",
      "Epoch: 27/100, Train Loss: 0.00079334, Test Loss: 0.07861339, Test Accuracy: 0.98060000\n",
      "\n",
      "Epoch: 28/100, Train Loss: 0.00092950, Test Loss: 0.08363148, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 29/100, Train Loss: 0.00061097, Test Loss: 0.07986297, Test Accuracy: 0.98090000\n",
      "\n",
      "Epoch: 30/100, Train Loss: 0.00046421, Test Loss: 0.10062413, Test Accuracy: 0.97750000\n",
      "\n",
      "Epoch: 31/100, Train Loss: 0.00119715, Test Loss: 0.08052915, Test Accuracy: 0.98190000\n",
      "\n",
      "Epoch: 32/100, Train Loss: 0.00021615, Test Loss: 0.08005297, Test Accuracy: 0.98230000\n",
      "\n",
      "Epoch: 33/100, Train Loss: 0.00018052, Test Loss: 0.08448353, Test Accuracy: 0.98120000\n",
      "\n",
      "Epoch: 34/100, Train Loss: 0.00016945, Test Loss: 0.08240576, Test Accuracy: 0.98120000\n",
      "\n",
      "Epoch: 35/100, Train Loss: 0.00125739, Test Loss: 0.08976206, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 36/100, Train Loss: 0.00055697, Test Loss: 0.08583010, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 37/100, Train Loss: 0.00011232, Test Loss: 0.08574918, Test Accuracy: 0.98080000\n",
      "\n",
      "Epoch: 38/100, Train Loss: 0.00008736, Test Loss: 0.08606742, Test Accuracy: 0.98100000\n",
      "\n",
      "Epoch: 39/100, Train Loss: 0.00007706, Test Loss: 0.08699867, Test Accuracy: 0.98070000\n",
      "\n",
      "Epoch: 40/100, Train Loss: 0.00006534, Test Loss: 0.09055047, Test Accuracy: 0.98100000\n",
      "\n",
      "Epoch: 41/100, Train Loss: 0.00120935, Test Loss: 0.09124434, Test Accuracy: 0.98180000\n",
      "\n",
      "Epoch: 42/100, Train Loss: 0.00011382, Test Loss: 0.09002588, Test Accuracy: 0.98170000\n",
      "\n",
      "Epoch: 43/100, Train Loss: 0.00005951, Test Loss: 0.09202634, Test Accuracy: 0.98100000\n",
      "\n",
      "Epoch: 44/100, Train Loss: 0.00004588, Test Loss: 0.09250587, Test Accuracy: 0.98110000\n",
      "\n",
      "Epoch: 45/100, Train Loss: 0.00003870, Test Loss: 0.09471079, Test Accuracy: 0.98050000\n",
      "\n",
      "Epoch: 46/100, Train Loss: 0.00003441, Test Loss: 0.09715460, Test Accuracy: 0.98060000\n",
      "\n",
      "Epoch: 47/100, Train Loss: 0.00166227, Test Loss: 0.10193565, Test Accuracy: 0.98060000\n",
      "\n",
      "Epoch: 48/100, Train Loss: 0.00009172, Test Loss: 0.09858884, Test Accuracy: 0.98070000\n",
      "\n",
      "Epoch: 49/100, Train Loss: 0.00004698, Test Loss: 0.09930062, Test Accuracy: 0.98080000\n",
      "\n",
      "Epoch: 50/100, Train Loss: 0.00003581, Test Loss: 0.09942393, Test Accuracy: 0.98060000\n",
      "\n",
      "Epoch: 51/100, Train Loss: 0.00002861, Test Loss: 0.10005366, Test Accuracy: 0.98040000\n",
      "\n",
      "Epoch: 52/100, Train Loss: 0.00002340, Test Loss: 0.10077310, Test Accuracy: 0.98070000\n",
      "\n",
      "Epoch: 53/100, Train Loss: 0.00002007, Test Loss: 0.10322671, Test Accuracy: 0.98050000\n",
      "\n",
      "Epoch: 54/100, Train Loss: 0.00130021, Test Loss: 0.11886340, Test Accuracy: 0.97810000\n",
      "\n",
      "Epoch: 55/100, Train Loss: 0.00038222, Test Loss: 0.10421769, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 56/100, Train Loss: 0.00004788, Test Loss: 0.10253059, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 57/100, Train Loss: 0.00002916, Test Loss: 0.10301790, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 58/100, Train Loss: 0.00002170, Test Loss: 0.10301694, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 59/100, Train Loss: 0.00001732, Test Loss: 0.10308848, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 60/100, Train Loss: 0.00001404, Test Loss: 0.10444098, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 61/100, Train Loss: 0.00001148, Test Loss: 0.10551353, Test Accuracy: 0.98070000\n",
      "\n",
      "Epoch: 62/100, Train Loss: 0.00035250, Test Loss: 0.17086084, Test Accuracy: 0.97200000\n",
      "\n",
      "Epoch: 63/100, Train Loss: 0.00118201, Test Loss: 0.11484244, Test Accuracy: 0.97860000\n",
      "\n",
      "Epoch: 64/100, Train Loss: 0.00004665, Test Loss: 0.10979080, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 65/100, Train Loss: 0.00002058, Test Loss: 0.10878172, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 66/100, Train Loss: 0.00001528, Test Loss: 0.10809496, Test Accuracy: 0.98050000\n",
      "\n",
      "Epoch: 67/100, Train Loss: 0.00001190, Test Loss: 0.10817285, Test Accuracy: 0.98040000\n",
      "\n",
      "Epoch: 68/100, Train Loss: 0.00000955, Test Loss: 0.10870460, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 69/100, Train Loss: 0.00000775, Test Loss: 0.10853405, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 70/100, Train Loss: 0.00000644, Test Loss: 0.10961923, Test Accuracy: 0.98090000\n",
      "\n",
      "Epoch: 71/100, Train Loss: 0.00009198, Test Loss: 0.13297067, Test Accuracy: 0.97800000\n",
      "\n",
      "Epoch: 72/100, Train Loss: 0.00136661, Test Loss: 0.11720489, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 73/100, Train Loss: 0.00002916, Test Loss: 0.11205891, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 74/100, Train Loss: 0.00001445, Test Loss: 0.11192006, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 75/100, Train Loss: 0.00001040, Test Loss: 0.11183113, Test Accuracy: 0.97960000\n",
      "\n",
      "Epoch: 76/100, Train Loss: 0.00000775, Test Loss: 0.11181636, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 77/100, Train Loss: 0.00000599, Test Loss: 0.11301589, Test Accuracy: 0.97970000\n",
      "\n",
      "Epoch: 78/100, Train Loss: 0.00000466, Test Loss: 0.11261178, Test Accuracy: 0.98000000\n",
      "\n",
      "Epoch: 79/100, Train Loss: 0.00000376, Test Loss: 0.11381540, Test Accuracy: 0.97920000\n",
      "\n",
      "Epoch: 80/100, Train Loss: 0.00000304, Test Loss: 0.11628671, Test Accuracy: 0.97980000\n",
      "\n",
      "Epoch: 81/100, Train Loss: 0.00000255, Test Loss: 0.11679827, Test Accuracy: 0.98040000\n",
      "\n",
      "Epoch: 82/100, Train Loss: 0.00000767, Test Loss: 0.12723028, Test Accuracy: 0.97860000\n",
      "\n",
      "Epoch: 83/100, Train Loss: 0.00112196, Test Loss: 0.12564958, Test Accuracy: 0.98010000\n",
      "\n",
      "Epoch: 84/100, Train Loss: 0.00003165, Test Loss: 0.12998324, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 85/100, Train Loss: 0.00001120, Test Loss: 0.12344562, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 86/100, Train Loss: 0.00000594, Test Loss: 0.12303723, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 87/100, Train Loss: 0.00000439, Test Loss: 0.12264948, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 88/100, Train Loss: 0.00000335, Test Loss: 0.12246187, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 89/100, Train Loss: 0.00000260, Test Loss: 0.12264592, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 90/100, Train Loss: 0.00000206, Test Loss: 0.12249227, Test Accuracy: 0.98020000\n",
      "\n",
      "Epoch: 91/100, Train Loss: 0.00000163, Test Loss: 0.12295615, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 92/100, Train Loss: 0.00000132, Test Loss: 0.12323132, Test Accuracy: 0.97990000\n",
      "\n",
      "Epoch: 93/100, Train Loss: 0.00000109, Test Loss: 0.12320963, Test Accuracy: 0.98100000\n",
      "\n",
      "Epoch: 94/100, Train Loss: 0.00085880, Test Loss: 0.15901357, Test Accuracy: 0.97580000\n",
      "\n",
      "Epoch: 95/100, Train Loss: 0.00027297, Test Loss: 0.13334575, Test Accuracy: 0.97910000\n",
      "\n",
      "Epoch: 96/100, Train Loss: 0.00006139, Test Loss: 0.13260757, Test Accuracy: 0.97900000\n",
      "\n",
      "Epoch: 97/100, Train Loss: 0.00000450, Test Loss: 0.13146959, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 98/100, Train Loss: 0.00000325, Test Loss: 0.13172996, Test Accuracy: 0.97930000\n",
      "\n",
      "Epoch: 99/100, Train Loss: 0.00000241, Test Loss: 0.13047977, Test Accuracy: 0.97950000\n",
      "\n",
      "Epoch: 100/100, Train Loss: 0.00000179, Test Loss: 0.13061550, Test Accuracy: 0.97920000\n"
     ]
    }
   ],
   "source": [
    "model_Adam = Model()\n",
    "print(\"model_Adam:\", model_Adam)\n",
    "model_Adam.to(device)\n",
    "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
    "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
    "Adam_test_acc, Adam_avg_selectivity_list, Adam_std_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
    "\n",
    "f = open(\"not_sorted_selectivity_Adam.txt\", \"w\")\n",
    "f.write(str(0)+'\\n'+str(Adam_test_acc)+'\\n'+str(Adam_avg_selectivity_list)+'\\n'+str(Adam_std_selectivity_list)+'\\n\\n')\n",
    "f.close()\n",
    "\n",
    "!cp not_sorted_selectivity_Adam.txt /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q90BXeqT11M4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "selectivity_not_sorted.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
