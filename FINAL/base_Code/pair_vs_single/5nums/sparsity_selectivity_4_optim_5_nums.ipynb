{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparsity_selectivity_4_optim_5_nums.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/sparsity_selectivity_4_optim_5_nums.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MU1dnFxiZMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e5e83d-4d4a-464f-b895-bb04872167ed"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGfGLr3Ejc3v",
        "outputId": "2d80b63a-db1e-4489-c0f0-ef4b973c7e42"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "root_dir = './'\n",
        "torchvision.datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-18 13:42:23--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-18 13:42:23--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [          <=>       ]  33.20M  6.51MB/s    in 5.8s    \n",
            "\n",
            "2021-03-18 13:42:30 (5.68 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZpOCWFxYgtO"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iJa_LOiivEN"
      },
      "source": [
        "mnist_trainset = torchvision.datasets.MNIST(root=root_dir, train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = torchvision.datasets.MNIST(root=root_dir, \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-pSE5X3i3l5"
      },
      "source": [
        "# class_inds 이거는 그냥 위에있는거를 list 로 만들어준 형태임 \n",
        "class_inds = [torch.where(mnist_trainset.targets == class_idx)[0]\n",
        "              for class_idx in mnist_trainset.class_to_idx.values()]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2bTkOMQj_3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3cd406-687b-45bc-c3dc-651e3fe38848"
      },
      "source": [
        "train_dataloaders = [\n",
        "                     DataLoader(dataset=Subset(mnist_trainset, inds),\n",
        "                                batch_size=10,\n",
        "                                shuffle=True,\n",
        "                                drop_last=False\n",
        "                     )\n",
        "                     for inds in class_inds\n",
        "]\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)\n",
        "\n",
        "print(\"Training dataset size: \", len(mnist_trainset))\n",
        "print(\"Testing dataset size: \",  len(mnist_testset))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size:  60000\n",
            "Testing dataset size:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSkAos_Jq7jP"
      },
      "source": [
        "# ************* modify this section for later use *************\n",
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        # modify this section for later use \n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid12  = torch.nn.Sigmoid()\n",
        "\n",
        "        self.layer_activations = dict()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # modify this section for later use \n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid12(x)\n",
        "        pred = self.linear_2(x)\n",
        "        return pred\n",
        "# ************* modify this section for later use *************"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6n-KajYdSw"
      },
      "source": [
        "def get_activation(model, layer_name):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations[layer_name] = output\n",
        "    return hook"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vLuXBwhjvgZ"
      },
      "source": [
        "def sparsity_calculator(final_spareness):\n",
        "    sparseness_list = list()\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "\n",
        "        hidden_layer_activation_list = single_epoch_spareness\n",
        "        hidden_layer_activation_list = torch.stack(hidden_layer_activation_list)\n",
        "        layer_activations_list = torch.reshape(hidden_layer_activation_list, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return sparseness_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf8JfDluYtay"
      },
      "source": [
        "def selectivity(hidden_layer_each_neuron):\n",
        "    __selectivity__ = list()\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(256)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 256 lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(256)]\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity\n",
        "        __selectivity__.append(selectivity)\n",
        "\n",
        "    avg_selectivity = np.average(__selectivity__)\n",
        "    std_selectivity = np.std(__selectivity__)\n",
        "                                 \n",
        "    return avg_selectivity, std_selectivity"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2uPxAlnYvY7"
      },
      "source": [
        "def model_factory(optimizer_name):\n",
        "    '''\n",
        "    optimizer_name : choose one of Adagrad, Adadelta, SGD, and Adam \n",
        "\n",
        "    '''\n",
        "    my_model = Model()\n",
        "    print(\"my_model:\", my_model)\n",
        "    my_model.to(device)\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    my_model.sigmoid12.register_forward_hook(get_activation(my_model, 's12'))\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    if optimizer_name == 'Adadelta':\n",
        "        my_optimizer = torch.optim.Adadelta(my_model.parameters(), lr=1.0)\n",
        "\n",
        "    elif optimizer_name == 'Adagrad':\n",
        "        my_optimizer = torch.optim.Adagrad(my_model.parameters(), lr=0.1)\n",
        "\n",
        "    elif optimizer_name == 'SGD':\n",
        "        my_optimizer = torch.optim.SGD(my_model.parameters(), lr=0.1)\n",
        "\n",
        "    elif optimizer_name == 'Adam':\n",
        "        my_optimizer = torch.optim.Adam(my_model.parameters(), lr=0.001)\n",
        "\n",
        "    else:\n",
        "        print(\"ERROR\")\n",
        "    \n",
        "    print(\"my_optimizer:\", my_optimizer)\n",
        "    test_acc, sparsity, selectivity_list_avg, selectivity_list_std = selectivity_trainer(optimizer=my_optimizer, model=my_model)\n",
        "    # ************* modify this section for later use *************\n",
        "    file_saver = open(f\"sparsity_selectivity_4_optim_5_nums_{optimizer_name}.txt\", \"w\")\n",
        "    # ************* modify this section for later use *************\n",
        "    file_saver.write(str(test_acc)+'\\n'+str(sparsity)+'\\n'+str(selectivity_list_avg)+'\\n'+str(selectivity_list_std)+'\\n\\n')\n",
        "    file_saver.close()\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    if optimizer_name == 'Adadelta':\n",
        "        !cp sparsity_selectivity_4_optim_5_nums_Adadelta.txt /content/drive/MyDrive\n",
        "    \n",
        "    elif optimizer_name == 'Adagrad':\n",
        "        !cp sparsity_selectivity_4_optim_5_nums_Adagrad.txt /content/drive/MyDrive\n",
        "\n",
        "    elif optimizer_name == 'SGD':\n",
        "        !cp sparsity_selectivity_4_optim_5_nums_SGD.txt /content/drive/MyDrive\n",
        "\n",
        "    elif optimizer_name == 'Adam':\n",
        "        !cp sparsity_selectivity_4_optim_5_nums_Adam.txt /content/drive/MyDrive\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    else:\n",
        "        print(\"ERROR\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LkuALwAYwgK"
      },
      "source": [
        "# ************* modify this section for later use *************\n",
        "def avg_std_calculator(_hidden_layer_each_neuron_12):\n",
        "\n",
        "    avg_selectivity12, std_selectivity12 = selectivity(_hidden_layer_each_neuron_12)\n",
        "\n",
        "    final_selectivity_avg = (avg_selectivity12) / 1\n",
        "    final_selecvitity_std = (std_selectivity12) / 1\n",
        "\n",
        "    return final_selectivity_avg, final_selecvitity_std\n",
        "# ************* modify this section for later use *************"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnD7OdVYlo7H"
      },
      "source": [
        "def selectivity_trainer(optimizer, model):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    no_epochs = 30\n",
        "    test_acc   = list()\n",
        "\n",
        "    selectivity_avg_list = list()\n",
        "    selectivity_std_list = list()\n",
        "\n",
        "    # ************* modify this section for later use *************\n",
        "    final_spareness_12 = list()\n",
        "    # ************* modify this section for later use *************\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        print(f\"epoch {epoch} started\")\n",
        "        # ************* modify this section for later use *************\n",
        "        hidden_layer_each_neuron_12 = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
        "        hidden_layer_each_neuron_12 = np.array(hidden_layer_each_neuron_12)\n",
        "        # ************* modify this section for later use *************\n",
        "\n",
        "        # ************* modify this section for later use *************\n",
        "        hidden_layer_activation_list_12 = list()\n",
        "        # ************* modify this section for later use *************\n",
        "\n",
        "        # TRAINING \n",
        "        model.train()\n",
        "        iterators = list(map(iter, train_dataloaders))   \n",
        "        while iterators:\n",
        "            iterator = np.random.choice(iterators, 5, replace=False)\n",
        "            try:\n",
        "                image0, label0 = next(iterator[0]) \n",
        "                image1, label1 = next(iterator[1]) \n",
        "                image2, label2 = next(iterator[2]) \n",
        "                image3, label3 = next(iterator[3]) \n",
        "                image4, label4 = next(iterator[4]) \n",
        "\n",
        "                # concat batch_size 10 * 5 => 50\n",
        "                images = torch.cat((image0, image1, image2, image3, image4), 0)\n",
        "                labels = torch.cat((label0, label1, label2, label3, label4), 0)\n",
        "                \n",
        "                # This is needed!!\n",
        "                indexes = torch.randperm(labels.shape[0])\n",
        "                images = images[indexes]\n",
        "                labels = labels[indexes]\n",
        "                # This is needed!!\n",
        "\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                pred = model(images)\n",
        "\n",
        "                loss = criterion(pred, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "            except StopIteration:\n",
        "                iterators.remove(iterator[0])\n",
        "                iterators.remove(iterator[1])\n",
        "                iterators.remove(iterator[2])\n",
        "                iterators.remove(iterator[3])\n",
        "                iterators.remove(iterator[4])\n",
        "\n",
        "\n",
        "        # TESTING\n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            # ***************** sparsity calculation ***************** #\n",
        "            hidden_layer_activation_list_12.append(model.layer_activations['s12'])\n",
        "\n",
        "            # ************* modify this section for later use *************\n",
        "            for activation, label in zip(model.layer_activations['s12'], labels):\n",
        "                label = label.item()\n",
        "                with torch.no_grad():\n",
        "                    activation = activation.numpy()\n",
        "                for i in range(256):    \n",
        "                    hidden_layer_each_neuron_12[i][label].append(activation[i])\n",
        "        \n",
        "        selectivity_avg, selecvitity_std = avg_std_calculator(hidden_layer_each_neuron_12)\n",
        "        # ************* modify this section for later use *************\n",
        "            \n",
        "        selectivity_avg_list.append(selectivity_avg)\n",
        "        selectivity_std_list.append(selecvitity_std)\n",
        "\n",
        "        # this conains activations for all epochs \n",
        "        final_spareness_12.append(hidden_layer_activation_list_12)\n",
        "        # ***************** sparsity calculation ***************** # \n",
        "\n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, accuracy))\n",
        "    \n",
        "    print(selectivity_avg_list)\n",
        "    print(selectivity_std_list)\n",
        "\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "    sparsity_list12 = sparsity_calculator(final_spareness_12)\n",
        "\n",
        "    average_sparsity = list()\n",
        "    for i in range(no_epochs):\n",
        "        average_sparsity.append( (sparsity_list12[i].item()) / 1 )\n",
        "    # ***************** sparsity calculation ***************** #\n",
        "\n",
        "    print(\"average_sparsity:\", average_sparsity)\n",
        "\n",
        "    return test_acc, average_sparsity, selectivity_avg_list, selectivity_std_list"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEdfCCHUam-f"
      },
      "source": [
        "# Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7jL46x7szw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf3cf57-55ce-48d2-e590-a1c912181f0c"
      },
      "source": [
        "model_factory('Adadelta')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-06\n",
            "    lr: 1.0\n",
            "    rho: 0.9\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.75330000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.90570000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.90380000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.88940000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.95600000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.94180000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.94450000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.94670000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.96930000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.97250000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.97170000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.97800000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.96870000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.97820000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.97150000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.98000000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.97810000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.96960000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.98000000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.98070000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.98010000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.97930000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.98030000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.98100000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.97710000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.98100000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.97920000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.97870000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.98090000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.98180000\n",
            "[0.36883099276053666, 0.41390302857092676, 0.4318973068015063, 0.44438578943626117, 0.44617574533968773, 0.44801638367350627, 0.45170529594396835, 0.4547141246491848, 0.45389407820711336, 0.4543808174898136, 0.4543725397241689, 0.45479389448185376, 0.4529637109736808, 0.45386677430745276, 0.45248355238041693, 0.45280259731620454, 0.4512665615086141, 0.45093100970844263, 0.45118262202316195, 0.44934374010517475, 0.44797435419613263, 0.44742563100417304, 0.4466019244828105, 0.44650000889862607, 0.44606860714435526, 0.4456259841343485, 0.44553439005328005, 0.44415377740205064, 0.44382107850233543, 0.44358942709715576]\n",
            "[0.1394756692752384, 0.15238346724311735, 0.16674687989390286, 0.16175631959707154, 0.16273906714815764, 0.1701192115657864, 0.1667136374021992, 0.16751747656291038, 0.16732316429989744, 0.16393909303487947, 0.1662501027203988, 0.1643381697229792, 0.1659397350188753, 0.16481704835744235, 0.16342743667785414, 0.16634047390822784, 0.16618323861271672, 0.16540332533410973, 0.16413362468786188, 0.16349156266017242, 0.1634461676811265, 0.16440585648892497, 0.1644649603363491, 0.16406748282527805, 0.1657401211784403, 0.1634789876177202, 0.16305492879521533, 0.1660520159221183, 0.16290049513025007, 0.16342414780886674]\n",
            "average_sparsity: [0.22713540494441986, 0.2787994146347046, 0.30626097321510315, 0.3230670988559723, 0.3283650279045105, 0.3338683247566223, 0.3412667214870453, 0.34722059965133667, 0.3473930060863495, 0.3498050272464752, 0.34961557388305664, 0.35332009196281433, 0.35279926657676697, 0.35331594944000244, 0.3534393012523651, 0.3548137843608856, 0.35435450077056885, 0.35441553592681885, 0.3558409810066223, 0.35404083132743835, 0.35353368520736694, 0.3530386984348297, 0.35293760895729065, 0.35332760214805603, 0.35312286019325256, 0.3537531793117523, 0.3530757427215576, 0.3519671559333801, 0.35235264897346497, 0.3526332676410675]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smiDmZZ1aoS3"
      },
      "source": [
        "# Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGakLBYDaYTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6426010a-b7bd-4c16-9312-535c28d5189e"
      },
      "source": [
        "model_factory('Adagrad')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.1\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.94950000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.94910000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.96390000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.96910000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.97300000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.97470000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.97450000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.97610000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.97670000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.97640000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.97760000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.97810000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.97900000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.97820000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.97840000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.97890000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.97920000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.97920000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.97860000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.98010000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.97950000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.98030000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.97970000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.97980000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.97950000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.97960000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.98080000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.98020000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.97990000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.98060000\n",
            "[0.733795709923405, 0.7186851972117677, 0.7184629355577966, 0.7037579971496926, 0.7042358199565442, 0.7008973424242301, 0.6962395125029641, 0.6947314856809965, 0.6912663776524501, 0.6871728734262413, 0.6840692438280442, 0.6804855258105368, 0.6790403977711835, 0.6788975340298864, 0.6789547615258986, 0.6794267478569963, 0.6771244092243244, 0.6764614993921891, 0.6740285244398301, 0.6750968239212163, 0.6748075745578066, 0.6753661927975451, 0.6749374006414663, 0.6748703548338588, 0.6749806823107078, 0.6747131538799607, 0.6742492793046477, 0.6752573335770444, 0.6744275073497965, 0.6742829368492453]\n",
            "[0.2335376897472066, 0.232448856727244, 0.23263717567486775, 0.22826602558494144, 0.22846389071911954, 0.22806320667461225, 0.22551465212314017, 0.22651630762098526, 0.22448257056636473, 0.2249682932410678, 0.2243318117519802, 0.2240370026760914, 0.22434798760656224, 0.22255536925795125, 0.22509342706502175, 0.22438574379950393, 0.22467407168354633, 0.22437767074236153, 0.22323248379620583, 0.22477437720466176, 0.2238667555316221, 0.22417247092417752, 0.22430112990906081, 0.2243651647688293, 0.2237996379790011, 0.2242763284581599, 0.224460376449942, 0.2237426442733844, 0.22407287564514963, 0.22400655158288166]\n",
            "average_sparsity: [0.6028327345848083, 0.5926600098609924, 0.5990641713142395, 0.5904542207717896, 0.590549886226654, 0.589606523513794, 0.5851853489875793, 0.5854049324989319, 0.5845910310745239, 0.5823137760162354, 0.5813130736351013, 0.5789408683776855, 0.578438401222229, 0.5774675011634827, 0.5776251554489136, 0.5780633687973022, 0.5761767029762268, 0.5760878920555115, 0.5739871263504028, 0.5745947957038879, 0.5734931826591492, 0.5747090578079224, 0.5735945105552673, 0.5729295611381531, 0.5731887817382812, 0.5721594095230103, 0.572014331817627, 0.5728393793106079, 0.5719091892242432, 0.5721914768218994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPYS2f8Dapah"
      },
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdlUNK4YaYVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce75ee3-51a1-4cc0-901b-8940d8b816da"
      },
      "source": [
        "model_factory('SGD')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.87920000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.87380000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.81060000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.89740000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.84260000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.92210000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.89960000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.89580000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.93060000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.87420000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.91430000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.92550000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.93620000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.94670000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.94920000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.94340000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.93770000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.95120000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.94750000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.95730000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.95210000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.94530000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.96130000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.96700000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.96700000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.96620000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.96470000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.96610000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.96430000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.96210000\n",
            "[0.24558091118742892, 0.2647212987458491, 0.27828911011439095, 0.29317036526111007, 0.3067901023364654, 0.3180340934972872, 0.32909919770198476, 0.3386570427175485, 0.3481655311420278, 0.35403925912612066, 0.3618803557143707, 0.36738741096516514, 0.3706899610997042, 0.37657624797312017, 0.3792973592682717, 0.38180377121297593, 0.38590844510434125, 0.38856652225618354, 0.3907682506857927, 0.39232691142597903, 0.3939106846730323, 0.3962927384851791, 0.3975817466397059, 0.3987599847422394, 0.40049861928715874, 0.40143877139894285, 0.40229533266115247, 0.40320675258853633, 0.4041548676007002, 0.40444437044095627]\n",
            "[0.07900779095297439, 0.09067130058417425, 0.09764883985686335, 0.10679552217360368, 0.11407813355201173, 0.11741130778050975, 0.12200879474206443, 0.12983763014926508, 0.1346436249852581, 0.13508526428364578, 0.1425935281538555, 0.1424193522929619, 0.14502129599075825, 0.1450421816668999, 0.14568150182694947, 0.14584508777507926, 0.15002086221257632, 0.14963273980584976, 0.14881262526068553, 0.14934501945613443, 0.15158262855353738, 0.15322496631311622, 0.15292806699432376, 0.15334510842405952, 0.15408410173251663, 0.15476303369432387, 0.15613024973522113, 0.15607125819877418, 0.15657770727102685, 0.1571233885738365]\n",
            "average_sparsity: [0.09654031693935394, 0.11320606619119644, 0.12396330386400223, 0.13939975202083588, 0.15588711202144623, 0.16545820236206055, 0.17822431027889252, 0.19279687106609344, 0.202572762966156, 0.20939716696739197, 0.22103770077228546, 0.22651691734790802, 0.2338021695613861, 0.23897206783294678, 0.24431033432483673, 0.24849610030651093, 0.25479185581207275, 0.2573859393596649, 0.2614282965660095, 0.26389655470848083, 0.2669508755207062, 0.2714698314666748, 0.27298790216445923, 0.27550530433654785, 0.2784179151058197, 0.2798316478729248, 0.28149595856666565, 0.28372398018836975, 0.2859259247779846, 0.2871268689632416]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_u1nZEIaqOL"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ga1E6jaYXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c52df2-8b63-4107-d459-31d59146f4f5"
      },
      "source": [
        "model_factory('Adam')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid12): Sigmoid()\n",
            ")\n",
            "my_optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "epoch 0 started\n",
            "\n",
            "Epoch: 1/30, Test Accuracy: 0.81450000\n",
            "epoch 1 started\n",
            "\n",
            "Epoch: 2/30, Test Accuracy: 0.82430000\n",
            "epoch 2 started\n",
            "\n",
            "Epoch: 3/30, Test Accuracy: 0.89190000\n",
            "epoch 3 started\n",
            "\n",
            "Epoch: 4/30, Test Accuracy: 0.92430000\n",
            "epoch 4 started\n",
            "\n",
            "Epoch: 5/30, Test Accuracy: 0.96770000\n",
            "epoch 5 started\n",
            "\n",
            "Epoch: 6/30, Test Accuracy: 0.93830000\n",
            "epoch 6 started\n",
            "\n",
            "Epoch: 7/30, Test Accuracy: 0.95620000\n",
            "epoch 7 started\n",
            "\n",
            "Epoch: 8/30, Test Accuracy: 0.96900000\n",
            "epoch 8 started\n",
            "\n",
            "Epoch: 9/30, Test Accuracy: 0.95510000\n",
            "epoch 9 started\n",
            "\n",
            "Epoch: 10/30, Test Accuracy: 0.97780000\n",
            "epoch 10 started\n",
            "\n",
            "Epoch: 11/30, Test Accuracy: 0.95770000\n",
            "epoch 11 started\n",
            "\n",
            "Epoch: 12/30, Test Accuracy: 0.96600000\n",
            "epoch 12 started\n",
            "\n",
            "Epoch: 13/30, Test Accuracy: 0.96410000\n",
            "epoch 13 started\n",
            "\n",
            "Epoch: 14/30, Test Accuracy: 0.97380000\n",
            "epoch 14 started\n",
            "\n",
            "Epoch: 15/30, Test Accuracy: 0.97880000\n",
            "epoch 15 started\n",
            "\n",
            "Epoch: 16/30, Test Accuracy: 0.98000000\n",
            "epoch 16 started\n",
            "\n",
            "Epoch: 17/30, Test Accuracy: 0.97440000\n",
            "epoch 17 started\n",
            "\n",
            "Epoch: 18/30, Test Accuracy: 0.96980000\n",
            "epoch 18 started\n",
            "\n",
            "Epoch: 19/30, Test Accuracy: 0.98030000\n",
            "epoch 19 started\n",
            "\n",
            "Epoch: 20/30, Test Accuracy: 0.98110000\n",
            "epoch 20 started\n",
            "\n",
            "Epoch: 21/30, Test Accuracy: 0.97940000\n",
            "epoch 21 started\n",
            "\n",
            "Epoch: 22/30, Test Accuracy: 0.97470000\n",
            "epoch 22 started\n",
            "\n",
            "Epoch: 23/30, Test Accuracy: 0.97990000\n",
            "epoch 23 started\n",
            "\n",
            "Epoch: 24/30, Test Accuracy: 0.98030000\n",
            "epoch 24 started\n",
            "\n",
            "Epoch: 25/30, Test Accuracy: 0.98080000\n",
            "epoch 25 started\n",
            "\n",
            "Epoch: 26/30, Test Accuracy: 0.97290000\n",
            "epoch 26 started\n",
            "\n",
            "Epoch: 27/30, Test Accuracy: 0.98140000\n",
            "epoch 27 started\n",
            "\n",
            "Epoch: 28/30, Test Accuracy: 0.97970000\n",
            "epoch 28 started\n",
            "\n",
            "Epoch: 29/30, Test Accuracy: 0.97950000\n",
            "epoch 29 started\n",
            "\n",
            "Epoch: 30/30, Test Accuracy: 0.97890000\n",
            "[0.33361219844437345, 0.3605009945882193, 0.37796121414644474, 0.38171765350908504, 0.389694642304139, 0.39247470153687253, 0.39728883225826506, 0.39519805225980686, 0.39795154490621637, 0.40307990125077514, 0.40084020604952386, 0.40045547225033673, 0.40020482854534495, 0.4018876563976963, 0.3983675099104696, 0.39926051218808284, 0.39915658464721393, 0.39679903957549734, 0.39754213961790125, 0.3995681463486612, 0.40028489598533923, 0.40086431172448256, 0.40005941412596335, 0.4005770172093399, 0.4000130788237712, 0.40158602506484464, 0.3995302661496827, 0.40066942426067725, 0.3998844547509761, 0.39946889070772273]\n",
            "[0.13566632445555374, 0.16750320546920008, 0.17097918061867837, 0.16033137055906574, 0.17087409998797476, 0.17634854748457127, 0.1783112725098289, 0.17256675976659938, 0.17046254547300332, 0.17835359383045837, 0.18125016682469222, 0.17141894326406965, 0.1748055617462178, 0.17289864195910745, 0.171618329453667, 0.17197704366286437, 0.17347841796526114, 0.1679330775724796, 0.1707895959711338, 0.17283406782951413, 0.1720307727909478, 0.16873256148012394, 0.17001633043585643, 0.17208510782906455, 0.17083581701487724, 0.17400469243845174, 0.1690553309452984, 0.17091596307808563, 0.16930039934512742, 0.17132759660515856]\n",
            "average_sparsity: [0.2028617113828659, 0.23553264141082764, 0.2568959891796112, 0.26293349266052246, 0.27453455328941345, 0.2808227241039276, 0.2891291379928589, 0.2890705466270447, 0.2921428084373474, 0.30053725838661194, 0.3012864291667938, 0.3013954758644104, 0.30134308338165283, 0.3066132068634033, 0.30357733368873596, 0.3064133822917938, 0.3068612515926361, 0.3062349259853363, 0.3070194125175476, 0.30988720059394836, 0.3105119466781616, 0.31212979555130005, 0.31239843368530273, 0.3130188584327698, 0.31294071674346924, 0.3156448304653168, 0.3139818608760834, 0.31570765376091003, 0.31481972336769104, 0.31400325894355774]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}