{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparsity_not_sorted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/sparsity_not_sorted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7STrWa0P3z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2186f45b-8e8e-4b92-968c-3150fbc8ff6c"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An-NVJcEfVG-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tke0vosw9vt4"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = datasets.MNIST(root='./data', \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 100\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "def sparsity_trainer(optimizer, model):\n",
        "\n",
        "    # reset the model \n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "    final_spareness = list()\n",
        "\n",
        "    # define activation list \n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        hidden_layer_activation_list = list()\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "        for itr, (image, label) in enumerate(train_dataloader):\n",
        "\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(image)\n",
        "\n",
        "            loss = criterion(pred, label)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (image, label) in enumerate(test_dataloader):\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "\n",
        "            loss = criterion(pred, label)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if label[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            hidden_layer_activation_list.append(model.layer_activations)\n",
        "\n",
        "        # this conains activations for all epochs \n",
        "        final_spareness.append(hidden_layer_activation_list)\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "        # if total_test_loss < best_test_loss:\n",
        "        #     best_test_loss = total_test_loss\n",
        "            # print(\"Saving the model state dictionary for Epoch: {} with Test loss: {:.8f}\".format(epoch + 1, total_test_loss))\n",
        "            # torch.save(model.state_dict(), \"model.dth\")\n",
        "\n",
        "    sparseness_list = list()\n",
        "\n",
        "    for single_epoch_spareness in final_spareness:\n",
        "        single_epoch_spareness = torch.stack(single_epoch_spareness)\n",
        "        layer_activations_list = torch.reshape(single_epoch_spareness, (10000, 256))\n",
        "\n",
        "        layer_activations_list = torch.abs(layer_activations_list)  # modified \n",
        "        num_neurons = layer_activations_list.shape[1]\n",
        "        population_sparseness = (np.sqrt(num_neurons) - (torch.sum(layer_activations_list, dim=1) / torch.sqrt(torch.sum(layer_activations_list ** 2, dim=1)))) / (np.sqrt(num_neurons) - 1)\n",
        "        mean_sparseness_per_epoch = torch.mean(population_sparseness)\n",
        "\n",
        "        sparseness_list.append(mean_sparseness_per_epoch)\n",
        "\n",
        "    return test_acc, sparseness_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# AdaDelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOb5LovDJjur",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "outputId": "3b7716ed-a333-487f-8f04-df81e25c9491"
      },
      "source": [
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, Adadelta_sparseness_list = sparsity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"not_sorted_sparsity_Adadelta.txt\", \"w\")\n",
        "f.write(str(Adadelta_test_acc)+'\\n'+str(Adadelta_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_sparsity_Adadelta.txt /content/drive/MyDrive"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adadelta: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.43482734, Test Loss: 0.25056328, Test Accuracy: 0.92680000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.21552304, Test Loss: 0.17478676, Test Accuracy: 0.94670000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.15641612, Test Loss: 0.13820602, Test Accuracy: 0.95740000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.12157690, Test Loss: 0.11924306, Test Accuracy: 0.96300000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.09919056, Test Loss: 0.09831684, Test Accuracy: 0.96860000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.08336800, Test Loss: 0.09016022, Test Accuracy: 0.97190000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0fcd7ad4724b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_Adadelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_Adadelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer_Adadelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_Adadelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mAdadelta_test_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdadelta_sparseness_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparsity_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_Adadelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_Adadelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not_sorted_sparsity_Adadelta.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b36a5c7cbc00>\u001b[0m in \u001b[0;36msparsity_trainer\u001b[0;34m(optimizer, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# set up training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXfQe4vMDKB"
      },
      "source": [
        "# AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb-4TPM5MGuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4777ce9-e71a-4048-ea56-830c96aefc8c"
      },
      "source": [
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, Adagrad_sparseness_list = sparsity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"not_sorted_sparsity_Adagrad.txt\", \"w\")\n",
        "f.write(str(Adagrad_test_acc)+'\\n'+str(Adagrad_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_sparsity_Adagrad.txt /content/drive/MyDrive"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.23439522, Test Loss: 0.12393352, Test Accuracy: 0.96080000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.09499635, Test Loss: 0.09212695, Test Accuracy: 0.97110000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.06664003, Test Loss: 0.08824838, Test Accuracy: 0.97180000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.05111396, Test Loss: 0.07646110, Test Accuracy: 0.97580000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.04075940, Test Loss: 0.07340739, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.03315783, Test Loss: 0.06994413, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.02713919, Test Loss: 0.07005949, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.02278634, Test Loss: 0.06832454, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.01949250, Test Loss: 0.06757483, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.01662500, Test Loss: 0.06679274, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.01444770, Test Loss: 0.06654883, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.01266692, Test Loss: 0.06626103, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.01102338, Test Loss: 0.06499955, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.00990729, Test Loss: 0.06596202, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.00878391, Test Loss: 0.06481290, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.00780406, Test Loss: 0.06558851, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.00710155, Test Loss: 0.06503779, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.00636237, Test Loss: 0.06550353, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.00581291, Test Loss: 0.06536915, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.00531581, Test Loss: 0.06590590, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.00491891, Test Loss: 0.06639947, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.00453402, Test Loss: 0.06578133, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.00419580, Test Loss: 0.06645118, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.00388953, Test Loss: 0.06623063, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.00364387, Test Loss: 0.06639447, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.00340730, Test Loss: 0.06569812, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.00319673, Test Loss: 0.06661246, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.00300245, Test Loss: 0.06650066, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.00283233, Test Loss: 0.06659617, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.00267987, Test Loss: 0.06658960, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.00254091, Test Loss: 0.06736415, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.00240679, Test Loss: 0.06677189, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.00229679, Test Loss: 0.06716743, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.00219164, Test Loss: 0.06736271, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00209084, Test Loss: 0.06757324, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00200114, Test Loss: 0.06760606, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00191773, Test Loss: 0.06736295, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00183769, Test Loss: 0.06747617, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00176658, Test Loss: 0.06751106, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00169622, Test Loss: 0.06769883, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00164088, Test Loss: 0.06795791, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00157768, Test Loss: 0.06780921, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00151795, Test Loss: 0.06801709, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00146855, Test Loss: 0.06832591, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00142091, Test Loss: 0.06812599, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00137204, Test Loss: 0.06859630, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00132680, Test Loss: 0.06883064, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00128480, Test Loss: 0.06868445, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00124612, Test Loss: 0.06867452, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00120732, Test Loss: 0.06882558, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00117176, Test Loss: 0.06875499, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00113840, Test Loss: 0.06919038, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00110509, Test Loss: 0.06919319, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00107569, Test Loss: 0.06934882, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00104487, Test Loss: 0.06934757, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00101921, Test Loss: 0.06942913, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00099228, Test Loss: 0.06946351, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00096667, Test Loss: 0.06988574, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00094295, Test Loss: 0.06973335, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00091958, Test Loss: 0.06983763, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00089803, Test Loss: 0.06985317, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00087784, Test Loss: 0.06999357, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00085748, Test Loss: 0.07029303, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00083765, Test Loss: 0.07033612, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00081977, Test Loss: 0.07017979, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00080000, Test Loss: 0.07059424, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00078540, Test Loss: 0.07053346, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00076762, Test Loss: 0.07073227, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00075278, Test Loss: 0.07088656, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00073618, Test Loss: 0.07100068, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00072221, Test Loss: 0.07077257, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00070763, Test Loss: 0.07101277, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00069489, Test Loss: 0.07094729, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00068147, Test Loss: 0.07105531, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00066832, Test Loss: 0.07125296, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00065683, Test Loss: 0.07126762, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00064353, Test Loss: 0.07136863, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00063275, Test Loss: 0.07131278, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00062213, Test Loss: 0.07149871, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00061132, Test Loss: 0.07153912, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00060143, Test Loss: 0.07168224, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00059076, Test Loss: 0.07170689, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00058055, Test Loss: 0.07180451, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00057159, Test Loss: 0.07180848, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00056214, Test Loss: 0.07201675, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00055263, Test Loss: 0.07197699, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00054445, Test Loss: 0.07218436, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00053621, Test Loss: 0.07233386, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00052776, Test Loss: 0.07223893, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00051936, Test Loss: 0.07228552, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00051174, Test Loss: 0.07237657, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00050379, Test Loss: 0.07249409, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00049676, Test Loss: 0.07250217, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00048937, Test Loss: 0.07262162, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00048238, Test Loss: 0.07277616, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00047583, Test Loss: 0.07276678, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00046911, Test Loss: 0.07288013, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00046279, Test Loss: 0.07291887, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00045637, Test Loss: 0.07288541, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00044947, Test Loss: 0.07306812, Test Accuracy: 0.98120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLJ4Zr2MnoS"
      },
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ObsEJHuMoPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b38b617-130b-49e7-e30c-c707bd036b84"
      },
      "source": [
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, SGD_sparseness_list = sparsity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"not_sorted_sparsity_SGD.txt\", \"w\")\n",
        "f.write(str(SGD_test_acc)+'\\n'+str(SGD_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_sparsity_SGD.txt /content/drive/MyDrive"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.76356382, Test Loss: 0.37123979, Test Accuracy: 0.89470000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.34639586, Test Loss: 0.30502521, Test Accuracy: 0.91280000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.30632597, Test Loss: 0.28052564, Test Accuracy: 0.91830000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.28360342, Test Loss: 0.26220752, Test Accuracy: 0.92460000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.26567984, Test Loss: 0.25403698, Test Accuracy: 0.92850000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.24908113, Test Loss: 0.23463870, Test Accuracy: 0.93200000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.23349987, Test Loss: 0.22112721, Test Accuracy: 0.93650000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.21825378, Test Loss: 0.20715809, Test Accuracy: 0.94200000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.20464664, Test Loss: 0.19649480, Test Accuracy: 0.94210000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.19216759, Test Loss: 0.18385484, Test Accuracy: 0.94630000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.18063866, Test Loss: 0.17739862, Test Accuracy: 0.94770000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.17032208, Test Loss: 0.16677698, Test Accuracy: 0.95200000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.16125472, Test Loss: 0.15835800, Test Accuracy: 0.95450000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.15238192, Test Loss: 0.15119765, Test Accuracy: 0.95680000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.14478209, Test Loss: 0.14645029, Test Accuracy: 0.95720000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.13725782, Test Loss: 0.14079188, Test Accuracy: 0.95880000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.13081672, Test Loss: 0.13568200, Test Accuracy: 0.96010000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.12485648, Test Loss: 0.13307593, Test Accuracy: 0.96080000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.11982298, Test Loss: 0.12728906, Test Accuracy: 0.96150000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.11430316, Test Loss: 0.12154536, Test Accuracy: 0.96380000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.10965057, Test Loss: 0.11994056, Test Accuracy: 0.96420000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.10507329, Test Loss: 0.11444282, Test Accuracy: 0.96520000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.10118069, Test Loss: 0.11071377, Test Accuracy: 0.96670000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.09730085, Test Loss: 0.10841079, Test Accuracy: 0.96740000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.09374404, Test Loss: 0.10639216, Test Accuracy: 0.96740000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.09021832, Test Loss: 0.10187216, Test Accuracy: 0.96870000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.08714523, Test Loss: 0.10136349, Test Accuracy: 0.96950000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.08429624, Test Loss: 0.09750499, Test Accuracy: 0.97010000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.08144080, Test Loss: 0.09683519, Test Accuracy: 0.96940000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.07874181, Test Loss: 0.09380753, Test Accuracy: 0.97020000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.07626768, Test Loss: 0.09300420, Test Accuracy: 0.97200000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.07375858, Test Loss: 0.09021916, Test Accuracy: 0.97090000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.07146056, Test Loss: 0.09050584, Test Accuracy: 0.97220000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.06930690, Test Loss: 0.08738769, Test Accuracy: 0.97290000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.06737025, Test Loss: 0.08639515, Test Accuracy: 0.97240000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.06527309, Test Loss: 0.08661623, Test Accuracy: 0.97300000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.06333048, Test Loss: 0.08585254, Test Accuracy: 0.97380000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.06154695, Test Loss: 0.08248136, Test Accuracy: 0.97530000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.05986690, Test Loss: 0.08169524, Test Accuracy: 0.97500000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.05814669, Test Loss: 0.08038770, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.05661100, Test Loss: 0.07955569, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.05510205, Test Loss: 0.07941229, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.05353584, Test Loss: 0.07761752, Test Accuracy: 0.97580000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.05217156, Test Loss: 0.07738513, Test Accuracy: 0.97700000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.05065000, Test Loss: 0.07931688, Test Accuracy: 0.97680000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.04945892, Test Loss: 0.07650752, Test Accuracy: 0.97570000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.04827879, Test Loss: 0.07652530, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.04690092, Test Loss: 0.07452328, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.04583254, Test Loss: 0.07416573, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.04456806, Test Loss: 0.07404650, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.04333155, Test Loss: 0.07417756, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.04248697, Test Loss: 0.07359999, Test Accuracy: 0.97690000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.04140803, Test Loss: 0.07129942, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.04043326, Test Loss: 0.07072434, Test Accuracy: 0.97700000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.03953349, Test Loss: 0.07076553, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.03847915, Test Loss: 0.07111501, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.03764602, Test Loss: 0.06933178, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.03673943, Test Loss: 0.07072005, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.03590498, Test Loss: 0.06988999, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.03515856, Test Loss: 0.06935955, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.03426694, Test Loss: 0.06910098, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.03339866, Test Loss: 0.06975502, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.03286493, Test Loss: 0.06706757, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.03202803, Test Loss: 0.06797058, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.03135423, Test Loss: 0.06687333, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.03052032, Test Loss: 0.06719929, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.02995424, Test Loss: 0.06630272, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.02917049, Test Loss: 0.06664475, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.02859105, Test Loss: 0.06530494, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.02797161, Test Loss: 0.06592701, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.02726438, Test Loss: 0.06576159, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.02679610, Test Loss: 0.06547761, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.02622566, Test Loss: 0.06588911, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.02570083, Test Loss: 0.06517162, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.02504798, Test Loss: 0.06418843, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.02465948, Test Loss: 0.06510493, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.02408957, Test Loss: 0.06393729, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.02361680, Test Loss: 0.06446638, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.02307125, Test Loss: 0.06488283, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.02255314, Test Loss: 0.06428956, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.02208437, Test Loss: 0.06358637, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.02169843, Test Loss: 0.06375327, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.02121720, Test Loss: 0.06327438, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.02084721, Test Loss: 0.06422208, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.02042555, Test Loss: 0.06276762, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.01999798, Test Loss: 0.06400940, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.01960026, Test Loss: 0.06302666, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.01921396, Test Loss: 0.06405811, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.01883972, Test Loss: 0.06322082, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.01849686, Test Loss: 0.06251765, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.01815609, Test Loss: 0.06244604, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.01771270, Test Loss: 0.06307347, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.01743330, Test Loss: 0.06271928, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.01713882, Test Loss: 0.06319509, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.01680648, Test Loss: 0.06246415, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.01650770, Test Loss: 0.06260618, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.01613964, Test Loss: 0.06216681, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.01593079, Test Loss: 0.06264680, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.01557601, Test Loss: 0.06288920, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.01532980, Test Loss: 0.06141043, Test Accuracy: 0.98160000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQxaN_fRXLq"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY35Kab0EeRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6442c940-ba0d-4d9d-f0f1-3ff6b086d797"
      },
      "source": [
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, Adam_sparseness_list = sparsity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"not_sorted_sparsity_Adam.txt\", \"w\")\n",
        "f.write(str(Adam_test_acc)+'\\n'+str(Adam_sparseness_list)+'\\n\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_sparsity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.42707376, Test Loss: 0.23229995, Test Accuracy: 0.92990000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.19683726, Test Loss: 0.16562192, Test Accuracy: 0.95000000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.14206681, Test Loss: 0.13353463, Test Accuracy: 0.96060000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.10818527, Test Loss: 0.10605625, Test Accuracy: 0.96830000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.08564620, Test Loss: 0.09401113, Test Accuracy: 0.97100000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.06876795, Test Loss: 0.08297990, Test Accuracy: 0.97430000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.05615342, Test Loss: 0.08354625, Test Accuracy: 0.97440000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.04597417, Test Loss: 0.07344530, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.03769751, Test Loss: 0.06873602, Test Accuracy: 0.97840000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.03101516, Test Loss: 0.07071251, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.02537434, Test Loss: 0.06492335, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.02047061, Test Loss: 0.06618053, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.01693426, Test Loss: 0.07665232, Test Accuracy: 0.97650000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.01364931, Test Loss: 0.06696025, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.01099578, Test Loss: 0.06797996, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.00841108, Test Loss: 0.06736419, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.00708614, Test Loss: 0.06715907, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.00565072, Test Loss: 0.06797179, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.00466511, Test Loss: 0.07272205, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.00360138, Test Loss: 0.07016233, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.00274890, Test Loss: 0.07272699, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.00217175, Test Loss: 0.07295484, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.00192691, Test Loss: 0.07512454, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.00152127, Test Loss: 0.07606529, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.00100184, Test Loss: 0.07846402, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.00148448, Test Loss: 0.08914684, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.00085640, Test Loss: 0.07977885, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.00046566, Test Loss: 0.08341784, Test Accuracy: 0.98140000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.00119113, Test Loss: 0.08623910, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.00042611, Test Loss: 0.08511791, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.00025191, Test Loss: 0.08421772, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.00026667, Test Loss: 0.08521773, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.00130465, Test Loss: 0.09092584, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.00019699, Test Loss: 0.08960607, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00012689, Test Loss: 0.09084925, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00010978, Test Loss: 0.09154339, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00025041, Test Loss: 0.12008357, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00106190, Test Loss: 0.09827330, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00009944, Test Loss: 0.09787847, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00007014, Test Loss: 0.09684015, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00005938, Test Loss: 0.09945007, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00079512, Test Loss: 0.11032275, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00083701, Test Loss: 0.09904732, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00007788, Test Loss: 0.10028154, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00005376, Test Loss: 0.10110579, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00004388, Test Loss: 0.10184855, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00003683, Test Loss: 0.10142750, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00003432, Test Loss: 0.10339792, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00084559, Test Loss: 0.10381365, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00013048, Test Loss: 0.10459649, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00003967, Test Loss: 0.10410242, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00002776, Test Loss: 0.10504241, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00002264, Test Loss: 0.10521197, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00001929, Test Loss: 0.10906776, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00001647, Test Loss: 0.11017134, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00109195, Test Loss: 0.11530584, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00005676, Test Loss: 0.10971366, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00002380, Test Loss: 0.10956610, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00001781, Test Loss: 0.10986930, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00001454, Test Loss: 0.11005140, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00001212, Test Loss: 0.11112287, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00001019, Test Loss: 0.11251049, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00000891, Test Loss: 0.11434086, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00135696, Test Loss: 0.12382925, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00015284, Test Loss: 0.11157616, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00002418, Test Loss: 0.11259007, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00001528, Test Loss: 0.11297355, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00001131, Test Loss: 0.11423795, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00000870, Test Loss: 0.11464553, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00000685, Test Loss: 0.11608377, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00000551, Test Loss: 0.11658233, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00000448, Test Loss: 0.11792392, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00000399, Test Loss: 0.12034067, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00028325, Test Loss: 0.16040145, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00090285, Test Loss: 0.12609634, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00002612, Test Loss: 0.12796723, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00000914, Test Loss: 0.12697822, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00000633, Test Loss: 0.12668315, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00000482, Test Loss: 0.12712835, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00000375, Test Loss: 0.12728642, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00000298, Test Loss: 0.12692184, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00000240, Test Loss: 0.12733105, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00000197, Test Loss: 0.12832266, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00000175, Test Loss: 0.12971539, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00182391, Test Loss: 0.14775922, Test Accuracy: 0.97700000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00035010, Test Loss: 0.13269844, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00001384, Test Loss: 0.13314978, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00000764, Test Loss: 0.13352758, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00000544, Test Loss: 0.13361662, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00000401, Test Loss: 0.13368689, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00000306, Test Loss: 0.13339697, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00000232, Test Loss: 0.13355805, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00000181, Test Loss: 0.13333100, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00000144, Test Loss: 0.13400901, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00000116, Test Loss: 0.13512830, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00000096, Test Loss: 0.13505113, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00000079, Test Loss: 0.13674877, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00054651, Test Loss: 0.17044001, Test Accuracy: 0.97650000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECkkHSExysT-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}