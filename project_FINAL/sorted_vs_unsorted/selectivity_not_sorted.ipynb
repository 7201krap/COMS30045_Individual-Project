{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selectivity_not_sorted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/PYTORCH_project/blob/main/selectivity_not_sorted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7STrWa0P3z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d47f8c-d245-441a-ca51-4a35254deafb"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4j9WoP-UnAm"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApOU7hvb95W4"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTW5TOUnP5XY"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_testset  = datasets.MNIST(root='./data', \n",
        "                                train=False, \n",
        "                                download=True, \n",
        "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=True)\n",
        "\n",
        "test_dataloader  = torch.utils.data.DataLoader(mnist_testset, \n",
        "                                               batch_size=50, \n",
        "                                               shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTkEUJ5P6kU"
      },
      "source": [
        "# Define the model \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = torch.nn.Linear(784, 256)\n",
        "        self.linear_2 = torch.nn.Linear(256, 10)\n",
        "        self.sigmoid  = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgvKH6eP9Ou"
      },
      "source": [
        "def get_activation(model):    \n",
        "    def hook(module, input, output):\n",
        "        model.layer_activations = output\n",
        "    return hook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXOpwTXEQFKY"
      },
      "source": [
        "no_epochs = 100\n",
        "def selectivity_trainer(optimizer, model):\n",
        "\n",
        "    hidden_layer_each_neuron = [{0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]} for x in range(256)]\n",
        "    hidden_layer_each_neuron = np.array(hidden_layer_each_neuron)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    train_loss = list()\n",
        "    test_loss  = list()\n",
        "    test_acc   = list()\n",
        "\n",
        "    best_test_loss = 1\n",
        "\n",
        "    for epoch in range(no_epochs):\n",
        "        total_train_loss = 0\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # training\n",
        "        # set up training mode \n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, labels) in enumerate(train_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print/Append activation of the hidden layer \n",
        "            # print(model.layer_activations.shape)\n",
        "            # model.layer_activations\n",
        "\n",
        "        total_train_loss = total_train_loss / (itr + 1)\n",
        "        train_loss.append(total_train_loss)\n",
        "\n",
        "        # testing \n",
        "        # change to evaluation mode \n",
        "        model.eval()\n",
        "        total = 0\n",
        "        for itr, (images, labels) in enumerate(test_dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            # we now need softmax because we are testing.\n",
        "            pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "            for i, p in enumerate(pred):\n",
        "                if labels[i] == torch.max(p.data, 0)[1]:\n",
        "                    total = total + 1\n",
        "\n",
        "            # find selectivity at the final epoch \n",
        "            if epoch == no_epochs - 1: # last epoch \n",
        "                for activation, label in zip(model.layer_activations, labels):\n",
        "                    # shape of activation and label: 256 and 1 \n",
        "                    \n",
        "                    # get the actual value of item. This is because label is now Tensor \n",
        "                    label = label.item()\n",
        "\n",
        "                    # this is not part of gradient calculcation \n",
        "                    with torch.no_grad():\n",
        "                        activation = activation.numpy()\n",
        "\n",
        "                    # for each image/label, append activation value of neuron \n",
        "                    for i in range(256):    # number of neurons in hidden layer \n",
        "                        hidden_layer_each_neuron[i][label].append(activation[i])\n",
        "\n",
        "\n",
        "        # caculate accuracy \n",
        "        accuracy = total / len(mnist_testset)\n",
        "\n",
        "        # append accuracy here\n",
        "        test_acc.append(accuracy)\n",
        "\n",
        "        # append test loss here \n",
        "        total_test_loss = total_test_loss / (itr + 1)\n",
        "        test_loss.append(total_test_loss)\n",
        "\n",
        "        print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Test Loss: {:.8f}, Test Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_test_loss, accuracy))\n",
        "\n",
        "        # if total_test_loss < best_test_loss:\n",
        "        #     best_test_loss = total_test_loss\n",
        "        #     print(\"Saving the model state dictionary for Epoch: {} with Test loss: {:.8f}\".format(epoch + 1, total_test_loss))\n",
        "        #     torch.save(model.state_dict(), \"model.dth\")\n",
        "\n",
        "    # I will now try to find the average of each class for each neuron.\n",
        "    # check out the next cell \n",
        "    avg_activations = [dict() for x in range(256)]\n",
        "    for i, neuron in enumerate(hidden_layer_each_neuron):\n",
        "        for k, v in neuron.items():\n",
        "            # v is the list of activations for hidden layer's neuron k \n",
        "            avg_activations[i][k] = sum(v) / float(len(v))\n",
        "\n",
        "    # generate 256 lists to get only values in avg_activations\n",
        "    only_activation_vals = [list() for x in range(256)]\n",
        "\n",
        "    # selectivity_list contains all of the selectivity of each neuron \n",
        "    selectivity_list = list()\n",
        "\n",
        "    # get only values from avg_activations\n",
        "    for i, avg_activation in enumerate(avg_activations):\n",
        "        for value in avg_activation.values():\n",
        "            only_activation_vals[i].append(value)\n",
        "\n",
        "\n",
        "    for activation_val in only_activation_vals:\n",
        "        # find u_max \n",
        "        u_max = np.max(activation_val)\n",
        "\n",
        "        # find u_minus_max \n",
        "        u_minus_max = (np.sum(activation_val) - u_max) / 9\n",
        "\n",
        "        # find selectivity \n",
        "        selectivity = (u_max - u_minus_max) / (u_max + u_minus_max)\n",
        "\n",
        "        # append selectivity value to selectivity_list\n",
        "        selectivity_list.append(selectivity)\n",
        "\n",
        "    return test_acc, selectivity_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKq9qSgMADr"
      },
      "source": [
        "# AdaDelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WytqcJRZxA"
      },
      "source": [
        "model_Adadelta = Model()\n",
        "print(\"model_Adadelta:\", model_Adadelta)\n",
        "model_Adadelta.to(device)\n",
        "model_Adadelta.sigmoid.register_forward_hook(get_activation(model_Adadelta))\n",
        "optimizer_Adadelta = torch.optim.Adadelta(model_Adadelta.parameters(), lr=1.0)\n",
        "Adadelta_test_acc, Adadelta_selectivity_list = selectivity_trainer(optimizer=optimizer_Adadelta, model=model_Adadelta)\n",
        "\n",
        "f = open(\"not_sorted_selectivity_Adadelta.txt\", \"a\")\n",
        "f.write(str(0)+'\\n'+str(Adadelta_test_acc)+'\\n'+str(np.average(Adadelta_selectivity_list))+'\\n'+str(np.std(Adadelta_selectivity_list))+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_selectivity_Adadelta.txt /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXfQe4vMDKB"
      },
      "source": [
        "# AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb-4TPM5MGuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ba497b-45a7-415c-9ad5-898769705397"
      },
      "source": [
        "model_Adagrad = Model()\n",
        "print(\"model_Adagrad:\", model_Adagrad)\n",
        "model_Adagrad.to(device)\n",
        "model_Adagrad.sigmoid.register_forward_hook(get_activation(model_Adagrad))\n",
        "optimizer_Adagrad = torch.optim.Adagrad(model_Adagrad.parameters(), lr=0.1)\n",
        "Adagrad_test_acc, Adagrad_selectivity_list = selectivity_trainer(optimizer=optimizer_Adagrad, model=model_Adagrad)\n",
        "\n",
        "f = open(\"not_sorted_selectivity_Adagrad.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adagrad_test_acc)+'\\n'+str(np.average(Adagrad_selectivity_list))+'\\n'+str(np.std(Adagrad_selectivity_list))+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_selectivity_Adagrad.txt /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adagrad: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.25258046, Test Loss: 0.12609529, Test Accuracy: 0.96400000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.10309967, Test Loss: 0.10109970, Test Accuracy: 0.96870000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.07298480, Test Loss: 0.09385988, Test Accuracy: 0.96920000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.05632330, Test Loss: 0.07996433, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.04489036, Test Loss: 0.07642399, Test Accuracy: 0.97640000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.03629026, Test Loss: 0.07400378, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.03001808, Test Loss: 0.07167674, Test Accuracy: 0.97710000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.02490960, Test Loss: 0.07024349, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.02092683, Test Loss: 0.06943788, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.01805655, Test Loss: 0.06961180, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.01566015, Test Loss: 0.06914306, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.01359088, Test Loss: 0.06803788, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.01188949, Test Loss: 0.06784331, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.01056453, Test Loss: 0.06748731, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.00937647, Test Loss: 0.06845701, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.00838093, Test Loss: 0.06746521, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.00760645, Test Loss: 0.06741957, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.00687379, Test Loss: 0.06757701, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.00629494, Test Loss: 0.06787334, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.00573218, Test Loss: 0.06757863, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.00528700, Test Loss: 0.06794375, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.00489190, Test Loss: 0.06708055, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.00455241, Test Loss: 0.06811688, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.00423414, Test Loss: 0.06838967, Test Accuracy: 0.97780000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.00395113, Test Loss: 0.06844128, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.00370304, Test Loss: 0.06874703, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.00347713, Test Loss: 0.06835801, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.00326178, Test Loss: 0.06854873, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.00309474, Test Loss: 0.06831893, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.00292309, Test Loss: 0.06853920, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.00277329, Test Loss: 0.06898954, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.00263502, Test Loss: 0.06868740, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.00249987, Test Loss: 0.06879360, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.00238842, Test Loss: 0.06934938, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00227738, Test Loss: 0.06907251, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00217797, Test Loss: 0.06934378, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00208217, Test Loss: 0.06959140, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00199226, Test Loss: 0.06929152, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00190326, Test Loss: 0.06967985, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00182763, Test Loss: 0.06990993, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00175211, Test Loss: 0.06998019, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00168989, Test Loss: 0.06996597, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00162635, Test Loss: 0.07019120, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00156749, Test Loss: 0.07023795, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00150864, Test Loss: 0.07043585, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00145901, Test Loss: 0.07056095, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00140883, Test Loss: 0.07034130, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00136124, Test Loss: 0.07101994, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00131759, Test Loss: 0.07066762, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00127182, Test Loss: 0.07080290, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00123265, Test Loss: 0.07124596, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00119419, Test Loss: 0.07158035, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00115800, Test Loss: 0.07129053, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00112479, Test Loss: 0.07119604, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00109281, Test Loss: 0.07123079, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00106074, Test Loss: 0.07160290, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00103517, Test Loss: 0.07159430, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00100713, Test Loss: 0.07165850, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00098275, Test Loss: 0.07203935, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00095497, Test Loss: 0.07223072, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00093396, Test Loss: 0.07241715, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00091134, Test Loss: 0.07237328, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00089125, Test Loss: 0.07227754, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00087019, Test Loss: 0.07231661, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00084997, Test Loss: 0.07272215, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00083210, Test Loss: 0.07284317, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00081253, Test Loss: 0.07309962, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00079595, Test Loss: 0.07293747, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00077910, Test Loss: 0.07286400, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00076356, Test Loss: 0.07322978, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00074793, Test Loss: 0.07321628, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00073273, Test Loss: 0.07329379, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00071770, Test Loss: 0.07342121, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00070479, Test Loss: 0.07342506, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00069139, Test Loss: 0.07358885, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00067746, Test Loss: 0.07370702, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00066475, Test Loss: 0.07389529, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00065352, Test Loss: 0.07391200, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00064132, Test Loss: 0.07374539, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00062903, Test Loss: 0.07411911, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00061919, Test Loss: 0.07408805, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00060818, Test Loss: 0.07428034, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00059802, Test Loss: 0.07437471, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00058732, Test Loss: 0.07455389, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00057811, Test Loss: 0.07462039, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00056922, Test Loss: 0.07457048, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00055990, Test Loss: 0.07480631, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00055089, Test Loss: 0.07491209, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00054177, Test Loss: 0.07507533, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00053328, Test Loss: 0.07496086, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00052572, Test Loss: 0.07522979, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00051731, Test Loss: 0.07504630, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00051038, Test Loss: 0.07548733, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00050205, Test Loss: 0.07564475, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00049513, Test Loss: 0.07535005, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00048814, Test Loss: 0.07547860, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00048147, Test Loss: 0.07560693, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00047415, Test Loss: 0.07568344, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00046819, Test Loss: 0.07560901, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00046140, Test Loss: 0.07575271, Test Accuracy: 0.98060000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLJ4Zr2MnoS"
      },
      "source": [
        "# SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ObsEJHuMoPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59be832-8c8d-494d-ca32-0f77e4002c7d"
      },
      "source": [
        "model_SGD = Model()\n",
        "print(\"model_SGD:\", model_SGD)\n",
        "model_SGD.to(device)\n",
        "model_SGD.sigmoid.register_forward_hook(get_activation(model_SGD))\n",
        "optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr=0.1)\n",
        "SGD_test_acc, SGD_selectivity_list = selectivity_trainer(optimizer=optimizer_SGD, model=model_SGD)\n",
        "\n",
        "f = open(\"not_sorted_selectivity_SGD.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(SGD_test_acc)+'\\n'+str(np.average(SGD_selectivity_list))+'\\n'+str(np.std(SGD_selectivity_list))+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_selectivity_SGD.txt /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_SGD: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.77723409, Test Loss: 0.37313266, Test Accuracy: 0.89520000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.34727685, Test Loss: 0.30445907, Test Accuracy: 0.91280000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.30735245, Test Loss: 0.28385138, Test Accuracy: 0.92000000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.28485614, Test Loss: 0.26544578, Test Accuracy: 0.92490000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.26737319, Test Loss: 0.25191398, Test Accuracy: 0.92810000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.25029423, Test Loss: 0.24011335, Test Accuracy: 0.93030000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.23442947, Test Loss: 0.22011212, Test Accuracy: 0.93650000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.21924428, Test Loss: 0.21427857, Test Accuracy: 0.93850000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.20613533, Test Loss: 0.20255191, Test Accuracy: 0.94080000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.19300371, Test Loss: 0.18722228, Test Accuracy: 0.94600000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.18202251, Test Loss: 0.17907211, Test Accuracy: 0.94800000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.17119431, Test Loss: 0.17048707, Test Accuracy: 0.94960000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.16238878, Test Loss: 0.16011688, Test Accuracy: 0.95290000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.15402859, Test Loss: 0.15466410, Test Accuracy: 0.95480000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.14618437, Test Loss: 0.14898521, Test Accuracy: 0.95570000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.13906063, Test Loss: 0.14027909, Test Accuracy: 0.95800000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.13276207, Test Loss: 0.13645628, Test Accuracy: 0.96000000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.12696758, Test Loss: 0.13090163, Test Accuracy: 0.96040000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.12142137, Test Loss: 0.12823266, Test Accuracy: 0.96180000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.11632346, Test Loss: 0.12222246, Test Accuracy: 0.96420000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.11162000, Test Loss: 0.12034595, Test Accuracy: 0.96340000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.10708322, Test Loss: 0.11572293, Test Accuracy: 0.96480000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.10297154, Test Loss: 0.11442075, Test Accuracy: 0.96660000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.09916286, Test Loss: 0.10932088, Test Accuracy: 0.96660000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.09568629, Test Loss: 0.10751288, Test Accuracy: 0.96720000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.09211885, Test Loss: 0.10663042, Test Accuracy: 0.96670000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.08885613, Test Loss: 0.10414018, Test Accuracy: 0.96850000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.08585990, Test Loss: 0.10049299, Test Accuracy: 0.96920000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.08313708, Test Loss: 0.09780724, Test Accuracy: 0.96980000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.08018050, Test Loss: 0.09590099, Test Accuracy: 0.97090000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.07784705, Test Loss: 0.09461174, Test Accuracy: 0.97020000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.07532646, Test Loss: 0.09337224, Test Accuracy: 0.97100000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.07289026, Test Loss: 0.09063902, Test Accuracy: 0.97140000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.07080012, Test Loss: 0.09003995, Test Accuracy: 0.97310000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.06854772, Test Loss: 0.09175942, Test Accuracy: 0.97280000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.06654971, Test Loss: 0.08756616, Test Accuracy: 0.97360000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.06468380, Test Loss: 0.08743949, Test Accuracy: 0.97280000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.06271067, Test Loss: 0.08489112, Test Accuracy: 0.97490000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.06106739, Test Loss: 0.08390575, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.05921162, Test Loss: 0.08350768, Test Accuracy: 0.97410000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.05745738, Test Loss: 0.08296769, Test Accuracy: 0.97460000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.05610121, Test Loss: 0.08151979, Test Accuracy: 0.97450000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.05456485, Test Loss: 0.07964738, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.05304698, Test Loss: 0.07828234, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.05176802, Test Loss: 0.07810334, Test Accuracy: 0.97550000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.05028707, Test Loss: 0.07805543, Test Accuracy: 0.97600000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.04906613, Test Loss: 0.07607157, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.04787844, Test Loss: 0.07710197, Test Accuracy: 0.97560000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.04660863, Test Loss: 0.07662562, Test Accuracy: 0.97540000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.04549285, Test Loss: 0.07504969, Test Accuracy: 0.97630000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.04435008, Test Loss: 0.07473289, Test Accuracy: 0.97800000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.04312426, Test Loss: 0.07509801, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.04225150, Test Loss: 0.07176872, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.04108012, Test Loss: 0.07324030, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.04019772, Test Loss: 0.07196317, Test Accuracy: 0.97720000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.03909320, Test Loss: 0.07114719, Test Accuracy: 0.97700000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.03823883, Test Loss: 0.07038088, Test Accuracy: 0.97790000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.03729093, Test Loss: 0.07093140, Test Accuracy: 0.97730000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.03643836, Test Loss: 0.06922669, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.03560669, Test Loss: 0.06958604, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.03461476, Test Loss: 0.06950817, Test Accuracy: 0.97740000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.03389265, Test Loss: 0.06900508, Test Accuracy: 0.97820000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.03318216, Test Loss: 0.06900791, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.03249759, Test Loss: 0.06817094, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.03165292, Test Loss: 0.06712767, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.03105859, Test Loss: 0.06756180, Test Accuracy: 0.97850000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.03035188, Test Loss: 0.06649761, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.02966083, Test Loss: 0.06711738, Test Accuracy: 0.97830000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.02895670, Test Loss: 0.06716421, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.02827490, Test Loss: 0.06601454, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.02765846, Test Loss: 0.06562752, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.02713320, Test Loss: 0.06546552, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.02650396, Test Loss: 0.06551673, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.02597333, Test Loss: 0.06598638, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.02539811, Test Loss: 0.06447339, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.02487577, Test Loss: 0.06587780, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.02437148, Test Loss: 0.06461265, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.02383289, Test Loss: 0.06521030, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.02333236, Test Loss: 0.06425752, Test Accuracy: 0.97880000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.02285488, Test Loss: 0.06363034, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.02240118, Test Loss: 0.06341285, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.02184351, Test Loss: 0.06438572, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.02150078, Test Loss: 0.06437650, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.02103467, Test Loss: 0.06428080, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.02063789, Test Loss: 0.06347091, Test Accuracy: 0.97900000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.02026193, Test Loss: 0.06372279, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.01977322, Test Loss: 0.06254789, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.01948727, Test Loss: 0.06329508, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.01900108, Test Loss: 0.06361767, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.01868941, Test Loss: 0.06205528, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.01832794, Test Loss: 0.06297598, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.01798944, Test Loss: 0.06283954, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.01767177, Test Loss: 0.06193269, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.01730822, Test Loss: 0.06225208, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.01697540, Test Loss: 0.06211837, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.01666104, Test Loss: 0.06226631, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.01629445, Test Loss: 0.06297070, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.01601889, Test Loss: 0.06240063, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.01572766, Test Loss: 0.06175615, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.01545797, Test Loss: 0.06260698, Test Accuracy: 0.98070000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQxaN_fRXLq"
      },
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkqfFoVkRXxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2eb296-aaa2-444e-a4e4-7c6ffd1e09a1"
      },
      "source": [
        "model_Adam = Model()\n",
        "print(\"model_Adam:\", model_Adam)\n",
        "model_Adam.to(device)\n",
        "model_Adam.sigmoid.register_forward_hook(get_activation(model_Adam))\n",
        "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=0.001)\n",
        "Adam_test_acc, Adam_selectivity_list = selectivity_trainer(optimizer=optimizer_Adam, model=model_Adam)\n",
        "\n",
        "f = open(\"not_sorted_selectivity_Adam.txt\", \"w\")\n",
        "f.write(str(0)+'\\n'+str(Adam_test_acc)+'\\n'+str(np.average(Adam_selectivity_list))+'\\n'+str(np.std(Adam_selectivity_list))+'\\n\\n')\n",
        "f.close()\n",
        "\n",
        "!cp not_sorted_selectivity_Adam.txt /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_Adam: Model(\n",
            "  (linear_1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Epoch: 1/100, Train Loss: 0.42718115, Test Loss: 0.22443770, Test Accuracy: 0.93520000\n",
            "\n",
            "Epoch: 2/100, Train Loss: 0.19834835, Test Loss: 0.16388322, Test Accuracy: 0.95140000\n",
            "\n",
            "Epoch: 3/100, Train Loss: 0.14312717, Test Loss: 0.13139713, Test Accuracy: 0.96030000\n",
            "\n",
            "Epoch: 4/100, Train Loss: 0.10981040, Test Loss: 0.10850899, Test Accuracy: 0.96910000\n",
            "\n",
            "Epoch: 5/100, Train Loss: 0.08679321, Test Loss: 0.09350853, Test Accuracy: 0.97100000\n",
            "\n",
            "Epoch: 6/100, Train Loss: 0.06963237, Test Loss: 0.08395875, Test Accuracy: 0.97470000\n",
            "\n",
            "Epoch: 7/100, Train Loss: 0.05673326, Test Loss: 0.07634868, Test Accuracy: 0.97660000\n",
            "\n",
            "Epoch: 8/100, Train Loss: 0.04688189, Test Loss: 0.07065204, Test Accuracy: 0.97760000\n",
            "\n",
            "Epoch: 9/100, Train Loss: 0.03782095, Test Loss: 0.07152031, Test Accuracy: 0.97810000\n",
            "\n",
            "Epoch: 10/100, Train Loss: 0.03140383, Test Loss: 0.06709625, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 11/100, Train Loss: 0.02538698, Test Loss: 0.06592197, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 12/100, Train Loss: 0.02085642, Test Loss: 0.06645740, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 13/100, Train Loss: 0.01663339, Test Loss: 0.06344215, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 14/100, Train Loss: 0.01371639, Test Loss: 0.06320045, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 15/100, Train Loss: 0.01102118, Test Loss: 0.07043395, Test Accuracy: 0.97920000\n",
            "\n",
            "Epoch: 16/100, Train Loss: 0.00863311, Test Loss: 0.07025997, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 17/100, Train Loss: 0.00713159, Test Loss: 0.06522836, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 18/100, Train Loss: 0.00575823, Test Loss: 0.06920990, Test Accuracy: 0.97910000\n",
            "\n",
            "Epoch: 19/100, Train Loss: 0.00437670, Test Loss: 0.06735116, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 20/100, Train Loss: 0.00367284, Test Loss: 0.07108823, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 21/100, Train Loss: 0.00337629, Test Loss: 0.06923143, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 22/100, Train Loss: 0.00229773, Test Loss: 0.07003634, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 23/100, Train Loss: 0.00184305, Test Loss: 0.07391859, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 24/100, Train Loss: 0.00151247, Test Loss: 0.07163594, Test Accuracy: 0.98120000\n",
            "\n",
            "Epoch: 25/100, Train Loss: 0.00121325, Test Loss: 0.07553940, Test Accuracy: 0.97960000\n",
            "\n",
            "Epoch: 26/100, Train Loss: 0.00094951, Test Loss: 0.07612158, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 27/100, Train Loss: 0.00096874, Test Loss: 0.08634856, Test Accuracy: 0.97890000\n",
            "\n",
            "Epoch: 28/100, Train Loss: 0.00141302, Test Loss: 0.07924347, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 29/100, Train Loss: 0.00041873, Test Loss: 0.07966960, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 30/100, Train Loss: 0.00037227, Test Loss: 0.08075455, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 31/100, Train Loss: 0.00027316, Test Loss: 0.08326486, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 32/100, Train Loss: 0.00165331, Test Loss: 0.08464362, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 33/100, Train Loss: 0.00036219, Test Loss: 0.08181692, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 34/100, Train Loss: 0.00016711, Test Loss: 0.08311347, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 35/100, Train Loss: 0.00013727, Test Loss: 0.08559787, Test Accuracy: 0.98150000\n",
            "\n",
            "Epoch: 36/100, Train Loss: 0.00097930, Test Loss: 0.08548609, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 37/100, Train Loss: 0.00017410, Test Loss: 0.08650065, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 38/100, Train Loss: 0.00009877, Test Loss: 0.08834770, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 39/100, Train Loss: 0.00008108, Test Loss: 0.08968639, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 40/100, Train Loss: 0.00162220, Test Loss: 0.10709858, Test Accuracy: 0.97770000\n",
            "\n",
            "Epoch: 41/100, Train Loss: 0.00037065, Test Loss: 0.09572860, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 42/100, Train Loss: 0.00009728, Test Loss: 0.09187702, Test Accuracy: 0.98180000\n",
            "\n",
            "Epoch: 43/100, Train Loss: 0.00006454, Test Loss: 0.09207760, Test Accuracy: 0.98130000\n",
            "\n",
            "Epoch: 44/100, Train Loss: 0.00005282, Test Loss: 0.09207608, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 45/100, Train Loss: 0.00004677, Test Loss: 0.09363433, Test Accuracy: 0.98170000\n",
            "\n",
            "Epoch: 46/100, Train Loss: 0.00100913, Test Loss: 0.10411734, Test Accuracy: 0.97860000\n",
            "\n",
            "Epoch: 47/100, Train Loss: 0.00069969, Test Loss: 0.09439961, Test Accuracy: 0.98090000\n",
            "\n",
            "Epoch: 48/100, Train Loss: 0.00006139, Test Loss: 0.09559138, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 49/100, Train Loss: 0.00004400, Test Loss: 0.09631185, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 50/100, Train Loss: 0.00003537, Test Loss: 0.09739815, Test Accuracy: 0.98100000\n",
            "\n",
            "Epoch: 51/100, Train Loss: 0.00122527, Test Loss: 0.10039234, Test Accuracy: 0.97980000\n",
            "\n",
            "Epoch: 52/100, Train Loss: 0.00029195, Test Loss: 0.09558438, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 53/100, Train Loss: 0.00005186, Test Loss: 0.09591365, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 54/100, Train Loss: 0.00003595, Test Loss: 0.09771534, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 55/100, Train Loss: 0.00002885, Test Loss: 0.09732680, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 56/100, Train Loss: 0.00002332, Test Loss: 0.09934952, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 57/100, Train Loss: 0.00013046, Test Loss: 0.10522198, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 58/100, Train Loss: 0.00086967, Test Loss: 0.10346928, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 59/100, Train Loss: 0.00004467, Test Loss: 0.10321251, Test Accuracy: 0.98060000\n",
            "\n",
            "Epoch: 60/100, Train Loss: 0.00002694, Test Loss: 0.10321151, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 61/100, Train Loss: 0.00002072, Test Loss: 0.10317649, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 62/100, Train Loss: 0.00001653, Test Loss: 0.10392433, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 63/100, Train Loss: 0.00001359, Test Loss: 0.10464063, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 64/100, Train Loss: 0.00001134, Test Loss: 0.10603379, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 65/100, Train Loss: 0.00000972, Test Loss: 0.10742223, Test Accuracy: 0.98080000\n",
            "\n",
            "Epoch: 66/100, Train Loss: 0.00188208, Test Loss: 0.11115120, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 67/100, Train Loss: 0.00014922, Test Loss: 0.11134756, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 68/100, Train Loss: 0.00002454, Test Loss: 0.11085761, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 69/100, Train Loss: 0.00001701, Test Loss: 0.11082772, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 70/100, Train Loss: 0.00001261, Test Loss: 0.11101399, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 71/100, Train Loss: 0.00000986, Test Loss: 0.11176959, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 72/100, Train Loss: 0.00000784, Test Loss: 0.11167906, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 73/100, Train Loss: 0.00000627, Test Loss: 0.11268560, Test Accuracy: 0.97990000\n",
            "\n",
            "Epoch: 74/100, Train Loss: 0.00000516, Test Loss: 0.11347198, Test Accuracy: 0.98030000\n",
            "\n",
            "Epoch: 75/100, Train Loss: 0.00000436, Test Loss: 0.11469008, Test Accuracy: 0.97970000\n",
            "\n",
            "Epoch: 76/100, Train Loss: 0.00080698, Test Loss: 0.11761779, Test Accuracy: 0.98050000\n",
            "\n",
            "Epoch: 77/100, Train Loss: 0.00004232, Test Loss: 0.11564647, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 78/100, Train Loss: 0.00001013, Test Loss: 0.11552018, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 79/100, Train Loss: 0.00000712, Test Loss: 0.11590979, Test Accuracy: 0.98110000\n",
            "\n",
            "Epoch: 80/100, Train Loss: 0.00000534, Test Loss: 0.11632401, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 81/100, Train Loss: 0.00000415, Test Loss: 0.11770054, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 82/100, Train Loss: 0.00000333, Test Loss: 0.11784478, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 83/100, Train Loss: 0.00000266, Test Loss: 0.11912171, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 84/100, Train Loss: 0.00000218, Test Loss: 0.12135572, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 85/100, Train Loss: 0.00000198, Test Loss: 0.12046582, Test Accuracy: 0.98070000\n",
            "\n",
            "Epoch: 86/100, Train Loss: 0.00060643, Test Loss: 0.12685055, Test Accuracy: 0.97930000\n",
            "\n",
            "Epoch: 87/100, Train Loss: 0.00001662, Test Loss: 0.12429278, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 88/100, Train Loss: 0.00000566, Test Loss: 0.12458757, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 89/100, Train Loss: 0.00000416, Test Loss: 0.12491528, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 90/100, Train Loss: 0.00000321, Test Loss: 0.12511305, Test Accuracy: 0.98010000\n",
            "\n",
            "Epoch: 91/100, Train Loss: 0.00000250, Test Loss: 0.12471338, Test Accuracy: 0.98040000\n",
            "\n",
            "Epoch: 92/100, Train Loss: 0.00000200, Test Loss: 0.12576906, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 93/100, Train Loss: 0.00000161, Test Loss: 0.12688946, Test Accuracy: 0.98000000\n",
            "\n",
            "Epoch: 94/100, Train Loss: 0.00000131, Test Loss: 0.12658071, Test Accuracy: 0.98020000\n",
            "\n",
            "Epoch: 95/100, Train Loss: 0.00060756, Test Loss: 0.16991158, Test Accuracy: 0.97620000\n",
            "\n",
            "Epoch: 96/100, Train Loss: 0.00041685, Test Loss: 0.13117272, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 97/100, Train Loss: 0.00003731, Test Loss: 0.13301395, Test Accuracy: 0.97870000\n",
            "\n",
            "Epoch: 98/100, Train Loss: 0.00000701, Test Loss: 0.13108377, Test Accuracy: 0.97940000\n",
            "\n",
            "Epoch: 99/100, Train Loss: 0.00000359, Test Loss: 0.13065298, Test Accuracy: 0.97950000\n",
            "\n",
            "Epoch: 100/100, Train Loss: 0.00000264, Test Loss: 0.13122587, Test Accuracy: 0.97960000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW3sV4cOZAIw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}