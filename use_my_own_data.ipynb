{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use_my_own_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIR0PCrKrEl3c1DrwPtw7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7201krap/Introduction_to_Pytorch/blob/main/use_my_own_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rqxkp8kSK2L"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tr\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3PxOYTPSO0h"
      },
      "source": [
        "# generate random image \n",
        "\n",
        "# 20 images, 32 X 32 pixels, and 3 channels \n",
        "train_images = np.random.randint(256, size=(20,32,32,3))\n",
        "# 2 labels: either 0 or 1 \n",
        "train_labels = np.random.randint(2,   size=(20,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKntxMJnS3jQ",
        "outputId": "81e7746d-abc8-43da-b4f4-94b6ea7ed4ca"
      },
      "source": [
        "print(f\"train_images.shape: {train_images.shape}\")\n",
        "print(f\"train_labels.shape: {train_labels.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_images.shape: (20, 32, 32, 3)\n",
            "train_labels.shape: (20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA0_4rlqS_dU"
      },
      "source": [
        "class TensorData(Dataset):\n",
        "  def __init__(self, x_data, y_data, transform=None):\n",
        "    self.x_data = x_data\n",
        "    self.y_data = y_data \n",
        "    self.transform = transform\n",
        "    self.len    = len(y_data)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample \n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFi-ze_YZtQh"
      },
      "source": [
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, labels = sample \n",
        "    inputs = torch.FloatTensor(inputs)\n",
        "    # numpy notation: 32 32 3 --> tensor notation: 3 32 32 \n",
        "    inputs = inputs.permute(2, 0, 1)\n",
        "    return inputs, torch.LongTensor(labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE65lRuzawr9"
      },
      "source": [
        "class LinearTensor:\n",
        "  def __init__(self, slope=1, bias=0):\n",
        "    self.slope = slope \n",
        "    self.bias  = bias \n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, labels = sample \n",
        "    inputs = self.slope * inputs + self.bias \n",
        "\n",
        "    return inputs, labels "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO2LWWcMbcd9"
      },
      "source": [
        "transf       = tr.Compose([ToTensor(), LinearTensor(2, 5)])\n",
        "train_set    = TensorData(train_images, train_labels, transform=transf)\n",
        "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy1y_YxPcA6U"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiRYZTvUczjj",
        "outputId": "3c96b994-8be0-4c50-ded6-c495bdb18e84"
      },
      "source": [
        "images[0].shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVDkH2rtdmri"
      },
      "source": [
        "images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi35dlwZVJmj",
        "outputId": "9546d66b-82dc-41b0-e355-227fa1f4a6ec"
      },
      "source": [
        "print(f\"Image size             : {images.size()}\")\n",
        "print(f\"Its corresponding label: {labels.flatten()}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size             : torch.Size([10, 3, 32, 32])\n",
            "Its corresponding label: tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boytQMjFVKAn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}